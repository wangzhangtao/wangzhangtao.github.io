<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>k8s/1.部署基础环境</title>
      <link href="/2020/06/19/k8s-1-%E9%83%A8%E7%BD%B2%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/"/>
      <url>/2020/06/19/k8s-1-%E9%83%A8%E7%BD%B2%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h2 id="nginx运维仓库"><a href="#nginx运维仓库" class="headerlink" title="nginx运维仓库"></a>nginx运维仓库</h2><p>在wang-200服务器上创建本地安装包和安装文档，方便以后工作</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;doc.od.com.conf </span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  doc.od.com;</span><br><span class="line">    # index index.html index.htm index.jsp;</span><br><span class="line">    # root &#x2F;data&#x2F;k8s;</span><br><span class="line"></span><br><span class="line">    location &#x2F;shell &#123;</span><br><span class="line">        autoindex on;</span><br><span class="line">        autoindex_exact_size off;</span><br><span class="line">        default_type text&#x2F;plain;</span><br><span class="line">        alias &#x2F;data&#x2F;shell&#x2F;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location &#x2F;soft &#123;</span><br><span class="line">        autoindex on;</span><br><span class="line">        autoindex_exact_size off;</span><br><span class="line">        alias &#x2F;data&#x2F;soft&#x2F;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    access_log &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;doc.log;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h2><blockquote><p>官网地址  :)  (没有)</p></blockquote><p>下载官网软件包到运维主机 /data/soft/centos7/jdk-8u202-linux-x64.tar.gz</p><p><strong>在运维主机创建jdk安装脚本</strong></p><p><code>vim /data/shell/install_java.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 准备文件夹</span><br><span class="line">mkdir &#x2F;opt&#x2F;src</span><br><span class="line">mkdir &#x2F;usr&#x2F;java</span><br><span class="line"></span><br><span class="line"># 拷贝安装包并解压</span><br><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;jdk-8u202-linux-x64.tar.gz -O &#x2F;opt&#x2F;src&#x2F;jdk-8u202-linux-x64.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;jdk-8u202-linux-x64.tar.gz -C &#x2F;usr&#x2F;java&#x2F;</span><br><span class="line">ln -s &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_202 &#x2F;usr&#x2F;java&#x2F;jdk</span><br><span class="line"></span><br><span class="line"># 配置默认全局变量</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">#JAVA HOME</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk</span><br><span class="line">export PATH&#x3D;\$PATH:\$JAVA_HOME&#x2F;bin:\$JAVA_HOME&#x2F;sbin</span><br><span class="line">export CLASSPATH&#x3D;\$CLASSPATH:\$JAVA_HOME&#x2F;lib:\$JAVA_HOME&#x2F;lib&#x2F;tools.jar</span><br><span class="line">EOF</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line"># 检查java是否可用</span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><p>执行远程脚本安装java</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;doc.od.com&#x2F;shell&#x2F;install_java.sh | sh</span><br></pre></td></tr></table></figure><h2 id="安装npm"><a href="#安装npm" class="headerlink" title="安装npm"></a>安装npm</h2><blockquote><p>官网下载地址 <a href="https://nodejs.org/dist/v12.16.2/node-v12.16.2-linux-x64.tar.xz" target="_blank" rel="noopener">node-v12.16.2</a></p><p>下载到运维主机 /data/soft/centos7/node-v12.16.2-linux-x64.tar.xz</p></blockquote><p><strong>在运维主机创建jdk安装脚本</strong></p><p><code>vim /data/shell/install_node.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;node-v12.16.2-linux-x64.tar.xz -O &#x2F;opt&#x2F;src&#x2F;node-v12.16.2-linux-x64.tar.xz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;node-v12.16.2-linux-x64.tar.xz -C &#x2F;usr&#x2F;</span><br><span class="line">ln -s &#x2F;usr&#x2F;node-v12.16.2-linux-x64 &#x2F;usr&#x2F;node</span><br><span class="line"></span><br><span class="line"># 配置全局变量</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">#NODE HOME</span><br><span class="line">export NODE_HOME&#x3D;&#x2F;usr&#x2F;node</span><br><span class="line">export PATH&#x3D;\$PATH:\$NODE_HOME&#x2F;bin</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 查看并验证node</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line"></span><br><span class="line"># 安装淘宝镜像源</span><br><span class="line">npm install -g cnpm --registry&#x3D;https:&#x2F;&#x2F;registry.npm.taobao.org</span><br><span class="line">cnpm -v</span><br></pre></td></tr></table></figure><p>执行远程脚本安装npm</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;doc.od.com&#x2F;shell&#x2F;install_node.sh | sh</span><br></pre></td></tr></table></figure><h2 id="部署golang"><a href="#部署golang" class="headerlink" title="部署golang"></a>部署golang</h2><p>安装包下载地址为：<a href="https://golang.org/dl/。" target="_blank" rel="noopener">https://golang.org/dl/。</a></p><p>如果打不开可以使用这个地址：<a href="https://golang.google.cn/dl/" target="_blank" rel="noopener">https://golang.google.cn/dl/</a>  <a href="https://dl.google.com/go/go1.14.4.linux-amd64.tar.gz" target="_blank" rel="noopener">go1.14.4</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;dl.google.com&#x2F;go&#x2F;go1.14.4.linux-amd64.tar.gz -O &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;go1.14.4.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>vim /data/shell/install_go.sh </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压安装包</span><br><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;go1.14.4.linux-amd64.tar.gz -O &#x2F;opt&#x2F;src&#x2F;go1.14.4.linux-amd64.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;go1.14.4.linux-amd64.tar.gz -C &#x2F;usr&#x2F;</span><br><span class="line">mv &#x2F;usr&#x2F;go &#x2F;usr&#x2F;go-1.14.4</span><br><span class="line">ln -s &#x2F;usr&#x2F;go-1.14.4 &#x2F;usr&#x2F;go</span><br><span class="line"></span><br><span class="line"># 设置全局变量</span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;profile</span><br><span class="line">#NODE HOME</span><br><span class="line">export GO_HOME&#x3D;&#x2F;usr&#x2F;go</span><br><span class="line">export PATH&#x3D;\$PATH:\$GO_HOME&#x2F;bin</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 验证可用性</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">go version</span><br></pre></td></tr></table></figure><p>远程执行安装脚本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;doc.od.com&#x2F;shell&#x2F;install_go.sh | sh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>二、常用软件-ELKF+kafka集群</title>
      <link href="/2020/06/17/%E4%BA%8C%E3%80%81%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6-elkf-kafka%E9%9B%86%E7%BE%A4/"/>
      <url>/2020/06/17/%E4%BA%8C%E3%80%81%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6-elkf-kafka%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="ELKF介绍"><a href="#ELKF介绍" class="headerlink" title="ELKF介绍"></a>ELKF介绍</h2><h3 id="elk介绍"><a href="#elk介绍" class="headerlink" title="elk介绍"></a>elk介绍</h3><p>ELK是三个开源软件的缩写，分别表示：Elasticsearch , Logstash, Kibana ,  它们都是开源软件。新增了一个FileBeat，它是一个轻量级的日志收集处理工具(Agent)，Filebeat占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具。  Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 Logstash  主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。 Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web  界面，可以帮助汇总、分析和搜索重要数据日志。 </p><h3 id="kakfa介绍"><a href="#kakfa介绍" class="headerlink" title="kakfa介绍"></a>kakfa介绍</h3><p>kafka  是一个分布式的基于push-subscribe的消息系统，它具备快速、可扩展、可持久化的特点。它现在是Apache旗下的一个开源系统，作为Hadoop生态系统的一部分，被各种商业公司广泛应用。它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/spark流式处理引擎。 特点：</p><ul><li><strong>高吞吐量、低延迟</strong>：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒</li><li><strong>可扩展性</strong>：kafka集群支持热扩展</li><li><strong>持久性、可靠性</strong>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li><li><strong>容错性</strong>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li><li><strong>高并发</strong>：支持数千个客户端同时读写</li></ul><h3 id="zookeeper介绍"><a href="#zookeeper介绍" class="headerlink" title="zookeeper介绍"></a>zookeeper介绍</h3><p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 集群角色：</p><ul><li>Leader服务器是整个zookeeper集群工作机制中的核心</li><li>Follower服务器是zookeeper集群状态的跟随者</li><li>Observer 服务器充当一个观察者的角色</li></ul><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><pre><code>系统版本 CentOS 7.6.1810</code></pre><p>​     jdk：8u202</p><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><table><thead><tr><th>主机名</th><th>IP</th><th>备住</th><th>资源</th></tr></thead><tbody><tr><td>wang-13</td><td>192.168.70.13</td><td>zk+kafka+ES+logstash+kibana+nginx</td><td>2核4G</td></tr><tr><td>wang-14</td><td>192.168.70.13</td><td>zk+kafka+ES</td><td>2核4G</td></tr><tr><td>wang-15</td><td>192.168.70.13</td><td>zk+kafka+ES</td><td>2核4G</td></tr></tbody></table><h3 id="安装jdk（所有）"><a href="#安装jdk（所有）" class="headerlink" title="安装jdk（所有）"></a>安装jdk（所有）</h3><blockquote><p>官网地址  :)  (没有)</p></blockquote><p>下载官网软件包到运维主机 /data/soft/centos7/jdk-8u202-linux-x64.tar.gz</p><p><strong>在运维主机创建jdk安装脚本</strong></p><p><code>vim /data/shell/install_java.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 准备文件夹</span><br><span class="line">mkdir &#x2F;opt&#x2F;src</span><br><span class="line">mkdir &#x2F;usr&#x2F;java</span><br><span class="line"></span><br><span class="line"># 拷贝安装包并解压</span><br><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;jdk-8u202-linux-x64.tar.gz -O &#x2F;opt&#x2F;src&#x2F;jdk-8u202-linux-x64.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;jdk-8u202-linux-x64.tar.gz -C &#x2F;usr&#x2F;java&#x2F;</span><br><span class="line">ln -s &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_202 &#x2F;usr&#x2F;java&#x2F;jdk</span><br><span class="line"></span><br><span class="line"># 配置默认全局变量</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">#JAVA HOME</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk</span><br><span class="line">export PATH&#x3D;\$PATH:\$JAVA_HOME&#x2F;bin:\$JAVA_HOME&#x2F;sbin</span><br><span class="line">export CLASSPATH&#x3D;\$CLASSPATH:\$JAVA_HOME&#x2F;lib:\$JAVA_HOME&#x2F;lib&#x2F;tools.jar</span><br><span class="line">EOF</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line"># 检查java是否可用</span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><p>执行远程脚本安装java</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;doc.od.com&#x2F;shell&#x2F;install_java.sh | sh</span><br></pre></td></tr></table></figure><h3 id="安装npm"><a href="#安装npm" class="headerlink" title="安装npm"></a>安装npm</h3><blockquote><p>官网下载地址 <a href="https://nodejs.org/dist/v12.16.2/node-v12.16.2-linux-x64.tar.xz" target="_blank" rel="noopener">node-v12.16.2</a></p><p>下载到运维主机 /data/soft/centos7/node-v12.16.2-linux-x64.tar.xz</p></blockquote><p><strong>在运维主机创建jdk安装脚本</strong></p><p><code>vim /data/shell/install_node.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;node-v12.16.2-linux-x64.tar.xz -O &#x2F;opt&#x2F;src&#x2F;node-v12.16.2-linux-x64.tar.xz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;node-v12.16.2-linux-x64.tar.xz -C &#x2F;usr&#x2F;</span><br><span class="line">ln -s &#x2F;usr&#x2F;node-v12.16.2-linux-x64 &#x2F;usr&#x2F;node</span><br><span class="line"></span><br><span class="line"># 配置全局变量</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">#NODE HOME</span><br><span class="line">export NODE_HOME&#x3D;&#x2F;usr&#x2F;node</span><br><span class="line">export PATH&#x3D;\$PATH:\$NODE_HOME&#x2F;bin</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 查看并验证node</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">node -v</span><br><span class="line">npm -v</span><br><span class="line"></span><br><span class="line"># 安装淘宝镜像源</span><br><span class="line">npm install -g cnpm --registry&#x3D;https:&#x2F;&#x2F;registry.npm.taobao.org</span><br><span class="line">cnpm -v</span><br></pre></td></tr></table></figure><p>执行远程脚本安装npm</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;doc.od.com&#x2F;shell&#x2F;install_node.sh | sh</span><br></pre></td></tr></table></figure><h2 id="部署zookeeper集群"><a href="#部署zookeeper集群" class="headerlink" title="部署zookeeper集群"></a>部署zookeeper集群</h2><h3 id="下载zookeeper"><a href="#下载zookeeper" class="headerlink" title="下载zookeeper"></a>下载zookeeper</h3><blockquote><p>下载zookeeper: <a href="https://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">下载地址</a>   <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz" target="_blank" rel="noopener">版本3.4.14</a></p></blockquote><p>下载官网软件包到运维主机 /data/soft/centos7/zookeeper-3.4.14.tar.gz</p><h3 id="解压安装包到服务器"><a href="#解压安装包到服务器" class="headerlink" title="解压安装包到服务器"></a>解压安装包到服务器</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;src&#x2F; </span><br><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;zookeeper-3.4.14.tar.gz </span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;zookeeper-3.4.14.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;zookeeper-3.4.14  &#x2F;opt&#x2F;zookeeper</span><br><span class="line">mkdir -pv &#x2F;data&#x2F;zookeeper&#x2F;data &#x2F;data&#x2F;zookeeper&#x2F;logs</span><br></pre></td></tr></table></figure><h3 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;zookeeper&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line">dataDir&#x3D;&#x2F;data&#x2F;zookeeper&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;data&#x2F;zookeeper&#x2F;logs</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line"></span><br><span class="line">server.1&#x3D;192.168.70.13:2888:3888</span><br><span class="line">server.2&#x3D;192.168.70.14:2888:3888</span><br><span class="line">server.3&#x3D;192.168.70.15:2888:3888</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>创建myid文件，里面是zookeeper标签,内容就是对应的你当前 ip 下的 server.x</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# echo &quot;1&quot; &gt; &#x2F;data&#x2F;zookeeper&#x2F;data&#x2F;myid</span><br></pre></td></tr></table></figure><h3 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><p>等zookeeper集群启动一半以上，再查看状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-14 src]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh status </span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: leader</span><br></pre></td></tr></table></figure><h2 id="部署kafka集群"><a href="#部署kafka集群" class="headerlink" title="部署kafka集群"></a>部署kafka集群</h2><blockquote><p><a href="http://mirror.bit.edu.cn/apache/kafka/2.0.0/kafka_2.11-2.0.0.tgz" target="_blank" rel="noopener">kafka2.0.0北理工镜像</a>  <a href="https://archive.apache.org/dist/kafka/2.2.0/kafka_2.12-2.2.0.tgz" target="_blank" rel="noopener">官网kafka2.2.0</a></p><p>下载到运维主机 /data/soft/centos7/kafka_2.12-2.2.0.tgz</p></blockquote><p>解压Kafka到服务器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;kafka_2.12-2.2.0.tgz -O &#x2F;opt&#x2F;src&#x2F;kafka_2.12-2.2.0.tgz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;kafka_2.12-2.2.0.tgz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;kafka_2.12-2.2.0 &#x2F;opt&#x2F;kafka</span><br><span class="line">mkdir -p &#x2F;data&#x2F;kafka&#x2F;logs</span><br></pre></td></tr></table></figure><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties </span><br><span class="line">broker.id&#x3D;1</span><br><span class="line">listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;192.168.70.13:9092</span><br><span class="line">num.network.threads&#x3D;3</span><br><span class="line">num.io.threads&#x3D;8</span><br><span class="line">socket.send.buffer.bytes&#x3D;102400</span><br><span class="line">socket.receive.buffer.bytes&#x3D;102400</span><br><span class="line">socket.request.max.bytes&#x3D;104857600</span><br><span class="line">log.dirs&#x3D;&#x2F;data&#x2F;kafka&#x2F;logs</span><br><span class="line">num.partitions&#x3D;1</span><br><span class="line">num.recovery.threads.per.data.dir&#x3D;1</span><br><span class="line">offsets.topic.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.min.isr&#x3D;1</span><br><span class="line">log.retention.hours&#x3D;168</span><br><span class="line">log.segment.bytes&#x3D;1073741824</span><br><span class="line">log.retention.check.interval.ms&#x3D;300000</span><br><span class="line">zookeeper.connect&#x3D;192.168.70.13:2181,192.168.70.13:2181,192.168.70.13:2181</span><br><span class="line">zookeeper.connection.timeout.ms&#x3D;6000</span><br><span class="line">group.initial.rebalance.delay.ms&#x3D;0</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>这两个参数需要修改broker.id zookeeper.connect， 添加 listeners  </p></blockquote><p>启动Kafka</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh -daemon &#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties</span><br><span class="line">[root@wang-13 ~]# netstat -luntp|grep 9092   </span><br><span class="line">tcp6       0      0 192.168.70.13:9092      :::*                    LISTEN      55398&#x2F;java</span><br></pre></td></tr></table></figure><h3 id="测试消息生产和消费"><a href="#测试消息生产和消费" class="headerlink" title="测试消息生产和消费"></a>测试消息生产和消费</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --create --zookeeper 192.168.70.13:2181 --replication-factor 1 --partitions 1 --topic test  # 创建topic  </span><br><span class="line">Created topic test.</span><br><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --list --zookeeper 192.168.70.13:2181  </span><br><span class="line">test                   # 查看创建的topic</span><br><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-console-producer.sh --broker-list 192.168.70.13:9092 --topic test </span><br><span class="line">&gt;Hello World!          # 模拟客户端发送消息(开2个终端效果会更好)</span><br><span class="line">&gt;exit</span><br><span class="line">&gt;</span><br><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-console-consumer.sh --bootstrap-server 192.168.70.13:9092 --topic test --from-beginning         </span><br><span class="line">&quot;Hello World!&quot;         # 模拟客户端接收信息 </span><br><span class="line">exit</span><br><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --delete --zookeeper 192.168.70.13:2181 --topic test             # 删除topic</span><br><span class="line">Topic test is marked for deletion.</span><br><span class="line">Note: This will have no impact if delete.topic.enable is not set to true</span><br></pre></td></tr></table></figure><h2 id="部署filebeat"><a href="#部署filebeat" class="headerlink" title="部署filebeat"></a>部署filebeat</h2><blockquote><p> 官网地址 <a href="https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.8.3-linux-x86_64.tar.gz" target="_blank" rel="noopener">filebeat-6.8.3-linux</a></p><p>下载到运维主机 /data/soft/centos7/filebeat-6.8.3-linux-x86_64.tar.gz</p></blockquote><p>解压安装包到服务器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;filebeat-6.8.3-linux-x86_64.tar.gz -O &#x2F;opt&#x2F;src&#x2F;filebeat-6.8.3-linux-x86_64.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;filebeat-6.8.3-linux-x86_64.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;filebeat-6.8.3-linux-x86_64 &#x2F;opt&#x2F;filebeat</span><br></pre></td></tr></table></figure><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;filebeat&#x2F;filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;var&#x2F;log&#x2F;messages</span><br><span class="line">  fields:</span><br><span class="line">    log_topics: syslog</span><br><span class="line">- type: log</span><br><span class="line">  enabed: true</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;data&#x2F;logs&#x2F;catalina.out</span><br><span class="line">  fields:</span><br><span class="line">    log_topics: tomcat</span><br><span class="line">output.kafka:</span><br><span class="line">  enabled: true</span><br><span class="line">  hosts: [&quot;192.168.70.13:9092&quot;,&quot;192.168.70.14:9092&quot;,&quot;192.168.70.15:9092&quot;]</span><br><span class="line">  topic: &#39;%&#123;[fields.log_topics]&#125;&#39;</span><br><span class="line">  partition.hash:</span><br><span class="line">    reachable_only: false</span><br><span class="line">  compression: gzip</span><br><span class="line">  max_message_bytes: 1000000</span><br><span class="line">  required_acks: 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>启动filebeat</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;filebeat&#x2F;filebeat -c &#x2F;opt&#x2F;filebeat&#x2F;filebeat.yml &amp;</span><br></pre></td></tr></table></figure><h3 id="测试filebeat"><a href="#测试filebeat" class="headerlink" title="测试filebeat"></a>测试filebeat</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# echo &#39;hello word!!!&#39; &gt;&gt; &#x2F;data&#x2F;logs&#x2F;catalina.out</span><br><span class="line"># 查看topic列表</span><br><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-topics.sh --list --zookeeper 192.168.70.13:2181  </span><br><span class="line">__consumer_offsets</span><br><span class="line">syslog</span><br><span class="line">test</span><br><span class="line">tomcat</span><br><span class="line"></span><br><span class="line"># 查看日志信息</span><br><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-console-consumer.sh --bootstrap-server 192.168.70.13:9092 --topic tomcat --from-beginning</span><br><span class="line">&#123;&quot;@timestamp&quot;:&quot;2020-06-18T09:31:08.887Z&quot;,&quot;@metadata&quot;:&#123;&quot;beat&quot;:&quot;filebeat&quot;,&quot;type&quot;:&quot;doc&quot;,&quot;version&quot;:&quot;6.8.3&quot;,&quot;topic&quot;:&quot;tomcat&quot;&#125;,&quot;input&quot;:&#123;&quot;type&quot;:&quot;log&quot;&#125;,&quot;beat&quot;:&#123;&quot;name&quot;:&quot;wang-13.host.com&quot;,&quot;hostname&quot;:&quot;wang-13.host.com&quot;,&quot;version&quot;:&quot;6.8.3&quot;&#125;,&quot;source&quot;:&quot;&#x2F;data&#x2F;logs&#x2F;catalina.out&quot;,&quot;log&quot;:&#123;&quot;file&quot;:&#123;&quot;path&quot;:&quot;&#x2F;data&#x2F;logs&#x2F;catalina.out&quot;&#125;&#125;,&quot;message&quot;:&quot;hello word!!!&quot;,&quot;prospector&quot;:&#123;&quot;type&quot;:&quot;log&quot;&#125;,&quot;fields&quot;:&#123;&quot;log_topics&quot;:&quot;tomcat&quot;&#125;,&quot;host&quot;:&#123;&quot;name&quot;:&quot;wang-13.host.com&quot;&#125;,&quot;offset&quot;:0&#125;</span><br></pre></td></tr></table></figure><h2 id="部署elasticsearch集群"><a href="#部署elasticsearch集群" class="headerlink" title="部署elasticsearch集群"></a>部署elasticsearch集群</h2><blockquote><p> <a href="https://www.elastic.co/" target="_blank" rel="noopener">官网</a>  <a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.8.6.tar.gz" target="_blank" rel="noopener">下载地址</a>  </p><p> 安装包下载到运维主机 /data/soft/centos7/elasticsearch-6.8.3.tar.gz</p></blockquote><h3 id="解压安装包到主机"><a href="#解压安装包到主机" class="headerlink" title="解压安装包到主机"></a>解压安装包到主机</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;elasticsearch-6.8.3.tar.gz -O &#x2F;opt&#x2F;src&#x2F;elasticsearch-6.8.3.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;elasticsearch-6.8.3.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;elasticsearch-6.8.3 &#x2F;opt&#x2F;elasticsearch</span><br><span class="line">mkdir -p &#x2F;data&#x2F;elasticsearch&#x2F;&#123;data,logs&#125;</span><br><span class="line">cd &#x2F;opt&#x2F;elasticsearch</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;elasticsearch&#x2F;config&#x2F;elasticsearch.yml </span><br><span class="line">cluster.name: ELK                                     #集群名称</span><br><span class="line">node.name: wang-13.host.com                           #节点名称</span><br><span class="line">path.data: &#x2F;data&#x2F;elasticsearch&#x2F;data                   #data存储路径</span><br><span class="line">path.logs: &#x2F;data&#x2F;elasticsearch&#x2F;logs                   #log存储路径</span><br><span class="line">network.host: 0.0.0.0                                 #监听地址</span><br><span class="line">http.port: 9200                                       #监听端口</span><br><span class="line">discovery.zen.ping.unicast.hosts: [&quot;wang-13.host.com&quot;, &quot;wang-14.host.com&quot;,&quot;wang-15.host.com&quot;]  #集群节点发现列表</span><br><span class="line">discovery.zen.minimum_master_nodes: 1                 #集群可做master的最小节点数</span><br><span class="line">node.master: true                                     #指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master</span><br><span class="line">node.data: true                                       # 指定该节点是否存储索引数据，默认为true</span><br><span class="line">transport.tcp.compress: true                          #设置是否压缩tcp传输时的数据，默认为false，不压缩</span><br><span class="line">http.cors.enabled: true                               #开启跨域访问支持，默认为false</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;                           # 跨域访问允许的域名地址</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>注意修改节点名称 node.name</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i &quot;s&amp;node.name: wang-13.host.com&amp;node.name: wang-$&#123;HOSTNUM&#125;.host.com&amp;&quot; &#x2F;opt&#x2F;elasticsearch&#x2F;config&#x2F;elasticsearch.yml </span><br></pre></td></tr></table></figure></blockquote><p>修改用户和文件描述符</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建普通用户</span><br><span class="line">useradd -s &#x2F;bin&#x2F;bash -M es</span><br><span class="line">chown -R es.es &#x2F;opt&#x2F;elasticsearch-6.8.3  &#x2F;data&#x2F;elasticsearch&#x2F;</span><br><span class="line"></span><br><span class="line"># 修改文件描述符</span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;es.conf</span><br><span class="line">es hard nofile 65536</span><br><span class="line">es soft fsize unlimited</span><br><span class="line">es hard memlock unlimited</span><br><span class="line">es soft memlock unlimited</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 调整内核参数</span><br><span class="line">sysctl -w vm.max_map_count&#x3D;262144</span><br><span class="line">echo &quot;vm.max_map_count&#x3D;262144&quot; &gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><h3 id="启动elasticsearch"><a href="#启动elasticsearch" class="headerlink" title="启动elasticsearch"></a>启动elasticsearch</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 elasticsearch]# su es -c &quot;&#x2F;opt&#x2F;elasticsearch&#x2F;bin&#x2F;elasticsearch -d&quot;</span><br><span class="line">[root@wang-13 elasticsearch]# netstat -luntp|grep 9200   </span><br><span class="line">tcp6       0      0 :::9200                 :::*                    LISTEN      50579&#x2F;java</span><br></pre></td></tr></table></figure><h3 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# curl -XGET &#39;http:&#x2F;&#x2F;localhost:9200&#x2F;_cluster&#x2F;health?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;cluster_name&quot; : &quot;ELK&quot;,</span><br><span class="line">  &quot;status&quot; : &quot;green&quot;,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;number_of_nodes&quot; : 3,</span><br><span class="line">  &quot;number_of_data_nodes&quot; : 3,</span><br><span class="line">  &quot;active_primary_shards&quot; : 0,</span><br><span class="line">  &quot;active_shards&quot; : 0,</span><br><span class="line">  &quot;relocating_shards&quot; : 0,</span><br><span class="line">  &quot;initializing_shards&quot; : 0,</span><br><span class="line">  &quot;unassigned_shards&quot; : 0,</span><br><span class="line">  &quot;delayed_unassigned_shards&quot; : 0,</span><br><span class="line">  &quot;number_of_pending_tasks&quot; : 0,</span><br><span class="line">  &quot;number_of_in_flight_fetch&quot; : 0,</span><br><span class="line">  &quot;task_max_waiting_in_queue_millis&quot; : 0,</span><br><span class="line">  &quot;active_shards_percent_as_number&quot; : 100.0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="安装head插件"><a href="#安装head插件" class="headerlink" title="安装head插件"></a>安装head插件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y git</span><br><span class="line">cd &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">git clone git:&#x2F;&#x2F;github.com&#x2F;mobz&#x2F;elasticsearch-head.git</span><br><span class="line">cd elasticsearch-head&#x2F;</span><br><span class="line">cnpm install grunt -save</span><br><span class="line">cnpm install</span><br><span class="line">npm run start &amp;</span><br></pre></td></tr></table></figure><h2 id="部署logstash"><a href="#部署logstash" class="headerlink" title="部署logstash"></a>部署logstash</h2><blockquote><p>官网地址 <a href="https://artifacts.elastic.co/downloads/logstash/logstash-6.8.3.tar.gz" target="_blank" rel="noopener">logstash-6.8.3</a></p><p>下载到运维主机 /data/soft/centos7/logstash-6.8.3.tar.gz</p></blockquote><p>解压logstash安装包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;logstash-6.8.3.tar.gz -O &#x2F;opt&#x2F;src&#x2F;logstash-6.8.3.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;logstash-6.8.3.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;logstash-6.8.3 &#x2F;opt&#x2F;logstash</span><br><span class="line">mkdir -pv &#x2F;data&#x2F;logstash&#x2F;data &#x2F;data&#x2F;logstash&#x2F;logs</span><br></pre></td></tr></table></figure><h3 id="修改logstash配置文件"><a href="#修改logstash配置文件" class="headerlink" title="修改logstash配置文件"></a>修改logstash配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;logstash&#x2F;config&#x2F;logstash.yml</span><br><span class="line">path.data: &#x2F;data&#x2F;logstash&#x2F;data</span><br><span class="line">http.host: &quot;192.168.70.13&quot;</span><br><span class="line">path.logs: &#x2F;data&#x2F;logstash&#x2F;logs</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>配置logstash从ZK将日志传入ES</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;logstash&#x2F;config&#x2F;logstash.conf</span><br><span class="line">input&#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    type &#x3D;&gt; &quot;tomcat&quot;</span><br><span class="line">    bootstrap_servers &#x3D;&gt; &quot;192.168.70.13:9092,192.168.70.14:9092,192.168.70.15:9092&quot;</span><br><span class="line">    group_id &#x3D;&gt; &quot;ecs&quot;    #logstash 集群需相同</span><br><span class="line">    topics &#x3D;&gt; [&quot;tomcat&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    type &#x3D;&gt; &quot;syslog&quot;</span><br><span class="line">    bootstrap_servers &#x3D;&gt; &quot;192.168.70.13:9092,192.168.70.14:9092,192.168.70.15:9092&quot;</span><br><span class="line">    group_id &#x3D;&gt; &quot;ecs1&quot;</span><br><span class="line">    topics &#x3D;&gt; [&quot;syslog&quot;]</span><br><span class="line">    codec &#x3D;&gt; &quot;json&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;    </span><br><span class="line">filter &#123;</span><br><span class="line">  if [type] &#x3D;&#x3D; &quot;tomcat&quot; &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">      match &#x3D;&gt; &#123; &quot;message&quot; &#x3D;&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">  if [type] &#x3D;&#x3D; &quot;tomcat&quot; &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">      hosts &#x3D;&gt; [&quot;192.168.70.13:9200&quot;,&quot;192.168.70.14:9200&quot;,&quot;192.168.70.15:9200&quot;]</span><br><span class="line">      index &#x3D;&gt; &quot;tomcat-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  if [type] &#x3D;&#x3D; &quot;syslog&quot; &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">      hosts &#x3D;&gt; [&quot;192.168.70.13:9200&quot;,&quot;192.168.70.14:9200&quot;,&quot;192.168.70.15:9200&quot;]</span><br><span class="line">      index &#x3D;&gt; &quot;syslog-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="启动logstash"><a href="#启动logstash" class="headerlink" title="启动logstash"></a>启动logstash</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;logstash&#x2F;bin&#x2F;logstash</span><br></pre></td></tr></table></figure><p>查看es索引，确认数据是否传输到es</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# curl http:&#x2F;&#x2F;192.168.70.13:9200&#x2F;_cat&#x2F;indices?v</span><br><span class="line">health status index                        uuid                   pri rep docs.count </span><br><span class="line">green  open   syslog-2020.06.18            exoYb4l2T2a2O4BarzzJRw   5   1          6            0    135.3kb         67.6kb</span><br></pre></td></tr></table></figure><h2 id="部署kibana"><a href="#部署kibana" class="headerlink" title="部署kibana"></a>部署kibana</h2><blockquote><p><a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">中文官网</a>  <a href="https://artifacts.elastic.co/downloads/kibana/kibana-6.8.3-linux-x86_64.tar.gz" target="_blank" rel="noopener">kibana-6.8.3-linux</a></p><p>下载到运维主机 /data/soft/centos7/kibana-6.8.3-linux-x86_64.tar.gz </p></blockquote><h3 id="解压kibana安转包"><a href="#解压kibana安转包" class="headerlink" title="解压kibana安转包"></a>解压kibana安转包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;doc.od.com&#x2F;soft&#x2F;centos7&#x2F;kibana-6.8.3-linux-x86_64.tar.gz -O &#x2F;opt&#x2F;src&#x2F;kibana-6.8.3-linux-x86_64.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;kibana-6.8.3-linux-x86_64.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;kibana-6.8.3-linux-x86_64 &#x2F;opt&#x2F;kibana</span><br><span class="line">mkdir -p &#x2F;data&#x2F;kibana&#x2F;logs</span><br></pre></td></tr></table></figure><h3 id="编辑配置文件-1"><a href="#编辑配置文件-1" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kibana&#x2F;config&#x2F;kibana.yml</span><br><span class="line">server.port: 5601</span><br><span class="line">server.host: &quot;192.168.70.13&quot; #内网地址</span><br><span class="line">elasticsearch.url: &quot;http:&#x2F;&#x2F;192.168.70.13:9200&quot;</span><br><span class="line">logging.dest: &#x2F;data&#x2F;kibana&#x2F;logs&#x2F;kibana.log</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="启动kibana"><a href="#启动kibana" class="headerlink" title="启动kibana"></a>启动kibana</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ~]# &#x2F;opt&#x2F;kibana&#x2F;bin&#x2F;kibana &amp;</span><br><span class="line">[root@wang-13 ~]# netstat -anput | grep 5601   </span><br><span class="line">tcp        0      0 192.168.70.13:5601      0.0.0.0:*               LISTEN      67246&#x2F;node</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;src </span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;anbai-inc&#x2F;Kibana_Hanization.git</span><br><span class="line">cd Kibana_Hanization&#x2F;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 old]# python main.py &#x2F;usr&#x2F;share&#x2F;kibana&#x2F;</span><br><span class="line">恭喜，Kibana汉化完成！</span><br></pre></td></tr></table></figure><h3 id="nginx验证登录kibana"><a href="#nginx验证登录kibana" class="headerlink" title="nginx验证登录kibana"></a>nginx验证登录kibana</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install epel-release nginx httpd-tools</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;kibana.conf</span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name kibana2.od.com;</span><br><span class="line">    auth_basic &quot;Restricted Access&quot;;</span><br><span class="line">    auth_basic_user_file &#x2F;etc&#x2F;nginx&#x2F;kibana-user;</span><br><span class="line">    access_log &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;doc.log;</span><br><span class="line"></span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;192.168.70.13:5601;</span><br><span class="line">        proxy_http_version 1.1;</span><br><span class="line">        proxy_set_header Upgrade \$http_upgrade;</span><br><span class="line">        proxy_set_header Connection &#39;upgrade&#39;;</span><br><span class="line">        proxy_set_header Host \$host;</span><br><span class="line">        proxy_cache_bypass \$http_upgrade;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>创建登陆文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-13 ～]# htpasswd -cm &#x2F;etc&#x2F;nginx&#x2F;kibana-user kibana</span><br><span class="line">New password: </span><br><span class="line">Re-type new password: </span><br><span class="line">Adding password for user kibana</span><br></pre></td></tr></table></figure><h3 id="启动nginx"><a href="#启动nginx" class="headerlink" title="启动nginx"></a>启动nginx</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br><span class="line">systemctl start nginx</span><br><span class="line">systemctl enable nginx</span><br></pre></td></tr></table></figure><h3 id="访问kibana界面"><a href="#访问kibana界面" class="headerlink" title="访问kibana界面"></a>访问kibana界面</h3><p><a href="http://kibana2.od.com" target="_blank" rel="noopener">http://kibana2.od.com</a></p><p><img src="/Users/wangzt/Library/Application%20Support/typora-user-images/image-20200618153834710.png" alt="kibana展示界面"></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> 常用软件部署 </category>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 常用软件部署 </tag>
            
            <tag> ELK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一、常用软件-nexus私服</title>
      <link href="/2020/06/16/%E4%B8%80%E3%80%81%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6-nexus%E7%A7%81%E6%9C%8D/"/>
      <url>/2020/06/16/%E4%B8%80%E3%80%81%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6-nexus%E7%A7%81%E6%9C%8D/</url>
      
        <content type="html"><![CDATA[<h3 id="Nexus介绍"><a href="#Nexus介绍" class="headerlink" title="Nexus介绍"></a>Nexus介绍</h3><p>　　<a href="http://nexus.sonatype.org/" target="_blank" rel="noopener">Nexus</a> 是Maven仓库管理器，如果你使用Maven，你可以从<a href="http://repo1.maven.org/maven2/" target="_blank" rel="noopener">Maven中央仓库</a> 下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，Nexus  还可以在代理远程仓库的同时维护本地仓库，以降低中央仓库的负荷，节省外网带宽和时间。</p><p>​        Nexus 是“开箱即用”的系统，不需要数据库，它使用文件系统加 Lucene 来组织数据，支持 WebDAV 与 LDAP  安全身份认证。Nexus 还提供了强大的仓库管理功能，构件搜索功能，它基于 REST，友好的 UI 是一个 extjs 的 REST  客户端，它占用较少的内存，基于简单文件系统而非数据库。Nexus 极大地简化了本地内部仓库的维护和外部仓库的访问。</p><h4 id="Nexus3-x-和-2-x-版本比较"><a href="#Nexus3-x-和-2-x-版本比较" class="headerlink" title="Nexus3.x 和 2.x 版本比较"></a>Nexus3.x 和 2.x 版本比较</h4><p>本篇 Nexus 选择 3.x 版本，Nexus3.x 相较 2.x 版本有很大的改变：</p><p>1）从底层重构，从而提高性能，增强扩展能力，并改善用户体验<br>2）升级界面，增加更多的浏览，搜索和管理功能<br>3）提供安装包，使部署更简单（安装完自动添加成服务，省去手动添加的麻烦）<br>4）增加 Docker，NuGet，npm，Bower的支持<br>5）提供新的管理接口，从而能自动管理任务。<br>注意：3.x版本只能运行在JVM8及以上</p><h4 id="本地构建nexus私服优势"><a href="#本地构建nexus私服优势" class="headerlink" title="本地构建nexus私服优势"></a>本地构建nexus私服优势</h4><p>本地内部仓库在本地构建nexus私服的好处有：</p><p>1）加速构建、稳定；<br>2）节省带宽、节省中央maven仓库的带宽；<br>3）控制和审计；<br>4）能够部署第三方构件；<br>5）可以建立本地内部仓库、可以建立公共仓库</p><h3 id="Nexus部署"><a href="#Nexus部署" class="headerlink" title="Nexus部署"></a>Nexus部署</h3><blockquote><p>nexus下载地址1: <a href="https://www.sonatype.com/download-oss-sonatype" target="_blank" rel="noopener">https://www.sonatype.com/download-oss-sonatype</a> (国内似乎打不开)</p><p>nexus下载地址2.<a href="https://help.sonatype.com/repomanager3/download/download-archives---repository-manager-3" target="_blank" rel="noopener">https://help.sonatype.com/repomanager3/download/download-archives---repository-manager-3</a></p><p>下载地址 <a href="http://download.sonatype.com/nexus/3/nexus-3.22.1-02-unix.tar.gz" target="_blank" rel="noopener">nexus-3.22.1-02-unix.tar.gz</a> 2020-04-16发布</p></blockquote><h4 id="解压nexus"><a href="#解压nexus" class="headerlink" title="解压nexus"></a>解压nexus</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;nexus-3.22.1-02-unix.tar.gz &#x2F;opt&#x2F;src&#x2F; </span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;nexus-3.22.1-02-unix.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;nexus-3.22.1-02 &#x2F;opt&#x2F;nexus</span><br><span class="line">ln -s &#x2F;opt&#x2F;nexus&#x2F;bin&#x2F;nexus &#x2F;etc&#x2F;init.d&#x2F;nexus</span><br><span class="line">cd &#x2F;opt&#x2F;nexus&#x2F;</span><br></pre></td></tr></table></figure><h4 id="用ROOT用户启动nexus"><a href="#用ROOT用户启动nexus" class="headerlink" title="用ROOT用户启动nexus"></a>用ROOT用户启动nexus</h4><p>可使用两个命令启动①./nexus start ②./nexus run(初次启动建议使用此命令,会显示启动日志)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@ikj-141 nexus]# vim bin&#x2F;nexus.rc </span><br><span class="line">run_as_user&#x3D;&quot;root&quot;</span><br><span class="line">[root@ikj-141 nexus]# bin&#x2F;nexus run</span><br><span class="line">2020-06-12 14:01:49,100+0800 INFO  [jetty-main-1] *SYSTEM org.eclipse.jetty.server.Server - Started @143576ms</span><br><span class="line">2020-06-12 14:01:49,101+0800 INFO  [jetty-main-1] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - </span><br><span class="line">-------------------------------------------------</span><br><span class="line"></span><br><span class="line">Started Sonatype Nexus OSS 3.22.1-02</span><br><span class="line"></span><br><span class="line">-------------------------------------------------</span><br></pre></td></tr></table></figure><h4 id="登陆nexus"><a href="#登陆nexus" class="headerlink" title="登陆nexus"></a>登陆nexus</h4><p>访问：<a href="http://localhost:8081/" target="_blank" rel="noopener">http://localhost:8081/</a></p><p>使用Nexus 内置账户admin/admin123登陆：</p><p>点击右上角的Log in，输入账号和密码 登陆，如果登陆失败，注意提示密码在文件/opt/sonatype-work/nexus3/admin.password里</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfph49cxqnj31860degms.jpg" alt="image-20200612140858036"></p><p><strong>第一步：帮助向导</strong> This wizard will help you complete required setup tasks.</p><p><strong>第二步：修改密码</strong>（Please choose a password for the admin user）</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfphcs8pz2j31as0cejsi.jpg" alt="修改密码"></p><p><strong>第三部：配置免密访问</strong> Configure Anonymous Access</p><p>我设置的是不允许，因为有公司的代码，可以根据自己的需要</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfv4ogx6vtj31dy0d8gnl.jpg" alt="配置免密访问"></p><p><strong>第四步：安装结束</strong> The setup tasks have been completed, enjoy using Nexus Repository Manager!</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfv4og0iv4j31o80kqjug.jpg" alt="image-20200612144114692"></p><h3 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h3><p>创建本地用户</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfpk6t4pegj320r0u045y.jpg" alt="image-20200612155508580"></p><p>填写用户信息</p><p>![image-20200612155733411](/Users/wangzt/Library/Application Support/typora-user-images/image-20200612155733411.png)</p><p>Grant 可以选择用户权限：</p><ul><li>nx-admin – 管理员权限</li><li>nx-anonymous – 无差别用户权限，无法看到设置图标并且无法进入设置页面</li></ul><h3 id="Nexus仓库类型介绍"><a href="#Nexus仓库类型介绍" class="headerlink" title="Nexus仓库类型介绍"></a>Nexus仓库类型介绍</h3><ul><li>hosted，本地仓库，通常我们会部署自己的构件到这一类型的仓库。比如公司的第二方库。</li></ul><ul><li>proxy，代理仓库，它们被用来代理远程的公共仓库，如maven中央仓库。</li></ul><ul><li>group，仓库组，用来合并多个hosted/proxy仓库，当你的项目希望在多个repository使用资源时就不需要多次引用了，只需要引用一个group即可。</li></ul><h4 id="管理本地仓库"><a href="#管理本地仓库" class="headerlink" title="管理本地仓库"></a>管理本地仓库</h4><p>我们前面讲到类型为hosted的为本地仓库，Nexus预定义了3个本地仓库，分别是Releases, Snapshots, 3rd Party. 分别讲一下这三个预置的仓库都是做什么用的:</p><p><strong>Releases:</strong> 这里存放我们自己项目中发布的构建, 通常是Release版本的, 比如我们自己做了一个FTP Server的项目, 生成的构件为ftpserver.war, 我们就可以把这个构建发布到Nexus的Releases本地仓库. 关于符合发布后面会有介绍.</p><p><strong>Snapshots:</strong>这个仓库非常的有用, 它的目的是让我们可以发布那些非release版本, 非稳定版本,  比如我们在trunk下开发一个项目,在正式release之前你可能需要临时发布一个版本给你的同伴使用, 因为你的同伴正在依赖你的模块开发,  那么这个时候我们就可以发布Snapshot版本到这个仓库, 你的同伴就可以通过简单的命令来获取和使用这个临时版本.</p><p><strong>3rd Party:</strong>顾名思义, 第三方库, 你可能会问不是有中央仓库来管理第三方库嘛,没错, 这里的是指可以让你添加自己的第三方库, 比如有些构件在中央仓库是不存在的. 比如你在中央仓库找不到Oracle 的JDBC驱动, 这个时候我们就需要自己添加到3rdparty仓库。 </p><h3 id="创建仓库"><a href="#创建仓库" class="headerlink" title="创建仓库"></a>创建仓库</h3><p>添加Repositories仓库</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfpk49nt3oj31ul0u0qcm.jpg" alt="image-20200612152955528"></p><p>这里我们有三种 maven 仓库可选</p><p><img src="https://techlog.cn/article/list/images/c6700184e7c325ad24bb34260125342b.png?id=3378041&v=1" alt="img"></p><p>他们的区别是：</p><ol><li>proxy – 远程仓库的代理，当用户向这个仓库请求一个 artifact，他会先在本地查找，如果找不到的话，就会从远程仓库下载，然后返回给用户</li><li>hosted – 宿主仓库，用户可以 deploy 到 hosted 中，也可以手工上传构件到 hosted 里，在 central repository 是获取不到的，就需要手工上传到hosted里</li><li>group – 仓库组，在 maven 里没有这个概念，是 nexus 特有的。目的是将上述多个仓库聚合，对用户暴露统一的地址</li></ol><h4 id="创建-hosted-仓库"><a href="#创建-hosted-仓库" class="headerlink" title="创建 hosted 仓库"></a>创建 hosted 仓库</h4><p>这里我们创建两个 hosted 仓库</p><p><img src="https://techlog.cn/article/list/images/de32d62ee9699b8bc2966779534493c6.png?id=3378042&v=1" alt="img"></p><p><img src="https://techlog.cn/article/list/images/166263a194b8082adcccd0095f72bc83.png?id=3378043&v=2" alt="img"></p><p>他们分别用来管理正式版 jar 包和 SNAPSHOT 包，区别在于是否允许重复上传</p><h4 id="上传到nexus私服"><a href="#上传到nexus私服" class="headerlink" title="上传到nexus私服"></a>上传到nexus私服</h4><ol><li>修改Maven的settings.xml文件，加入认证机制</li></ol><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;settings xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0&quot;</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0</span><br><span class="line">https:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;settings-1.0.0.xsd&quot;&gt;</span><br><span class="line">&lt;servers&gt;</span><br><span class="line">&lt;server&gt;</span><br><span class="line">&lt;id&gt;releases&lt;&#x2F;id&gt;</span><br><span class="line">&lt;username&gt;admin&lt;&#x2F;username&gt;</span><br><span class="line">&lt;password&gt;admin123&lt;&#x2F;password&gt;</span><br><span class="line">&lt;&#x2F;server&gt;</span><br><span class="line">&lt;server&gt;</span><br><span class="line">&lt;id&gt;snapshots&lt;&#x2F;id&gt;</span><br><span class="line">&lt;username&gt;admin&lt;&#x2F;username&gt;</span><br><span class="line">&lt;password&gt;admin123&lt;&#x2F;password&gt;</span><br><span class="line">&lt;&#x2F;server&gt;</span><br><span class="line">&lt;&#x2F;servers&gt;</span><br><span class="line">&lt;&#x2F;settings&gt;</span><br></pre></td></tr></table></figure><p><strong>配置 pom.xml</strong></p><p>我们创建一个项目，然后配置 pom.xml</p><p>最重要的是 distributionManagement 节点的配置，引用我们在 settings.xml 中配置的 nexus 私服 id</p><p>配置中的 url 通过下图按钮处点击获取即可</p><p><img src="https://techlog.cn/article/list/images/5be309fcea685ded58269e1e43450dc3.png?id=3378045&v=1" alt="img"></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;distributionManagement&gt;</span><br><span class="line">&lt;repository&gt;</span><br><span class="line">&lt;id&gt;releases&lt;&#x2F;id&gt;</span><br><span class="line">&lt;name&gt;Release Repository&lt;&#x2F;name&gt;</span><br><span class="line">&lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;java&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;repository&gt;</span><br><span class="line">&lt;snapshotRepository&gt;</span><br><span class="line">&lt;id&gt;snapshots&lt;&#x2F;id&gt;</span><br><span class="line">&lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;java&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;snapshotRepository&gt;</span><br><span class="line">&lt;&#x2F;distributionManagement&gt;</span><br></pre></td></tr></table></figure><p><strong>打包上传</strong></p><p>接下来我们执行 mvn deploy -e 就可以实现打包上传了</p><p>通过页面，我们可以看到已经上传成功</p><p><img src="https://techlog.cn/article/list/images/604cbeffc7beebc5fefdaed563585d39.png?id=3378044&v=1" alt="img"></p><h4 id="创建repository仓库"><a href="#创建repository仓库" class="headerlink" title="创建repository仓库"></a>创建repository仓库</h4><p>添加repository仓库ali, 路径为 <a href="https://maven.aliyun.com/repository/public" target="_blank" rel="noopener">https://maven.aliyun.com/repository/public</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfv4vbit3mj31fg0u0k1p.jpg" alt="添加repository仓库ali"></p><p>如果需要认证，我们还要配置http认证</p><p><strong><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfv4vgxotxj317807iq37.jpg" alt="配置http认证"></strong></p><h3 id="创建仓库组group"><a href="#创建仓库组group" class="headerlink" title="创建仓库组group"></a>创建仓库组group</h3><p>将仓库放入仓库组中，我们就不需要修改配置了，且可以集中管理</p><p>创建三个仓库组group：public; releases; snapshots</p><ul><li><a href="http://localhost:8081/repository/public/" target="_blank" rel="noopener">http://localhost:8081/repository/public/</a></li></ul><ul><li><a href="http://localhost:8081/repository/releases/" target="_blank" rel="noopener">http://localhost:8081/repository/releases/</a></li></ul><ul><li><a href="http://localhost:8081/repository/snapshots/" target="_blank" rel="noopener">http://localhost:8081/repository/snapshots/</a></li></ul><p>添加组public,另外两个类似</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfv4zfto4fj319y0u0wnd.jpg" alt="添加组public"></p><h3 id="使用mvn构建"><a href="#使用mvn构建" class="headerlink" title="使用mvn构建"></a>使用mvn构建</h3><p>配置.m2/settings.xml 就可以使用mvn了</p><p>这里是一个完整的例子，注意自己修改地址</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;settings xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">          xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;settings-1.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;mirrors&gt;</span><br><span class="line">        &lt;mirror&gt;</span><br><span class="line">            &lt;id&gt;mirror&lt;&#x2F;id&gt;</span><br><span class="line">            &lt;mirrorOf&gt;!snapshots,!releases&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">            &lt;name&gt;mirror&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;public&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">        &lt;&#x2F;mirror&gt;</span><br><span class="line">    &lt;&#x2F;mirrors&gt;</span><br><span class="line">    &lt;servers&gt;</span><br><span class="line">        &lt;server&gt;</span><br><span class="line">            &lt;id&gt;central&lt;&#x2F;id&gt;</span><br><span class="line">            &lt;username&gt;user&lt;&#x2F;username&gt;</span><br><span class="line">            &lt;password&gt;user123&lt;&#x2F;password&gt;</span><br><span class="line">        &lt;&#x2F;server&gt;</span><br><span class="line">        &lt;server&gt;</span><br><span class="line">            &lt;id&gt;releases&lt;&#x2F;id&gt;</span><br><span class="line">            &lt;username&gt;user&lt;&#x2F;username&gt;</span><br><span class="line">            &lt;password&gt;user123&lt;&#x2F;password&gt;</span><br><span class="line">        &lt;&#x2F;server&gt;</span><br><span class="line">&lt;server&gt;</span><br><span class="line">            &lt;id&gt;snapshots&lt;&#x2F;id&gt;</span><br><span class="line">            &lt;username&gt;user&lt;&#x2F;username&gt;</span><br><span class="line">            &lt;password&gt;user123&lt;&#x2F;password&gt;</span><br><span class="line">        &lt;&#x2F;server&gt;</span><br><span class="line">    &lt;&#x2F;servers&gt;</span><br><span class="line">    &lt;profiles&gt;</span><br><span class="line">        &lt;profile&gt;</span><br><span class="line">            &lt;id&gt;nexus&lt;&#x2F;id&gt;</span><br><span class="line">            &lt;repositories&gt;</span><br><span class="line">                &lt;repository&gt;</span><br><span class="line">                    &lt;id&gt;central&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;public&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">                    &lt;releases&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;releases&gt;</span><br><span class="line">                    &lt;snapshots&gt;</span><br><span class="line">                        &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;snapshots&gt;</span><br><span class="line">                &lt;&#x2F;repository&gt;</span><br><span class="line">                &lt;repository&gt;</span><br><span class="line">                    &lt;id&gt;releases&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;releases&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">                    &lt;releases&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;releases&gt;</span><br><span class="line">                    &lt;snapshots&gt;</span><br><span class="line">                        &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;snapshots&gt;</span><br><span class="line">                &lt;&#x2F;repository&gt;</span><br><span class="line">                &lt;repository&gt;</span><br><span class="line">                    &lt;id&gt;snapshots&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;snapshots&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">                    &lt;releases&gt;</span><br><span class="line">                        &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;releases&gt;</span><br><span class="line">                    &lt;snapshots&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                        &lt;updatePolicy&gt;always&lt;&#x2F;updatePolicy&gt;</span><br><span class="line">                    &lt;&#x2F;snapshots&gt;</span><br><span class="line">                &lt;&#x2F;repository&gt;</span><br><span class="line">            &lt;&#x2F;repositories&gt;</span><br><span class="line">            &lt;pluginRepositories&gt;</span><br><span class="line">                &lt;pluginRepository&gt;</span><br><span class="line">                    &lt;id&gt;central&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;public&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">                    &lt;releases&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;releases&gt;</span><br><span class="line">                    &lt;snapshots&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;snapshots&gt;</span><br><span class="line">                &lt;&#x2F;pluginRepository&gt;</span><br><span class="line">                &lt;pluginRepository&gt;</span><br><span class="line">                    &lt;id&gt;releases&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;releases&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">                    &lt;releases&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;releases&gt;</span><br><span class="line">                    &lt;snapshots&gt;</span><br><span class="line">                        &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;snapshots&gt;</span><br><span class="line">                &lt;&#x2F;pluginRepository&gt;</span><br><span class="line">                &lt;pluginRepository&gt;</span><br><span class="line">                    &lt;id&gt;snapshots&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;snapshots&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">                    &lt;releases&gt;</span><br><span class="line">                        &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">                    &lt;&#x2F;releases&gt;</span><br><span class="line">                    &lt;snapshots&gt;</span><br><span class="line">                        &lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">                        &lt;updatePolicy&gt;always&lt;&#x2F;updatePolicy&gt;</span><br><span class="line">                    &lt;&#x2F;snapshots&gt;</span><br><span class="line">                &lt;&#x2F;pluginRepository&gt;</span><br><span class="line">            &lt;&#x2F;pluginRepositories&gt;</span><br><span class="line">        &lt;&#x2F;profile&gt;</span><br><span class="line">    &lt;&#x2F;profiles&gt;</span><br><span class="line">    &lt;activeProfiles&gt;</span><br><span class="line">        &lt;activeProfile&gt;nexus&lt;&#x2F;activeProfile&gt;</span><br><span class="line">    &lt;&#x2F;activeProfiles&gt;</span><br><span class="line">&lt;&#x2F;settings&gt;</span><br></pre></td></tr></table></figure><p>这样，你就可以通过 mvn clean install 命令引用第三方和公司本地jar包了</p><h3 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h3><p>​        说实话，nexus部署和使用挺简单的，但是因为以前对其操作少，都是拿来就用，所以理解不深。通过此次部署，对其jar包的引用顺序更深刻了。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>​        感谢 龙潭斋 <a href="https://techlog.cn/article/list/10183220" target="_blank" rel="noopener">详解通过 Nexus3.x 搭建 Maven 私服</a></p><p>​        感谢 nexus官网 <a href="https://help.sonatype.com/repomanager3" target="_blank" rel="noopener">repomanager3使用文档</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> 常用软件部署 </category>
          
          <category> nexus私服 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 常用软件部署 </tag>
            
            <tag> nexus私服 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>五、生态-elk收集系统日志</title>
      <link href="/2020/06/10/%E4%BA%94%E3%80%81%E7%94%9F%E6%80%81-elk%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97/"/>
      <url>/2020/06/10/%E4%BA%94%E3%80%81%E7%94%9F%E6%80%81-elk%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<p><strong>特别鸣谢</strong> </p><p>​        filebeat 梦轻尘 <a href="https://www.cnblogs.com/uglyliu/p/12382214.html" target="_blank" rel="noopener">利用 Log-Pilot + Kafka+Elasticsearch + Kibana 搭建 kubernetes日志解决方案</a></p><p>​        国内镜像源 天凉好个秋  <a href="https://www.jianshu.com/p/9e291ca4d16d" target="_blank" rel="noopener">CentOS yum、docker、alpine apk、maven 国内镜像源</a></p><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn8lzlosbj310h0hxq5r.jpg" alt="elk架构图"></p><h2 id="部署elasticsearch"><a href="#部署elasticsearch" class="headerlink" title="部署elasticsearch"></a>部署elasticsearch</h2><blockquote><p> <a href="https://www.elastic.co/" target="_blank" rel="noopener">官网</a>  <a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.8.6.tar.gz" target="_blank" rel="noopener">下载地址</a></p></blockquote><h3 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget -o &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;elasticsearch-6.8.3.tar.gz https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;elasticsearch&#x2F;elasticsearch-6.8.3.tar.gz</span><br></pre></td></tr></table></figure><p>在wang-12上解压elasticsearch</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;elasticsearch-6.8.3.tar.gz &#x2F;opt&#x2F;src&#x2F;elasticsearch-6.8.3.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;elasticsearch-6.8.3.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;elasticsearch-6.8.3 &#x2F;opt&#x2F;elasticsearch</span><br><span class="line">mkdir -p &#x2F;data&#x2F;elasticsearch&#x2F;&#123;data,logs&#125;</span><br><span class="line">cd &#x2F;opt&#x2F;elasticsearch</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; config&#x2F;elasticsearch.yml</span><br><span class="line">cluster.name: es.od.com</span><br><span class="line">node.name: wang-12.host.com</span><br><span class="line">path.data: &#x2F;data&#x2F;elasticsearch&#x2F;data</span><br><span class="line">path.logs: &#x2F;data&#x2F;elasticsearch&#x2F;logs</span><br><span class="line">bootstrap.memory_lock: true</span><br><span class="line">network.host: 192.168.70.12</span><br><span class="line">http.port: 9200</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>修改jvm</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 elasticsearch]# vim config&#x2F;jvm.options </span><br><span class="line">-Xms512m  # 根据环境设置，-Xms和-Xmx设置为相同的值，推荐设置为机器内存的一半左右 </span><br><span class="line">-Xmx512m</span><br></pre></td></tr></table></figure><h3 id="创建普通用户"><a href="#创建普通用户" class="headerlink" title="创建普通用户"></a>创建普通用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">useradd -s &#x2F;bin&#x2F;bash -M es</span><br><span class="line">chown -R es.es &#x2F;opt&#x2F;elasticsearch-6.8.3  &#x2F;data&#x2F;elasticsearch&#x2F;</span><br></pre></td></tr></table></figure><p>文件描述符</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;es.conf</span><br><span class="line">es hard nofile 65536</span><br><span class="line">es soft fsize unlimited</span><br><span class="line">es hard memlock unlimited</span><br><span class="line">es soft memlock unlimited</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>调整内核参数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -w vm.max_map_count&#x3D;262144</span><br><span class="line">echo &quot;vm.max_map_count&#x3D;262144&quot; &gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><h3 id="启动es"><a href="#启动es" class="headerlink" title="启动es"></a>启动es</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 elasticsearch]# su es -c &quot;&#x2F;opt&#x2F;elasticsearch&#x2F;bin&#x2F;elasticsearch -d&quot; </span><br><span class="line">[root@wang-12 elasticsearch]# netstat -luntp|grep 9200</span><br><span class="line">tcp6       0      0 192.168.70.12:9200      :::*                    LISTEN      124790&#x2F;java</span><br></pre></td></tr></table></figure><h3 id="调整ES日志模板"><a href="#调整ES日志模板" class="headerlink" title="调整ES日志模板"></a>调整ES日志模板</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &quot;Content-Type:application&#x2F;json&quot; -XPUT http:&#x2F;&#x2F;192.168.70.12:9200&#x2F;_template&#x2F;k8s -d &#39;&#123;</span><br><span class="line"> &quot;template&quot; : &quot;k8s*&quot;,</span><br><span class="line"> &quot;index_patterns&quot;: [&quot;k8s*&quot;], </span><br><span class="line"> &quot;settings&quot;: &#123;</span><br><span class="line">  &quot;number_of_shards&quot;: 5,</span><br><span class="line">  &quot;number_of_replicas&quot;: 0    </span><br><span class="line"> &#125;</span><br><span class="line">&#125;&#39;</span><br><span class="line"></span><br><span class="line"># 返回值 &#123;&quot;acknowledged&quot;:true&#125;</span><br></pre></td></tr></table></figure><blockquote><p>“number_of_replicas”: 0 生产为3份副本集，本es为单节点，不能配置副本集</p></blockquote><h2 id="部署Kafka"><a href="#部署Kafka" class="headerlink" title="部署Kafka"></a>部署Kafka</h2><p>在运维主机下载kafaka</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;kafka&#x2F;2.2.0&#x2F;kafka_2.12-2.2.0.tgz -O &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;kafka_2.12-2.2.0.tgz</span><br></pre></td></tr></table></figure><p>在wang-11解压kafaka</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;kafka_2.12-2.2.0.tgz &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;kafka_2.12-2.2.0.tgz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;kafka_2.12-2.2.0&#x2F; &#x2F;opt&#x2F;kafka</span><br><span class="line">mkdir &#x2F;data&#x2F;kafka&#x2F;logs -p</span><br><span class="line">cd &#x2F;opt&#x2F;kafka</span><br></pre></td></tr></table></figure><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 kafka]# vim config&#x2F;server.properties</span><br><span class="line">log.dirs&#x3D;&#x2F;data&#x2F;kafka&#x2F;logs</span><br><span class="line">zookeeper.connect&#x3D;localhost:2181    # zk消息队列地址 </span><br><span class="line">log.flush.interval.messages&#x3D;10000</span><br><span class="line">log.flush.interval.ms&#x3D;1000</span><br><span class="line"># 最后两行追加</span><br><span class="line">delete.topic.enable&#x3D;true</span><br><span class="line">host.name&#x3D;wang-11.host.com</span><br></pre></td></tr></table></figure><h3 id="启动Kafka"><a href="#启动Kafka" class="headerlink" title="启动Kafka"></a>启动Kafka</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 kafka]# bin&#x2F;kafka-server-start.sh -daemon config&#x2F;server.properties</span><br><span class="line">[root@wang-11 kafka]# netstat -luntp|grep 9092</span><br><span class="line">tcp6       0      0 192.168.70.11:9092      :::*                    LISTEN      110908&#x2F;java</span><br></pre></td></tr></table></figure><h2 id="部署kafka-manager"><a href="#部署kafka-manager" class="headerlink" title="部署kafka-manager"></a>部署kafka-manager</h2><blockquote><p><a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="noopener">官方github地址</a></p></blockquote><h3 id="准备镜像"><a href="#准备镜像" class="headerlink" title="准备镜像"></a>准备镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull sheepkiller&#x2F;kafka-manager:latest</span><br><span class="line">docker tag 4e4a8c5dabab harbor.od.com&#x2F;infra&#x2F;kafka-manager:latest</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;kafka-manager:latest</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单"><a href="#准备资源配置清单" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建资源配置清单文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kafka-manager</span><br></pre></td></tr></table></figure><p><strong>deploy.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kafka-manager&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: kafka-manager</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: kafka-manager</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: kafka-manager</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: kafka-manager</span><br><span class="line">        name: kafka-manager</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kafka-manager</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;kafka-manager:latest</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">        - name: ZK_HOSTS</span><br><span class="line">          value: zk1.od.com:2181</span><br><span class="line">        - name: APPLICATION_SECRET</span><br><span class="line">          value: letmein</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>svc.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kafka-manager&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: kafka-manager</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 9000</span><br><span class="line">    targetPort: 9000</span><br><span class="line">  selector: </span><br><span class="line">    app: kafka-manager</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>ingress.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kafka-manager&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: kafka-manager</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: km.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: kafka-manager</span><br><span class="line">          servicePort: 9000</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单"><a href="#应用资源配置清单" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kafka-manager&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kafka-manager&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kafka-manager&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><h3 id="web界面管理"><a href="#web界面管理" class="headerlink" title="web界面管理"></a>web界面管理</h3><p><a href="http://km.od.com/" target="_blank" rel="noopener">http://km.od.com/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmyhj8ku6j31cg0h6q4m.jpg" alt="kafka-manager展示界面"></p><p>添加集群</p><p>名称：kafka-od,     地址：zk1.od.com:2181</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmyobsqnzj31ey0lgtag.jpg" alt="添加集群"></p><p>查看集群kafka-od信息</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmys345e1j31he0kmwgc.jpg" alt="集群kafka-od信息"></p><h2 id="部署filebeat"><a href="#部署filebeat" class="headerlink" title="部署filebeat"></a>部署filebeat</h2><h3 id="下载镜像-二选一"><a href="#下载镜像-二选一" class="headerlink" title="下载镜像(二选一)"></a>下载镜像(二选一)</h3><blockquote><p>github地址：<a href="https://github.com/AliyunContainerService/log-pilot" target="_blank" rel="noopener">https://github.com/AliyunContainerService/log-pilot</a> </p><p>log-pilot官方介绍：<a href="https://yq.aliyun.com/articles/674327" target="_blank" rel="noopener">https://yq.aliyun.com/articles/674327</a> </p><p>log-pilot官方搭建：<a href="https://yq.aliyun.com/articles/674361?spm=a2c4e.11153940.0.0.21ae21c3mTKwWS" target="_blank" rel="noopener">https://yq.aliyun.com/articles/674361?spm=a2c4e.11153940.0.0.21ae21c3mTKwWS</a> </p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com&#x2F;acs&#x2F;log-pilot:0.9.7-filebeat</span><br><span class="line">docker tag 10a688e1229a harbor.od.com&#x2F;public&#x2F;log-pilot:0.9.7-filebeat</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;log-pilot:0.9.7-filebeat</span><br></pre></td></tr></table></figure><h3 id="自定义镜像-推荐，二选一"><a href="#自定义镜像-推荐，二选一" class="headerlink" title="自定义镜像(推荐，二选一)"></a>自定义镜像(推荐，二选一)</h3><p>修改log-pilot源码使其可以收集多行日志(以日期开头，刑如2020-02-29)</p><h4 id="拉取master的代码"><a href="#拉取master的代码" class="headerlink" title="拉取master的代码"></a>拉取master的代码</h4><p>一开始用的分支v0.9.5，但是报错了，没出结果</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data&#x2F;soft&#x2F;docker</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;AliyunContainerService&#x2F;log-pilot.git</span><br><span class="line">cd log-pilot</span><br><span class="line">git tag</span><br><span class="line"># git checkout v0.9.5  #指定v0.9.5这个版本</span><br></pre></td></tr></table></figure><h4 id="修改filebeat模板"><a href="#修改filebeat模板" class="headerlink" title="修改filebeat模板"></a>修改filebeat模板</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 log-pilot]# vim assets&#x2F;filebeat&#x2F;filebeat.tpl</span><br><span class="line"></span><br><span class="line">&#123;&#123;range .configList&#125;&#125;</span><br><span class="line">- type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">      - &#123;&#123; .HostDir &#125;&#125;&#x2F;&#123;&#123; .File &#125;&#125;</span><br><span class="line">  multiline.pattern: &#39;^[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]&#39; #新增正则条件，以日期开头</span><br><span class="line">  multiline.negate: true                                           #新增</span><br><span class="line">  multiline.match: after                                           #新增</span><br><span class="line">  multiline.max_lines: 10000                                       #新增</span><br><span class="line">  scan_frequency: 10s</span><br><span class="line">  fields_under_root: true</span><br><span class="line">  &#123;&#123;if .Stdout&#125;&#125;</span><br><span class="line">  docker-json: true</span><br><span class="line">  &#123;&#123;end&#125;&#125;</span><br><span class="line">  &#123;&#123;if eq .Format &quot;json&quot;&#125;&#125;</span><br><span class="line">  json.keys_under_root: true</span><br><span class="line">  &#123;&#123;end&#125;&#125;</span><br><span class="line">  fields:</span><br><span class="line">      &#123;&#123;range $key, $value :&#x3D; .Tags&#125;&#125;</span><br><span class="line">      &#123;&#123; $key &#125;&#125;: &#123;&#123; $value &#125;&#125;</span><br><span class="line">      &#123;&#123;end&#125;&#125;</span><br><span class="line">      &#123;&#123;range $key, $value :&#x3D; $.container&#125;&#125;</span><br><span class="line">      &#123;&#123; $key &#125;&#125;: &#123;&#123; $value &#125;&#125;</span><br><span class="line">      &#123;&#123;end&#125;&#125;</span><br><span class="line">  tail_files: false</span><br><span class="line">  close_inactive: 2h</span><br><span class="line">  close_eof: false</span><br><span class="line">  close_removed: true</span><br><span class="line">  clean_removed: true</span><br><span class="line">  close_renamed: false</span><br><span class="line"></span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure><h4 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i &quot;s&amp;log-pilot:latest&amp;harbor.od.com&#x2F;infra&#x2F;log-pilot:v1.0.1-filebeat&amp;&quot; build-image.sh</span><br><span class="line"># sed -i &quot;s&amp;apk update&amp;sed -i &#39;s&#x2F;dl-cdn.alpinelinux.org&#x2F;mirrors.aliyun.com&#x2F;g&#39; &#x2F;etc&#x2F;apk&#x2F;repositories \&amp;\&amp; apk update&amp;&quot; Dockerfile.filebeat </span><br><span class="line">.&#x2F;build-image.sh</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;log-pilot:v1.0.1-filebeat</span><br><span class="line"></span><br><span class="line">kubectl create secret docker-registry harbor --docker-server&#x3D;harbor.od.com --docker-username&#x3D;harbor --docker-password&#x3D;Harbo12345 -n kube-system</span><br></pre></td></tr></table></figure><h3 id="配置资源清单"><a href="#配置资源清单" class="headerlink" title="配置资源清单"></a>配置资源清单</h3><p>创建文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;log-pilot</span><br></pre></td></tr></table></figure><p><strong>ds.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;log-pilot&#x2F;ds.yaml</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: log-pilot</span><br><span class="line">  labels:</span><br><span class="line">    app: log-pilot</span><br><span class="line">  # 设置期望部署的namespace</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: log-pilot</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">    spec:</span><br><span class="line">      # 是否允许部署到Master节点上</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: node-role.kubernetes.io&#x2F;master</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      containers:</span><br><span class="line">      - name: log-pilot</span><br><span class="line">        # 版本请参考https:&#x2F;&#x2F;github.com&#x2F;AliyunContainerService&#x2F;log-pilot&#x2F;releases</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;log-pilot:v1.0.1-filebeat</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 500Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 200m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        env:</span><br><span class="line">          - name: &quot;NODE_NAME&quot;</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: spec.nodeName</span><br><span class="line">          - name: &quot;LOGGING_OUTPUT&quot;</span><br><span class="line">            value: &quot;kafka&quot;</span><br><span class="line">          - name: &quot;KAFKA_BROKERS&quot;</span><br><span class="line">            value: &quot;192.168.70.11:9092&quot;</span><br><span class="line">          - name: &quot;NODE_NAME&quot;</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: spec.nodeName</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: sock</span><br><span class="line">          mountPath: &#x2F;var&#x2F;run&#x2F;docker.sock</span><br><span class="line">        - name: root</span><br><span class="line">          mountPath: &#x2F;host</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: varlib</span><br><span class="line">          mountPath: &#x2F;var&#x2F;lib&#x2F;filebeat</span><br><span class="line">        - name: varlog</span><br><span class="line">          mountPath: &#x2F;var&#x2F;log&#x2F;filebeat</span><br><span class="line">        - name: localtime</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;localtime</span><br><span class="line">          readOnly: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          exec:</span><br><span class="line">            command:</span><br><span class="line">            - &#x2F;pilot&#x2F;healthz</span><br><span class="line">          initialDelaySeconds: 10</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          timeoutSeconds: 2</span><br><span class="line">        securityContext:</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - SYS_ADMIN</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: sock</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;run&#x2F;docker.sock</span><br><span class="line">      - name: root</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;</span><br><span class="line">      - name: varlib</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;lib&#x2F;filebeat</span><br><span class="line">          type: DirectoryOrCreate</span><br><span class="line">      - name: varlog</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;log&#x2F;filebeat</span><br><span class="line">          type: DirectoryOrCreate</span><br><span class="line">      - name: localtime</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;etc&#x2F;localtime</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="执行资源配置清单"><a href="#执行资源配置清单" class="headerlink" title="执行资源配置清单"></a>执行资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;log-pilot&#x2F;ds.yaml</span><br></pre></td></tr></table></figure><h3 id="收集服务日志"><a href="#收集服务日志" class="headerlink" title="收集服务日志"></a>收集服务日志</h3><p>在dubbo-demo-consumer的deploy.yaml 添加环境变量</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 yaml]# vim test&#x2F;dubbo-demo-consumer&#x2F;deploy.yaml </span><br><span class="line">        env:</span><br><span class="line">        - name: aliyun_logs_k8s-out  #当然如果你不想使用aliyun这个关键字，Log-Pilot 也提供了环境变量 PILOT_LOG_PREFIX可以指定自己的声明式日志配置前缀，比如 PILOT_LOG_PREFIX: &quot;aliyun,custom&quot;，最好是和官方一致，省去多余的配置</span><br><span class="line">          value: &quot;stdout&quot;                 #需要收集的日志路径</span><br><span class="line">        - name: aliyun_logs_k8s-out_tags  #定义一个tag</span><br><span class="line">          value: &quot;topic&#x3D;k8s-fb-test-out&quot;  #kafka topic的名字，这个定义是关键，不定义这个，日志是无法输出到kafka内的         </span><br><span class="line"></span><br><span class="line">[root@wang-200 yaml]# kubectl apply -f test&#x2F;dubbo-demo-consumer&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><p><strong>使用Podpreset收集日志(有兴趣自己研究)</strong></p><h3 id="验证Kafka"><a href="#验证Kafka" class="headerlink" title="验证Kafka"></a>验证Kafka</h3><p>通过kafka-manager查看索引  <a href="http://km.od.com/clusters/kafka-od/topics" target="_blank" rel="noopener">http://km.od.com/clusters/kafka-od/topics</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfnghhmjcwj31q60hq40z.jpg" alt="索引k8s-fb-tset-out注册成功"></p><h2 id="部署logstash"><a href="#部署logstash" class="headerlink" title="部署logstash"></a>部署logstash</h2><h3 id="准备镜像-1"><a href="#准备镜像-1" class="headerlink" title="准备镜像"></a>准备镜像</h3><p>在运维主机拉取镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull logstash:6.8.3</span><br><span class="line">docker tag 972bf55ad27b harbor.od.com&#x2F;infra&#x2F;logstash:v6.8.3</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;logstash:v6.8.3</span><br></pre></td></tr></table></figure><h3 id="准备配置文件"><a href="#准备配置文件" class="headerlink" title="准备配置文件"></a>准备配置文件</h3><p>在运维主机创建文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;etc&#x2F;logstash&#x2F;</span><br></pre></td></tr></table></figure><p>准备测试环境配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;logstash&#x2F;logstash-test.conf</span><br><span class="line">input &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    bootstrap_servers &#x3D;&gt; &quot;192.168.70.11:9092&quot;</span><br><span class="line">    client_id &#x3D;&gt; &quot;192.168.70.200&quot;</span><br><span class="line">    consumer_threads &#x3D;&gt; 4</span><br><span class="line">    group_id &#x3D;&gt; &quot;k8s_test&quot;               # 为test组</span><br><span class="line">    topics_pattern &#x3D;&gt; &quot;k8s-fb-test-.*&quot;   # 只收集k8s-fb-test开头的topics</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">  json &#123;</span><br><span class="line">    source &#x3D;&gt; &quot;message&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts &#x3D;&gt; [&quot;192.168.70.12:9200&quot;]</span><br><span class="line">    index &#x3D;&gt; &quot;k8s-test-%&#123;+YYYY.MM.DD&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>准备生产环境配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;logstash&#x2F;logstash-prod.conf</span><br><span class="line">input &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    bootstrap_servers &#x3D;&gt; &quot;192.168.70.11:9092&quot;</span><br><span class="line">    client_id &#x3D;&gt; &quot;192.168.70.200&quot;</span><br><span class="line">    consumer_threads &#x3D;&gt; 4</span><br><span class="line">    group_id &#x3D;&gt; &quot;k8s_prod&quot;                   </span><br><span class="line">    topics_pattern &#x3D;&gt; &quot;k8s-fb-prod-.*&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">  json &#123;</span><br><span class="line">    source &#x3D;&gt; &quot;message&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts &#x3D;&gt; [&quot;192.168.70.12:9200&quot;]</span><br><span class="line">    index &#x3D;&gt; “k8s-prod-%&#123;+YYYY.MM.DD&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="测试logstash启动"><a href="#测试logstash启动" class="headerlink" title="测试logstash启动"></a>测试logstash启动</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# docker run -d --restart&#x3D;always --name logstash-test -v &#x2F;etc&#x2F;logstash:&#x2F;etc&#x2F;logstash  harbor.od.com&#x2F;infra&#x2F;logstash:v6.8.3 -f &#x2F;etc&#x2F;logstash&#x2F;logstash-test.conf</span><br><span class="line">[root@wang-200 ~]# docker ps -a|grep logstash</span><br><span class="line">53a32e867f2e        harbor.od.com&#x2F;infra&#x2F;logstash:v6.8.3                 &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;dock…&quot;   10 seconds ago      Up 9 seconds           5044&#x2F;tcp, 9600&#x2F;tcp          logstash-test</span><br></pre></td></tr></table></figure><h3 id="查看es是否接收数据"><a href="#查看es是否接收数据" class="headerlink" title="查看es是否接收数据"></a>查看es是否接收数据</h3><p>要等一会儿，不要着急，等它多产生一点数据。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;192.168.70.12:9200&#x2F;_cat&#x2F;indices?v</span><br></pre></td></tr></table></figure><h3 id="生产logstash启动"><a href="#生产logstash启动" class="headerlink" title="生产logstash启动"></a>生产logstash启动</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# docker run -d --restart&#x3D;always --name logstash-prod -v &#x2F;etc&#x2F;logstash:&#x2F;etc&#x2F;logstash  harbor.od.com&#x2F;infra&#x2F;logstash:v6.8.3 -f &#x2F;etc&#x2F;logstash&#x2F;logstash-prod.conf</span><br></pre></td></tr></table></figure><h2 id="部署kibana"><a href="#部署kibana" class="headerlink" title="部署kibana"></a>部署kibana</h2><h3 id="准备镜像-2"><a href="#准备镜像-2" class="headerlink" title="准备镜像"></a>准备镜像</h3><p>运维主机wang-200.host.com上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull kibana:6.8.6</span><br><span class="line">docker tag adfab5632ef4 harbor.od.com&#x2F;infra&#x2F;kibana:v6.8.6</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;kibana:v6.8.6</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-1"><a href="#准备资源配置清单-1" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kibana</span><br><span class="line">cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kibana</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kibana&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: kibana</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: kibana</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: kibana</span><br><span class="line">        name: kibana</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kibana</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;kibana:v6.8.6</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 5601</span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">        - name: ELASTICSEARCH_URL</span><br><span class="line">          value: http:&#x2F;&#x2F;192.168.70.12:9200</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kibana&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 5601</span><br><span class="line">    targetPort: 5601</span><br><span class="line">  selector: </span><br><span class="line">    app: kibana</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kibana&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: kibana.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: kibana</span><br><span class="line">          servicePort: 5601</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="执行资源配置清单-1"><a href="#执行资源配置清单-1" class="headerlink" title="执行资源配置清单"></a>执行资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kibana&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kibana&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kibana&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><h3 id="web展示"><a href="#web展示" class="headerlink" title="web展示"></a>web展示</h3><p><a href="http://kibana.od.com/" target="_blank" rel="noopener">http://kibana.od.com/</a></p><p><strong>添加索引k8s-test-*</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfngjil5q0j32180qa7c9.jpg" alt="添加索引k8s-test-*"></p><p><strong>elasticsearch收集的数据</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfngkq5zgsj321o0twaka.jpg" alt="elasticsearch收集的数据"></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 实战交付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 老男孩 </tag>
            
            <tag> 实战交付 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四、生态-prometheus系统监控</title>
      <link href="/2020/06/09/%E5%9B%9B%E3%80%81%E7%94%9F%E6%80%81-prometheus%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
      <url>/2020/06/09/%E5%9B%9B%E3%80%81%E7%94%9F%E6%80%81-prometheus%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="Prometheus介绍"><a href="#Prometheus介绍" class="headerlink" title="Prometheus介绍"></a>Prometheus介绍</h2><p>​        由于docker容器的特殊性，传统的zabbix无法对k8s集群内的docker状态进行监控，所以需要使用prometheus来进行监控：</p><h3 id="什么是Prometheus"><a href="#什么是Prometheus" class="headerlink" title="什么是Prometheus?"></a>什么是Prometheus?</h3><p>Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。<br> 2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。<br> Prometheus目前在开源社区相当活跃。<br> Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。</p><h3 id="Prometheus的特点"><a href="#Prometheus的特点" class="headerlink" title="Prometheus的特点"></a>Prometheus的特点</h3><ul><li><ul><li>多维度数据模型。</li><li>灵活的查询语言。</li><li>不依赖分布式存储，单个服务器节点是自主的。</li><li>通过基于HTTP的pull方式采集时序数据。</li><li>可以通过中间网关进行时序列数据推送。</li><li>通过服务发现或者静态配置来发现目标服务对象。</li><li>支持多种多样的图表和界面展示，比如Grafana等。</li></ul></li></ul><h3 id="prometheus架构图"><a href="#prometheus架构图" class="headerlink" title="prometheus架构图"></a>prometheus架构图</h3><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfon4fvspsj311j0mjdjb.jpg" alt="prometheus架构图"></p><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter  。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。</p><h3 id="服务过程"><a href="#服务过程" class="headerlink" title="服务过程"></a>服务过程</h3><ul><li>Prometheus  Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV  Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。</li><li>Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。</li><li>Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。</li><li>PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。</li><li>Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。</li></ul><h3 id="三大套件"><a href="#三大套件" class="headerlink" title="三大套件"></a>三大套件</h3><ul><li>Server 主要负责数据采集和存储，提供PromQL查询语言的支持。</li><li>Alertmanager 警告管理器，用来进行报警。</li><li>Push Gateway 支持临时性Job主动推送指标的中间网关。</li></ul><p>prometheus不同于zabbix，没有agent，使用的是针对不同服务的exporter：</p><p>prometheus官网：<a href="https://prometheus.io/" target="_blank" rel="noopener">官网地址</a></p><p>正常情况下，监控k8s集群及node，pod，常用的exporter有四个：</p><ul><li><strong>kube-state-metrics – 收集k8s集群master&amp;etcd等基本状态信息</strong></li><li><strong>node-exporter      – 收集k8s集群node信息</strong></li><li><strong>cadvisor           – 收集k8s集群docker容器内部使用资源信息</strong></li><li><strong>blackbox-exporte   – 收集k8s集群docker容器服务是否存活</strong></li></ul><p>接下来逐一创建以上exporter：</p><p>下载docker镜像，准备资源配置清单，应用资源配置清单：</p><h2 id="kube-state-metrics"><a href="#kube-state-metrics" class="headerlink" title="kube-state-metrics"></a>kube-state-metrics</h2><h3 id="下载docker镜像"><a href="#下载docker镜像" class="headerlink" title="下载docker镜像"></a>下载docker镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull quay.io&#x2F;coreos&#x2F;kube-state-metrics:v1.5.0</span><br><span class="line">docker tag 91599517197a harbor.od.com&#x2F;public&#x2F;kube-state-metrics:v1.5.0</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;kube-state-metrics:v1.5.0</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单"><a href="#准备资源配置清单" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建资源配置清单文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kube-state-metrics</span><br></pre></td></tr></table></figure><p>rbac.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kube-state-metrics&#x2F;rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  - secrets</span><br><span class="line">  - nodes</span><br><span class="line">  - pods</span><br><span class="line">  - services</span><br><span class="line">  - resourcequotas</span><br><span class="line">  - replicationcontrollers</span><br><span class="line">  - limitranges</span><br><span class="line">  - persistentvolumeclaims</span><br><span class="line">  - persistentvolumes</span><br><span class="line">  - namespaces</span><br><span class="line">  - endpoints</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - policy</span><br><span class="line">  resources:</span><br><span class="line">  - poddisruptionbudgets</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - extensions</span><br><span class="line">  resources:</span><br><span class="line">  - daemonsets</span><br><span class="line">  - deployments</span><br><span class="line">  - replicasets</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - apps</span><br><span class="line">  resources:</span><br><span class="line">  - statefulsets</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - batch</span><br><span class="line">  resources:</span><br><span class="line">  - cronjobs</span><br><span class="line">  - jobs</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - autoscaling</span><br><span class="line">  resources:</span><br><span class="line">  - horizontalpodautoscalers</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;kube-state-metrics&#x2F;deploy.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    deployment.kubernetes.io&#x2F;revision: &quot;2&quot;</span><br><span class="line">  labels:</span><br><span class="line">    grafanak8sapp: &quot;true&quot;</span><br><span class="line">    app: kube-state-metrics</span><br><span class="line">  name: kube-state-metrics</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      grafanak8sapp: &quot;true&quot;</span><br><span class="line">      app: kube-state-metrics</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 25%</span><br><span class="line">      maxUnavailable: 25%</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        grafanak8sapp: &quot;true&quot;</span><br><span class="line">        app: kube-state-metrics</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-state-metrics</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;kube-state-metrics:v1.5.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          name: http-metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        readinessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: &#x2F;healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 5</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">      serviceAccountName: kube-state-metrics</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单"><a href="#应用资源配置清单" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kube-state-metrics&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;kube-state-metrics&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><p>查看服务状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n kube-system -o wide | grep kube-state-metrics</span><br><span class="line">kube-state-metrics-8669f776c6-cd9mq     1&#x2F;1     Running   0          71s   172.16.23.12   wang-23.host.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[root@wang-200 ~]# curl http:&#x2F;&#x2F;172.16.23.12:8080&#x2F;healthz</span><br><span class="line">ok</span><br></pre></td></tr></table></figure><p>显示ok证明已经成功运行</p><h2 id="node-exporter"><a href="#node-exporter" class="headerlink" title="node-exporter"></a>node-exporter</h2><h3 id="下载docker镜像-1"><a href="#下载docker镜像-1" class="headerlink" title="下载docker镜像"></a>下载docker镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull prom&#x2F;node-exporter:v0.15.0</span><br><span class="line">docker tag 12d51ffa2b22 harbor.od.com&#x2F;public&#x2F;node-exporter:v0.15.0</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;node-exporter:v0.15.0</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-1"><a href="#准备资源配置清单-1" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p><strong>由于node-exporter是监控node的，所有需要每个节点启动一个，所以使用ds控制器</strong></p><p>准备资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;node-exporter</span><br></pre></td></tr></table></figure><p>ds.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;node-exporter&#x2F;ds.yaml</span><br><span class="line">kind: DaemonSet</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    daemon: &quot;node-exporter&quot;</span><br><span class="line">    grafanak8sapp: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      daemon: &quot;node-exporter&quot;</span><br><span class="line">      grafanak8sapp: &quot;true&quot;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: node-exporter</span><br><span class="line">      labels:</span><br><span class="line">        daemon: &quot;node-exporter&quot;</span><br><span class="line">        grafanak8sapp: &quot;true&quot;</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">      - name: proc</span><br><span class="line">        hostPath: </span><br><span class="line">          path: &#x2F;proc</span><br><span class="line">          type: &quot;&quot;</span><br><span class="line">      - name: sys</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;sys</span><br><span class="line">          type: &quot;&quot;</span><br><span class="line">      containers:</span><br><span class="line">      - name: node-exporter</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;node-exporter:v0.15.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        args:</span><br><span class="line">        - --path.procfs&#x3D;&#x2F;host_proc</span><br><span class="line">        - --path.sysfs&#x3D;&#x2F;host_sys</span><br><span class="line">        ports:</span><br><span class="line">        - name: node-exporter</span><br><span class="line">          hostPort: 9100</span><br><span class="line">          containerPort: 9100</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: sys</span><br><span class="line">          readOnly: true</span><br><span class="line">          mountPath: &#x2F;host_sys</span><br><span class="line">        - name: proc</span><br><span class="line">          readOnly: true</span><br><span class="line">          mountPath: &#x2F;host_proc</span><br><span class="line">      hostNetwork: true</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-1"><a href="#应用资源配置清单-1" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;node-exporter&#x2F;ds.yaml</span><br></pre></td></tr></table></figure><p>验证pod状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n kube-system -o wide | grep node-exporter</span><br><span class="line">node-exporter-967mm                     1&#x2F;1     Running   0          26s   192.168.70.24   wang-24.host.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-exporter-b9sn8                     1&#x2F;1     Running   0          26s   192.168.70.23   wang-23.host.com   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h2 id="cadvisor"><a href="#cadvisor" class="headerlink" title="cadvisor"></a>cadvisor</h2><h3 id="下载docker镜像-2"><a href="#下载docker镜像-2" class="headerlink" title="下载docker镜像"></a>下载docker镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull google&#x2F;cadvisor:v0.28.3</span><br><span class="line">docker tag 75f88e3ec333 harbor.od.com&#x2F;public&#x2F;cadvisor:v0.28.3</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;cadvisor:v0.28.3</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-2"><a href="#准备资源配置清单-2" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;cadvisor</span><br></pre></td></tr></table></figure><p>ds.yaml </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;cadvisor&#x2F;ds.yaml</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: cadvisor</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app: cadvisor</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: cadvisor</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: cadvisor</span><br><span class="line">    spec:</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: node-role.kubernetes.io&#x2F;master</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      containers:</span><br><span class="line">      - name: cadvisor</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;cadvisor:v0.28.3</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: rootfs</span><br><span class="line">          mountPath: &#x2F;rootfs</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: var-run</span><br><span class="line">          mountPath: &#x2F;var&#x2F;run</span><br><span class="line">        - name: sys</span><br><span class="line">          mountPath: &#x2F;sys</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: docker</span><br><span class="line">          mountPath: &#x2F;var&#x2F;lib&#x2F;docker</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">          - name: http</span><br><span class="line">            containerPort: 4194</span><br><span class="line">            protocol: TCP</span><br><span class="line">        readinessProbe:</span><br><span class="line">          tcpSocket:</span><br><span class="line">            port: 4194</span><br><span class="line">          initialDelaySeconds: 5</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        args:</span><br><span class="line">          - --housekeeping_interval&#x3D;10s</span><br><span class="line">          - --port&#x3D;4194</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: rootfs</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;</span><br><span class="line">      - name: var-run</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;run</span><br><span class="line">      - name: sys</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;sys</span><br><span class="line">      - name: docker</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;data&#x2F;docker</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>针对挂载资源，做一些调整(所有监控的机器)：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -o remount,rw &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;</span><br><span class="line">ln -s &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu,cpuacct &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuacct,cpu</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-2"><a href="#应用资源配置清单-2" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;cadvisor&#x2F;ds.yaml</span><br></pre></td></tr></table></figure><p>验证pod状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n kube-system -o wide | grep cadvisor</span><br><span class="line">cadvisor-62t7c                          1&#x2F;1     Running   0          82s   192.168.70.24   wang-24.host.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">cadvisor-szlpj                          1&#x2F;1     Running   0          90s   192.168.70.23   wang-23.host.com   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h2 id="blackbox-exporter"><a href="#blackbox-exporter" class="headerlink" title="blackbox-exporter"></a>blackbox-exporter</h2><h3 id="下载docker镜像-3"><a href="#下载docker镜像-3" class="headerlink" title="下载docker镜像"></a>下载docker镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull prom&#x2F;blackbox-exporter:v0.15.1</span><br><span class="line">docker tag 81b70b6158be  harbor.od.com&#x2F;public&#x2F;blackbox-exporter:v0.15.1</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;blackbox-exporter:v0.15.1</span><br></pre></td></tr></table></figure><h3 id="创建资源配置清单"><a href="#创建资源配置清单" class="headerlink" title="创建资源配置清单"></a>创建资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;blackbox-exporter</span><br></pre></td></tr></table></figure><p>cm.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;blackbox-exporter&#x2F;cm.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: blackbox-exporter</span><br><span class="line">  name: blackbox-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  blackbox.yml: |-</span><br><span class="line">    modules:</span><br><span class="line">      http_2xx:</span><br><span class="line">        prober: http</span><br><span class="line">        timeout: 2s</span><br><span class="line">        http:</span><br><span class="line">          valid_http_versions: [&quot;HTTP&#x2F;1.1&quot;, &quot;HTTP&#x2F;2&quot;]</span><br><span class="line">          valid_status_codes: [200,301,302]</span><br><span class="line">          method: GET</span><br><span class="line">          preferred_ip_protocol: &quot;ip4&quot;</span><br><span class="line">      tcp_connect:</span><br><span class="line">        prober: tcp</span><br><span class="line">        timeout: 2s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;blackbox-exporter&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: blackbox-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app: blackbox-exporter</span><br><span class="line">  annotations:</span><br><span class="line">    deployment.kubernetes.io&#x2F;revision: 1</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: blackbox-exporter</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: blackbox-exporter</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">      - name: config</span><br><span class="line">        configMap:</span><br><span class="line">          name: blackbox-exporter</span><br><span class="line">          defaultMode: 420</span><br><span class="line">      containers:</span><br><span class="line">      - name: blackbox-exporter</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;blackbox-exporter:v0.15.1</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        args:</span><br><span class="line">        - --config.file&#x3D;&#x2F;etc&#x2F;blackbox_exporter&#x2F;blackbox.yml</span><br><span class="line">        - --log.level&#x3D;info</span><br><span class="line">        - --web.listen-address&#x3D;:9115</span><br><span class="line">        ports:</span><br><span class="line">        - name: blackbox-port</span><br><span class="line">          containerPort: 9115</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 200m</span><br><span class="line">            memory: 256Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 50Mi</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;blackbox_exporter</span><br><span class="line">        readinessProbe:</span><br><span class="line">          tcpSocket:</span><br><span class="line">            port: 9115</span><br><span class="line">          initialDelaySeconds: 5</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;blackbox-exporter&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: blackbox-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: blackbox-exporter</span><br><span class="line">  ports:</span><br><span class="line">    - name: blackbox-port</span><br><span class="line">      protocol: TCP</span><br><span class="line">      port: 9115</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;blackbox-exporter&#x2F;ingress.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: blackbox-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: blackbox.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: blackbox-exporter</span><br><span class="line">          servicePort: blackbox-port</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-3"><a href="#应用资源配置清单-3" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;blackbox-exporter&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;blackbox-exporter&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;blackbox-exporter&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;blackbox-exporter&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>查看pod运行状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n kube-system | grep blackbox-exporter</span><br><span class="line">blackbox-exporter-659fc46b55-jr8hg      1&#x2F;1     Running   0          24s</span><br></pre></td></tr></table></figure><h3 id="访问域名测试："><a href="#访问域名测试：" class="headerlink" title="访问域名测试："></a>访问域名测试：</h3><p>访问blackbox.od.com，表示blackbox已经运行成功</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqor0nve4j31a20l4di6.jpg" alt="blackbox.od.com展示界面"></p><h2 id="部署prometheus-server"><a href="#部署prometheus-server" class="headerlink" title="部署prometheus server"></a>部署prometheus server</h2><p>下载docker镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull prom&#x2F;prometheus:v2.14.0</span><br><span class="line">docker tag 7317640d555e harbor.od.com&#x2F;infra&#x2F;prometheus:v2.14.0</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;prometheus:v2.14.0</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-3"><a href="#准备资源配置清单-3" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;prometheus</span><br></pre></td></tr></table></figure><p>创建需要的目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir -p &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;prometheus&#x2F;&#123;etc,prom-db&#125;</span><br></pre></td></tr></table></figure><p>拷贝配置文件中用到的证书：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;prometheus&#x2F;etc&#x2F;</span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;ca.pem .&#x2F;</span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;client.pem .&#x2F;</span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;client-key.pem .&#x2F;</span><br></pre></td></tr></table></figure><p>rbac.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;prometheus&#x2F;rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: infra</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: prometheus</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes&#x2F;metrics</span><br><span class="line">  - services</span><br><span class="line">  - endpoints</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - &#x2F;metrics</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: prometheus</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: prometheus</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: infra</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><blockquote><p>加上–web.enable-lifecycle启用远程热加载配置文件<br>调用指令是curl -X POST <a href="http://localhost:9090/-/reload" target="_blank" rel="noopener">http://localhost:9090/-/reload</a></p><p>storage.tsdb.min-block-duration=10m  #只加载10分钟数据到内</p><p>storage.tsdb.retention=72h   #保留72小时数据</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;prometheus&#x2F;deploy.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    deployment.kubernetes.io&#x2F;revision: &quot;5&quot;</span><br><span class="line">  labels:</span><br><span class="line">    name: prometheus</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: prometheus</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: prometheus</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: prometheus</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;prometheus:v2.14.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;bin&#x2F;prometheus</span><br><span class="line">        args:</span><br><span class="line">        - --config.file&#x3D;&#x2F;data&#x2F;etc&#x2F;prometheus.yml</span><br><span class="line">        - --storage.tsdb.path&#x3D;&#x2F;data&#x2F;prom-db</span><br><span class="line">        - --storage.tsdb.min-block-duration&#x3D;10m</span><br><span class="line">        - --storage.tsdb.retention&#x3D;72h</span><br><span class="line">        - --web.enable-lifecycle</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9090</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;data</span><br><span class="line">          name: data</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;1000m&quot;</span><br><span class="line">            memory: &quot;1.5Gi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;2000m&quot;</span><br><span class="line">            memory: &quot;3Gi&quot;</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsUser: 0</span><br><span class="line">      serviceAccountName: prometheus</span><br><span class="line">      volumes:</span><br><span class="line">      - name: data</span><br><span class="line">        nfs:</span><br><span class="line">          server: wang-200</span><br><span class="line">          path: &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;prometheus</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;prometheus&#x2F;svc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 9090</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9090</span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;prometheus&#x2F;ingress.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: traefik</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: prometheus.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: prometheus</span><br><span class="line">          servicePort: 9090</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>修改prometheus配置文件：别问为啥这么写，问就是不懂~</p><p>vim /data/nfs/v1/prometheus/etc/prometheus.yml </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval:     15s</span><br><span class="line">  evaluation_interval: 15s</span><br><span class="line">scrape_configs:</span><br><span class="line">- job_name: &#39;etcd&#39;</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: &#x2F;data&#x2F;etc&#x2F;ca.pem</span><br><span class="line">    cert_file: &#x2F;data&#x2F;etc&#x2F;client.pem</span><br><span class="line">    key_file: &#x2F;data&#x2F;etc&#x2F;client-key.pem</span><br><span class="line">  scheme: https</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets:</span><br><span class="line">    - &#39;192.168.70.21:2379&#39;</span><br><span class="line">    - &#39;192.168.70.22:2379&#39;</span><br><span class="line">    - &#39;192.168.70.23:2379&#39;</span><br><span class="line">- job_name: &#39;kubernetes-apiservers&#39;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line">  scheme: https</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;ca.crt</span><br><span class="line">  bearer_token_file: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]</span><br><span class="line">    action: keep</span><br><span class="line">    regex: default;kubernetes;https</span><br><span class="line">- job_name: &#39;kubernetes-pods&#39;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]</span><br><span class="line">    action: keep</span><br><span class="line">    regex: true</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: __metrics_path__</span><br><span class="line">    regex: (.+)</span><br><span class="line">  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]</span><br><span class="line">    action: replace</span><br><span class="line">    regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">    replacement: $1:$2</span><br><span class="line">    target_label: __address__</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_namespace</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_name]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_pod_name</span><br><span class="line">- job_name: &#39;kubernetes-kubelet&#39;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: node</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">    regex: (.+)</span><br><span class="line">    target_label: __address__</span><br><span class="line">    replacement: $&#123;1&#125;:10255</span><br><span class="line">- job_name: &#39;kubernetes-cadvisor&#39;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: node</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">    regex: (.+)</span><br><span class="line">    target_label: __address__</span><br><span class="line">    replacement: $&#123;1&#125;:4194</span><br><span class="line">- job_name: &#39;kubernetes-kube-state&#39;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_namespace</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_name]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_pod_name</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_label_grafanak8sapp]</span><br><span class="line">    regex: .*true.*</span><br><span class="line">    action: keep</span><br><span class="line">  - source_labels: [&#39;__meta_kubernetes_pod_label_daemon&#39;, &#39;__meta_kubernetes_pod_node_name&#39;]</span><br><span class="line">    regex: &#39;node-exporter;(.*)&#39;</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: nodename</span><br><span class="line">- job_name: &#39;blackbox_http_pod_probe&#39;</span><br><span class="line">  metrics_path: &#x2F;probe</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">  params:</span><br><span class="line">    module: [http_2xx]</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_blackbox_scheme]</span><br><span class="line">    action: keep</span><br><span class="line">    regex: http</span><br><span class="line">  - source_labels: [__address__, __meta_kubernetes_pod_annotation_blackbox_port,  __meta_kubernetes_pod_annotation_blackbox_path]</span><br><span class="line">    action: replace</span><br><span class="line">    regex: ([^:]+)(?::\d+)?;(\d+);(.+)</span><br><span class="line">    replacement: $1:$2$3</span><br><span class="line">    target_label: __param_target</span><br><span class="line">  - action: replace</span><br><span class="line">    target_label: __address__</span><br><span class="line">    replacement: blackbox-exporter.kube-system:9115</span><br><span class="line">  - source_labels: [__param_target]</span><br><span class="line">    target_label: instance</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_namespace</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_name]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_pod_name</span><br><span class="line">- job_name: &#39;blackbox_tcp_pod_probe&#39;</span><br><span class="line">  metrics_path: &#x2F;probe</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">  params:</span><br><span class="line">    module: [tcp_connect]</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_blackbox_scheme]</span><br><span class="line">    action: keep</span><br><span class="line">    regex: tcp</span><br><span class="line">  - source_labels: [__address__, __meta_kubernetes_pod_annotation_blackbox_port]</span><br><span class="line">    action: replace</span><br><span class="line">    regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">    replacement: $1:$2</span><br><span class="line">    target_label: __param_target</span><br><span class="line">  - action: replace</span><br><span class="line">    target_label: __address__</span><br><span class="line">    replacement: blackbox-exporter.kube-system:9115</span><br><span class="line">  - source_labels: [__param_target]</span><br><span class="line">    target_label: instance</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_namespace</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_name]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_pod_name</span><br><span class="line">- job_name: &#39;traefik&#39;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]</span><br><span class="line">    action: keep</span><br><span class="line">    regex: traefik</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: __metrics_path__</span><br><span class="line">    regex: (.+)</span><br><span class="line">  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]</span><br><span class="line">    action: replace</span><br><span class="line">    regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">    replacement: $1:$2</span><br><span class="line">    target_label: __address__</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">  - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_namespace</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_name]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: kubernetes_pod_name</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-4"><a href="#应用资源配置清单-4" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;prometheus&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;prometheus&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;prometheus&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;prometheus&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>查看pod运行状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n infra | grep prometheus</span><br><span class="line">prometheus-6847bb9f95-jntt6            1&#x2F;1     Running   0          39s</span><br></pre></td></tr></table></figure><p>浏览器验证：</p><p><a href="http://prometheus.od.com/targets" target="_blank" rel="noopener">http://prometheus.od.com/targets</a></p><p>这里点击status-targets，这里展示的就是我们在prometheus.yml中配置的job-name，这些targets基本可以满足我们收集数据的需求。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqqef86q7j30eq0eedh5.jpg" alt="prometheus监控项"></p><p>点击status-configuration就是我们的配置文件</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqqg87jkxj30ds099js1.jpg" alt="prometheu配置文件"></p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>我们在配置文件中，除了etcd使用的静态配置以外，其他job都是使用的自动发现。</p><h4 id="静态配置"><a href="#静态配置" class="headerlink" title="静态配置"></a>静态配置</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval:     15s</span><br><span class="line">  evaluation_interval: 15s</span><br><span class="line">scrape_configs:</span><br><span class="line">- job_name: &#39;etcd&#39;</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: &#x2F;data&#x2F;etc&#x2F;ca.pem</span><br><span class="line">    cert_file: &#x2F;data&#x2F;etc&#x2F;client.pem</span><br><span class="line">    key_file: &#x2F;data&#x2F;etc&#x2F;client-key.pem</span><br><span class="line">  scheme: https</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets:</span><br><span class="line">    - &#39;192.168.70.21:2379&#39;</span><br><span class="line">    - &#39;192.168.70.22:2379&#39;</span><br><span class="line">    - &#39;192.168.70.23:2379&#39;</span><br></pre></td></tr></table></figure><h4 id="自动发现"><a href="#自动发现" class="headerlink" title="自动发现"></a>自动发现</h4><p>自动发现资源是pod</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- job_name: &#39;blackbox_http_pod_probe&#39;</span><br><span class="line">  metrics_path: &#x2F;probe</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">  params:</span><br><span class="line">    module: [http_2xx]</span><br><span class="line">  relabel_configs:</span><br></pre></td></tr></table></figure><p>这里还有很多数据没有收集到，是因为我们在启动服务的时候，没有添加annotations，下面给需要收集数据的服务添加annotations</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqqilcdifj30bv0cu75b.jpg" alt="img"></p><h4 id="traefik"><a href="#traefik" class="headerlink" title="traefik"></a>traefik</h4><p>修改traefik的yaml：</p><p>从dashboard里找到traefik的yaml，跟labels同级添加annotations</p><p>查看prometheus的traffik自动发现规则，你会发现需要有这三个标签</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;annotations&quot;: &#123;</span><br><span class="line">  &quot;prometheus_io_scheme&quot;: &quot;traefik&quot;,</span><br><span class="line">  &quot;prometheus_io_path&quot;: &quot;&#x2F;metrics&quot;,</span><br><span class="line">  &quot;prometheus_io_port&quot;: &quot;8080&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqqlcy8p0j30bp0an0t6.jpg" alt="img"></p><p>等待pod重启以后，在去prometheus上去看</p><p>通过这里查看pod是否有符合你要求的。 <a href="http://prometheus.od.com/service-discovery" target="_blank" rel="noopener">http://prometheus.od.com/service-discovery</a></p><p>我添加了标签没有自动更新，手动帮他更新(删除pod) </p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqrya030ij31vc0pa7a8.jpg" alt="image-20200613170856736"></p><h4 id="blackbox"><a href="#blackbox" class="headerlink" title="blackbox"></a>blackbox</h4><p>这个是检测容器内服务存活性的，也就是端口健康状态检查，分为tcp和http</p><p>首先准备两个服务，将dubbo-demo-service和dubbo-demo-consumer都调整为使用master镜像，不依赖apollo的（节省资源）</p><p>等两个服务起来以后，首先在dubbo-demo-service资源中添加一个TCP的annotation：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;annotations&quot;: &#123;</span><br><span class="line">  &quot;blackbox_port&quot;: &quot;20880&quot;,</span><br><span class="line">  &quot;blackbox_scheme&quot;: &quot;tcp&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqrzpk430j30ap06xt8x.jpg" alt="img"></p><p>等待pod更新（重启）后</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft0dtadc1j31wq0dgado.jpg" alt="image-20200613171206561"></p><p>这里会自动发现我们服务中，运行tcp port端口为20880的服务，并监控其状态</p><p>添加dubbo-demo-consumer服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;annotations&quot;: &#123;</span><br><span class="line">  &quot;blackbox_path&quot;: &quot;&#x2F;hello?name&#x3D;health&quot;,</span><br><span class="line">  &quot;blackbox_port&quot;: &quot;8080&quot;,</span><br><span class="line">  &quot;blackbox_scheme&quot;: &quot;http&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqs2264msj30cs06odg4.jpg" alt="img"></p><p>等pod重启后查看监控项</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqs41f3ejj31xy0e0786.jpg" alt="image-20200613171447140"></p><p>去检查blackbox.od.com</p><p><a href="http://blackbox.od.com/" target="_blank" rel="noopener">http://blackbox.od.com/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqs4zq8yij31hj0u0tfu.jpg" alt="image-20200613171547435"></p><h4 id="添加监控jvm信息"><a href="#添加监控jvm信息" class="headerlink" title="添加监控jvm信息"></a>添加监控jvm信息</h4><p>添加监控jvm信息的annotation</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;annotations&quot;: &#123;</span><br><span class="line">  &quot;prometheus_io_scrape&quot;: &quot;true&quot;,</span><br><span class="line">  &quot;prometheus_io_port&quot;: &quot;12346&quot;,</span><br><span class="line">  &quot;prometheus_io_path&quot;: &quot;&#x2F;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>dubbo-demo-service和dubbo-demo-consumer都添加</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqvk69dslj31ya0j079n.jpg" alt="image-20200613191358238"></p><p> 匹配规则，要去prometheus.yml中去看。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqs7vf64ej30fm06xq3m.jpg" alt="img"></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqs80nb91j309f03e0ss.jpg" alt="img"></p><h2 id="grafana监控展示"><a href="#grafana监控展示" class="headerlink" title="grafana监控展示"></a>grafana监控展示</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull grafana&#x2F;grafana:5.4.2</span><br><span class="line">docker tag 6f18ddf9e552 harbor.od.com&#x2F;infra&#x2F;grafana:v5.4.2</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;grafana:v5.4.2</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-4"><a href="#准备资源配置清单-4" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;grafana</span><br><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;grafana</span><br></pre></td></tr></table></figure><p>rbac.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;grafana&#x2F;rbac.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: grafana</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;*&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - namespaces</span><br><span class="line">  - deployments</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">  name: grafana</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: grafana</span><br><span class="line">subjects:</span><br><span class="line">- kind: User</span><br><span class="line">  name: k8s-node</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;grafana&#x2F;deploy.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: grafana</span><br><span class="line">    name: grafana</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: grafana</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: grafana</span><br><span class="line">        name: grafana</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: grafana</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;grafana:v5.4.2</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 3000</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;var&#x2F;lib&#x2F;grafana</span><br><span class="line">          name: data</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsUser: 0</span><br><span class="line">      volumes:</span><br><span class="line">      - nfs:</span><br><span class="line">          server: wang-200</span><br><span class="line">          path: &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;grafana</span><br><span class="line">        name: data</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;grafana&#x2F;svc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 3000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 3000</span><br><span class="line">  selector:</span><br><span class="line">    app: grafana</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;grafana&#x2F;ingress.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: grafana.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: grafana</span><br><span class="line">          servicePort: 3000</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-5"><a href="#应用资源配置清单-5" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;grafana&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;grafana&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;grafana&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;grafana&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>查看pod启动状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n infra | grep grafana               </span><br><span class="line">grafana-856f9db8c5-v874r               1&#x2F;1     Running   0          44s</span><br></pre></td></tr></table></figure><h3 id="通过页面配置grafana"><a href="#通过页面配置grafana" class="headerlink" title="通过页面配置grafana"></a>通过页面配置grafana</h3><p>浏览器访问grafana.od.com</p><p>默认用户名密码admin:admin</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqsuiu6o0j31ng0kugnt.jpg" alt="image-20200613174017876"></p><p>进入容器安装插件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl exec -it grafana-856f9db8c5-v874r -n infra &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grafana-cli plugins install grafana-kubernetes-app</span><br><span class="line">grafana-cli plugins install grafana-clock-panel</span><br><span class="line">grafana-cli plugins install grafana-piechart-panel</span><br><span class="line">grafana-cli plugins install briangann-gauge-panel</span><br><span class="line">grafana-cli plugins install natel-discrete-panel</span><br></pre></td></tr></table></figure><h3 id="配置数据源"><a href="#配置数据源" class="headerlink" title="配置数据源"></a>配置数据源</h3><p>选择prometheus，把三个证书添加进来</p><p>URL: <a href="http://prometheus.od.com" target="_blank" rel="noopener">http://prometheus.od.com</a></p><p>CA Cert: /opt/certs/ca.pem      Client Cert: /opt/certs/client.pem        Client Key:/opt/certs/client-key.pem</p><p><img src="https://img2018.cnblogs.com/blog/1034759/201912/1034759-20191218150843677-574385113.png" alt="img"></p><h3 id="使用插件kubernetes"><a href="#使用插件kubernetes" class="headerlink" title="使用插件kubernetes"></a>使用插件kubernetes</h3><p>重启grafana</p><p>找到我们刚才安装的插件里面的kubernetes,启用，</p><p><a href="http://grafana.od.com/plugins/grafana-kubernetes-app/edit" target="_blank" rel="noopener">http://grafana.od.com/plugins/grafana-kubernetes-app/edit</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqtnpuxlij31rc0lc4d6.jpg" alt="image-20200613180820337"></p><p>然后新建cluster, </p><p>URL: <a href="https://kubernetes.default，" target="_blank" rel="noopener">https://kubernetes.default，</a> 数据源为 prometheus</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft1ezwx1cj30sp0h8wh1.jpg" alt="image-20200615160757653"></p><p> 添加完需要稍等几分钟，在没有取到数据之前，会报http forbidden，没关系，等一会就好。大概2-5分钟。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft1e8teo7j30yi0ey0x2.jpg" alt="image-20200615160714630"></p><h2 id="配置alertmanager告警"><a href="#配置alertmanager告警" class="headerlink" title="配置alertmanager告警"></a>配置alertmanager告警</h2><p>下载docker镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull docker.io&#x2F;prom&#x2F;alertmanager:v0.14.0</span><br><span class="line">docker tag 23744b2d645c harbor.od.com&#x2F;infra&#x2F;alertmanager:v0.14.0</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;alertmanager:v0.14.0</span><br></pre></td></tr></table></figure><h3 id="配置资源配置清单"><a href="#配置资源配置清单" class="headerlink" title="配置资源配置清单"></a>配置资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;alertmanager</span><br></pre></td></tr></table></figure><p>cm.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;alertmanager&#x2F;cm.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager-config</span><br><span class="line">  namespace: infra</span><br><span class="line">data:</span><br><span class="line">  config.yml: |-</span><br><span class="line">    global:</span><br><span class="line">      # 在没有报警的情况下声明为已解决的时间</span><br><span class="line">      resolve_timeout: 5m</span><br><span class="line">      # 配置邮件发送信息</span><br><span class="line">      smtp_smarthost: &#39;smtp.163.com:25&#39;</span><br><span class="line">      smtp_from: &#39;xxx@163.com&#39;</span><br><span class="line">      smtp_auth_username: &#39;xxx@163.com&#39;</span><br><span class="line">      smtp_auth_password: &#39;xxxxxx&#39;</span><br><span class="line">      smtp_require_tls: false</span><br><span class="line">    # 所有报警信息进入后的根路由，用来设置报警的分发策略</span><br><span class="line">    route:</span><br><span class="line">      # 这里的标签列表是接收到报警信息后的重新分组标签，例如，接收到的报警信息里面有许多具有 cluster&#x3D;A 和 alertname&#x3D;LatncyHigh 这样的标签的报警信息将会批量被聚合到一个分组里面</span><br><span class="line">      group_by: [&#39;alertname&#39;, &#39;cluster&#39;]</span><br><span class="line">      # 当一个新的报警分组被创建后，需要等待至少group_wait时间来初始化通知，这种方式可以确保您能有足够的时间为同一分组来获取多个警报，然后一起触发这个报警信息。</span><br><span class="line">      group_wait: 30s</span><br><span class="line"></span><br><span class="line">      # 当第一个报警发送后，等待&#39;group_interval&#39;时间来发送新的一组报警信息。</span><br><span class="line">      group_interval: 5m</span><br><span class="line"></span><br><span class="line">      # 如果一个报警信息已经发送成功了，等待&#39;repeat_interval&#39;时间来重新发送他们</span><br><span class="line">      repeat_interval: 5m</span><br><span class="line"></span><br><span class="line">      # 默认的receiver：如果一个报警没有被一个route匹配，则发送给默认的接收器</span><br><span class="line">      receiver: default</span><br><span class="line"></span><br><span class="line">    receivers:</span><br><span class="line">    - name: &#39;default&#39;</span><br><span class="line">      email_configs:</span><br><span class="line">      - to: &#39;xxxx@qq.com&#39;</span><br><span class="line">        send_resolved: true</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;alertmanager&#x2F;deploy.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: alertmanager</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: alertmanager</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: alertmanager</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;alertmanager:v0.14.0</span><br><span class="line">        args:</span><br><span class="line">          - &quot;--config.file&#x3D;&#x2F;etc&#x2F;alertmanager&#x2F;config.yml&quot;</span><br><span class="line">          - &quot;--storage.path&#x3D;&#x2F;alertmanager&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - name: alertmanager</span><br><span class="line">          containerPort: 9093</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: alertmanager-cm</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;alertmanager</span><br><span class="line">      volumes:</span><br><span class="line">      - name: alertmanager-cm</span><br><span class="line">        configMap:</span><br><span class="line">          name: alertmanager-config</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;alertmanager&#x2F;svc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  selector: </span><br><span class="line">    app: alertmanager</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 9093</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;alertmanager&#x2F;ingress.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: alertmanager.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: alertmanager</span><br><span class="line">          servicePort: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="执行资源配置清单"><a href="#执行资源配置清单" class="headerlink" title="执行资源配置清单"></a>执行资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;alertmanager&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;alertmanager&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;alertmanager&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;alertmanager&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>查看alertmanager pod运行状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n infra | grep alertmanager</span><br><span class="line">alertmanager-5d46bdc7b4-7jcmg          1&#x2F;1     Running   0          40s</span><br></pre></td></tr></table></figure><p>访问web页面</p><p><a href="http://alertmanager.od.com/#/alerts" target="_blank" rel="noopener">http://alertmanager.od.com/#/alerts</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft0ew5yrkj31vw0ncacs.jpg" alt="image-20200615152624577"></p><h3 id="基础报警规则"><a href="#基础报警规则" class="headerlink" title="基础报警规则"></a>基础报警规则</h3><p><code>vim /data/nfs/v1/prometheus/etc/rules.yml</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: hostStatsAlert</span><br><span class="line">  rules:</span><br><span class="line">  - alert: hostCpuUsageAlert</span><br><span class="line">    expr: sum(avg without (cpu)(irate(node_cpu&#123;mode!&#x3D;&#39;idle&#39;&#125;[5m]))) by (instance) &gt; 0.85</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;&#123;&#123; $labels.instance &#125;&#125; CPU usage above 85% (current value: &#123;&#123; $value &#125;&#125;%)&quot;</span><br><span class="line">  - alert: hostMemUsageAlert</span><br><span class="line">    expr: (node_memory_MemTotal - node_memory_MemAvailable)&#x2F;node_memory_MemTotal &gt; 0.85</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;&#123;&#123; $labels.instance &#125;&#125; MEM usage above 85% (current value: &#123;&#123; $value &#125;&#125;%)&quot;</span><br><span class="line">  - alert: OutOfInodes</span><br><span class="line">    expr: node_filesystem_free&#123;fstype&#x3D;&quot;overlay&quot;,mountpoint &#x3D;&quot;&#x2F;&quot;&#125; &#x2F; node_filesystem_size&#123;fstype&#x3D;&quot;overlay&quot;,mountpoint &#x3D;&quot;&#x2F;&quot;&#125; * 100 &lt; 10</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Out of inodes (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Disk is almost running out of available inodes (&lt; 10% left) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: OutOfDiskSpace</span><br><span class="line">    expr: node_filesystem_free&#123;fstype&#x3D;&quot;overlay&quot;,mountpoint &#x3D;&quot;&#x2F;rootfs&quot;&#125; &#x2F; node_filesystem_size&#123;fstype&#x3D;&quot;overlay&quot;,mountpoint &#x3D;&quot;&#x2F;rootfs&quot;&#125; * 100 &lt; 10</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Out of disk space (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Disk is almost full (&lt; 10% left) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: UnusualNetworkThroughputIn</span><br><span class="line">    expr: sum by (instance) (irate(node_network_receive_bytes[2m])) &#x2F; 1024 &#x2F; 1024 &gt; 100</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Unusual network throughput in (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Host network interfaces are probably receiving too much data (&gt; 100 MB&#x2F;s) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: UnusualNetworkThroughputOut</span><br><span class="line">    expr: sum by (instance) (irate(node_network_transmit_bytes[2m])) &#x2F; 1024 &#x2F; 1024 &gt; 100</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Unusual network throughput out (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Host network interfaces are probably sending too much data (&gt; 100 MB&#x2F;s) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: UnusualDiskReadRate</span><br><span class="line">    expr: sum by (instance) (irate(node_disk_bytes_read[2m])) &#x2F; 1024 &#x2F; 1024 &gt; 50</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Unusual disk read rate (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Disk is probably reading too much data (&gt; 50 MB&#x2F;s) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: UnusualDiskWriteRate</span><br><span class="line">    expr: sum by (instance) (irate(node_disk_bytes_written[2m])) &#x2F; 1024 &#x2F; 1024 &gt; 50</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Unusual disk write rate (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Disk is probably writing too much data (&gt; 50 MB&#x2F;s) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: UnusualDiskReadLatency</span><br><span class="line">    expr: rate(node_disk_read_time_ms[1m]) &#x2F; rate(node_disk_reads_completed[1m]) &gt; 100</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Unusual disk read latency (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Disk latency is growing (read operations &gt; 100ms) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: UnusualDiskWriteLatency</span><br><span class="line">    expr: rate(node_disk_write_time_ms[1m]) &#x2F; rate(node_disk_writes_completedl[1m]) &gt; 100</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Unusual disk write latency (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Disk latency is growing (write operations &gt; 100ms) (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">- name: http_status</span><br><span class="line">  rules:</span><br><span class="line">  - alert: ProbeFailed</span><br><span class="line">    expr: probe_success &#x3D;&#x3D; 0</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: error</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Probe failed (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Probe failed (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: StatusCode</span><br><span class="line">    expr: probe_http_status_code &lt;&#x3D; 199 OR probe_http_status_code &gt;&#x3D; 400</span><br><span class="line">    for: 1m</span><br><span class="line">    labels:</span><br><span class="line">      severity: error</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Status Code (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;HTTP status code is not 200-399 (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: SslCertificateWillExpireSoon</span><br><span class="line">    expr: probe_ssl_earliest_cert_expiry - time() &lt; 86400 * 30</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;SSL certificate will expire soon (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;SSL certificate expires in 30 days (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: SslCertificateHasExpired</span><br><span class="line">    expr: probe_ssl_earliest_cert_expiry - time()  &lt;&#x3D; 0</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: error</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;SSL certificate has expired (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;SSL certificate has expired already (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: BlackboxSlowPing</span><br><span class="line">    expr: probe_icmp_duration_seconds &gt; 2</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Blackbox slow ping (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Blackbox ping took more than 2s (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: BlackboxSlowRequests</span><br><span class="line">    expr: probe_http_duration_seconds &gt; 2 </span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Blackbox slow requests (instance &#123;&#123; $labels.instance &#125;&#125;)&quot;</span><br><span class="line">      description: &quot;Blackbox request took more than 2s (current value: &#123;&#123; $value &#125;&#125;)&quot;</span><br><span class="line">  - alert: PodCpuUsagePercent</span><br><span class="line">    expr: sum(sum(label_replace(irate(container_cpu_usage_seconds_total[1m]),&quot;pod&quot;,&quot;$1&quot;,&quot;container_label_io_kubernetes_pod_name&quot;, &quot;(.*)&quot;))by(pod) &#x2F; on(pod) group_right kube_pod_container_resource_limits_cpu_cores *100 )by(container,namespace,node,pod,severity) &gt; 80</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: &quot;Pod cpu usage percent has exceeded 80% (current value: &#123;&#123; $value &#125;&#125;%)&quot;</span><br></pre></td></tr></table></figure><p>在/data/nfs/v1/prometheus/etc/prometheus.yml中添加配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">    - static_configs:</span><br><span class="line">        - targets: [&quot;alertmanager&quot;]</span><br><span class="line">rule_files:</span><br><span class="line"> - &quot;&#x2F;data&#x2F;etc&#x2F;rules.yml&quot;</span><br></pre></td></tr></table></figure><p>重载配置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X POST http:&#x2F;&#x2F;prometheus.od.com&#x2F;-&#x2F;reload</span><br></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfqv8547e9j30d20ezaas.jpg" alt="img"></p><p> 以上这些就是我们的告警规则</p><p>测试告警：</p><p>把app命名空间里的dubbo-demo-service给停掉：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft0f88hxqj30sh02bq2z.jpg" alt="img"></p><p> 看下blackbox里的信息： <a href="http://blackbox.od.com/" target="_blank" rel="noopener">http://blackbox.od.com/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft0ijndtej31dc0o80wo.jpg" alt="image-20200615153640360"></p><p>看下alert告警：</p><p><img src="https://img2018.cnblogs.com/blog/1034759/201912/1034759-20191218174052248-183200263.png" alt="img"></p><p> 红色的时候就开会发邮件告警：</p><p><img src="https://img2018.cnblogs.com/blog/1034759/201912/1034759-20191218174118507-915764907.png" alt="img"></p><p><strong>邮件告警示例图</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gft0kcu1enj30sf0h6q56.jpg" alt="邮件告警示例图"></p><p>后续上生产，还会更新如何添加微信、钉钉、短信告警</p><p> 如果需要自己定制告警规则和告警内容，需要研究一下promql，自己修改配置文件。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 实战交付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 老男孩 </tag>
            
            <tag> 实战交付 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三、交付-使用apollo配置中心</title>
      <link href="/2020/06/08/%E4%B8%89%E3%80%81%E4%BA%A4%E4%BB%98-%E4%BD%BF%E7%94%A8apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"/>
      <url>/2020/06/08/%E4%B8%89%E3%80%81%E4%BA%A4%E4%BB%98-%E4%BD%BF%E7%94%A8apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/</url>
      
        <content type="html"><![CDATA[<h2 id="configmap资源"><a href="#configmap资源" class="headerlink" title="configmap资源"></a>configmap资源</h2><p>在我们的环境中测试使用configmap资源，需要先对我们的环境进行一些准备</p><p> 新建一个zk环境(见以前部署zookeeper)，模拟测试环境跟生产环境：</p><h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-11.host.com</td><td>192.168.70.11</td><td>zk1.od.com(Test环境)</td></tr><tr><td>wang-12.host.com</td><td>192.168.70.12</td><td>zk2.od.com(Prod环境)</td></tr></tbody></table><h3 id="创建资源配置清单"><a href="#创建资源配置清单" class="headerlink" title="创建资源配置清单"></a>创建资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;</span><br></pre></td></tr></table></figure><h4 id="cm-yaml"><a href="#cm-yaml" class="headerlink" title="cm.yaml"></a>cm.yaml</h4><p>红色部分是配置文件的name，下面的是内容。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: dubbo-monitor-cm</span><br><span class="line">  namespace: infra</span><br><span class="line">data:</span><br><span class="line">  dubbo.properties: |</span><br><span class="line">    dubbo.container&#x3D;log4j,spring,registry,jetty</span><br><span class="line">    dubbo.application.name&#x3D;simple-monitor</span><br><span class="line">    dubbo.application.owner&#x3D;OldboyEdu</span><br><span class="line">    dubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;zk1.od.com:2181</span><br><span class="line">    dubbo.protocol.port&#x3D;20880</span><br><span class="line">    dubbo.jetty.port&#x3D;8080</span><br><span class="line">    dubbo.jetty.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;monitor</span><br><span class="line">    dubbo.charts.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;charts</span><br><span class="line">    dubbo.statistics.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;statistics</span><br><span class="line">    dubbo.log4j.file&#x3D;&#x2F;dubbo-monitor-simple&#x2F;logs&#x2F;dubbo-monitor.log</span><br><span class="line">    dubbo.log4j.level&#x3D;WARN</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="deploy-cm-yaml"><a href="#deploy-cm-yaml" class="headerlink" title="deploy-cm.yaml"></a>deploy-cm.yaml</h4><p>在dp里面如何使用configmap资源：</p><p>首先声明一个卷，卷的名字叫configmap-volume,然后指定这个卷使用的configmap</p><p>然后定义这个卷的挂载，挂载到哪里。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy-cm.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: dubbo-monitor</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: dubbo-monitor</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: dubbo-monitor</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: dubbo-monitor</span><br><span class="line">        name: dubbo-monitor</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: dubbo-monitor</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;dubbo-monitor:latest</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 20880</span><br><span class="line">          protocol: TCP</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        volumeMounts:</span><br><span class="line">          - name: configmap-volume</span><br><span class="line">            mountPath: &#x2F;dubbo-monitor-simple&#x2F;conf</span><br><span class="line">      volumes:</span><br><span class="line">        - name: configmap-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: dubbo-monitor-cm</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单"><a href="#应用资源配置清单" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy-cm.yaml</span><br></pre></td></tr></table></figure><p>去dashboard查看configmap资源：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl5hx19pjj31bl0u0jwt.jpg" alt="configmap资源"></p><p>我们可以创建多个configmap资源，然后在dp中去挂载应用这些configmap资源，达到修改配置的功能。 </p><p>我们检查一下我们的容器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n infra</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">dubbo-monitor-6676dd74cc-drlgz   1&#x2F;1     Running   0          3m4s</span><br></pre></td></tr></table></figure><p>已经起来了</p><p> 我们检查一下我们挂载的配置是不是我们定义的configmap资源中的配置：</p><p>我们把配置文件挂载到了<strong>/dubbo-monitor-simple/**</strong>conf** 这里，我们去看一下。（上面的dp-cm.yaml中声明的）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl exec -it dubbo-monitor-6676dd74cc-drlgz -n infra &#x2F;bin&#x2F;bash</span><br><span class="line">bash-4.3# cat &#x2F;dubbo-monitor-simple&#x2F;conf&#x2F;dubbo.properties</span><br><span class="line">dubbo.container&#x3D;log4j,spring,registry,jetty</span><br><span class="line">dubbo.application.name&#x3D;simple-monitor</span><br><span class="line">dubbo.application.owner&#x3D;OldboyEdu</span><br><span class="line">dubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;zk1.od.com:2181</span><br><span class="line">dubbo.protocol.port&#x3D;20880</span><br><span class="line">dubbo.jetty.port&#x3D;8080</span><br><span class="line">dubbo.jetty.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;monitor</span><br><span class="line">dubbo.charts.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;charts</span><br><span class="line">dubbo.statistics.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;statistics</span><br><span class="line">dubbo.log4j.file&#x3D;&#x2F;dubbo-monitor-simple&#x2F;logs&#x2F;dubbo-monitor.log</span><br><span class="line">dubbo.log4j.level&#x3D;WARN</span><br></pre></td></tr></table></figure><p>跟我们定义的一模一样。</p><h3 id="通过configmap更换配置"><a href="#通过configmap更换配置" class="headerlink" title="通过configmap更换配置"></a>通过configmap更换配置</h3><p>这里如果想有两种方法：</p><p>　　一、修改configmap 资源，然后apply一下更新资源，然后重启挂载这个configmap资源的deploy。</p><p>　　二、准备多个configmap资源，然后在deploy中更改挂载的configmap,apply以后，dp自动重启。</p><p>检查dubbo-monitor页面的注册信息：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl5ppzu9zj322i0aaacs.jpg" alt="dubbo-monitor页面的注册信息"></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl5obgm1dj31z20eijut.jpg" alt="dubbo-monitor页面的数据源"></p><p>连接的zk1.od.com，下面我们模拟更换configmap资源，来切换环境：</p><p> 这里使用第二种方法，准备多个configmap，我们在准备一个configmap,就叫cm-pro.yaml:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm.yaml &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm-pro.yaml</span><br><span class="line">sed -i &quot;s&amp;dubbo-monitor-cm&amp;dubbo-monitor-cm-pro&amp;&quot; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm-pro.yaml</span><br><span class="line">sed -i &quot;s&amp;zk1.od.com&amp;zk2.od.com&amp;&quot; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm-pro.yaml</span><br></pre></td></tr></table></figure><p> 应用cm-pro.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm-pro.yaml</span><br></pre></td></tr></table></figure><p>通过UI检查执行结果</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl5uujaxbj315u0ckmxu.jpg" alt="配置字典cm"></p><p>dubbo-monitor-cm-pro的数据</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl5we7g6zj317q0h6n0m.jpg" alt="dubbo-monitor-cm-pro的数据"></p><p> 然后我们修改dp-cm.yaml并应用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i &quot;s&amp;dubbo-monitor-cm&amp;dubbo-monitor-cm-pro&amp;&quot; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy-cm.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy-cm.yaml</span><br></pre></td></tr></table></figure><p>新的dubbo-monitor pod起来后，我们进去看看是不是应用的新的configmap配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl exec -it dubbo-monitor-5cb756cc6c-xgqfg -n infra &#x2F;bin&#x2F;bash</span><br><span class="line">bash-4.3# cat &#x2F;dubbo-monitor-simple&#x2F;conf&#x2F;dubbo.properties </span><br><span class="line">dubbo.container&#x3D;log4j,spring,registry,jetty</span><br><span class="line">dubbo.application.name&#x3D;simple-monitor</span><br><span class="line">dubbo.application.owner&#x3D;OldboyEdu</span><br><span class="line">dubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;zk2.od.com:2181</span><br><span class="line">dubbo.protocol.port&#x3D;20880</span><br><span class="line">dubbo.jetty.port&#x3D;8080</span><br><span class="line">dubbo.jetty.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;monitor</span><br><span class="line">dubbo.charts.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;charts</span><br><span class="line">dubbo.statistics.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;statistics</span><br><span class="line">dubbo.log4j.file&#x3D;&#x2F;dubbo-monitor-simple&#x2F;logs&#x2F;dubbo-monitor.log</span><br><span class="line">dubbo.log4j.level&#x3D;WARN</span><br></pre></td></tr></table></figure><p>查看dubbo-monitor界面，已经是zk2.od.com了。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl60lhcalj31ky06ugmk.jpg" alt="dubbo源换成了zk2.od.com"></p><p><strong>更新configmap资源来更改配置需要更新(删除/apply/update)pod，否则无效。</strong></p><blockquote><p>注意，我们这里使用的是mountPath，这个是挂载整个目录，会使容器内的被挂载目录中原有的文件不可见，我们原来脚本中的命令已经无法对挂载的目录操作了。</p></blockquote><h3 id="使用subPath挂载指定的文件"><a href="#使用subPath挂载指定的文件" class="headerlink" title="使用subPath挂载指定的文件"></a>使用subPath挂载指定的文件</h3><p>查看我们pod容器启动的命令可以看见：如果想单独挂载一个配置配件，而不是整个目录，如何操作：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl64yqzvgj31ju05uwfl.jpg" alt="目录只读"></p><p>这里我使用之前的nginx:curl来做如何挂载单个的文件：</p><p>查看资源key的使用方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl explain pod.spec.containers.volumeMounts</span><br></pre></td></tr></table></figure><p>这里有个挂载方法是：subPath,使用这个方法，可以挂载指定的文件，要结合mountPath来使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">subPath      &lt;string&gt;</span><br><span class="line">  Path within the volume from which the container&#39;s volume should be mounted.</span><br><span class="line">  Defaults to &quot;&quot; (volume&#39;s root).</span><br></pre></td></tr></table></figure><p>查看我们原来实验做的nginx:curl这个容器：在default命名空间里。</p><p>我们实验的需求，把<strong>dubbo.properties</strong>这个配置文件挂载到/usr/lib/目录下，并且保证原来容器内/usr/lib/目录下的文件都还在：</p><p> 进入容器查看容器内/usr/lib/下有哪些文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl exec -it nginx-ds-92dn4 &#x2F;bin&#x2F;bash</span><br><span class="line">root@nginx-ds-92dn4:&#x2F;# ls &#x2F;usr&#x2F;lib&#x2F;</span><br><span class="line">apt  coreutils  dpkg  gcc  gnupg  libperl.so.5.14  libperl.so.5.14.2  locale  mime  perl  perl5  pt_chown  python2.6  python2.7  python3  tc  x86_64-linux-gnu</span><br></pre></td></tr></table></figure><p>在default命名空间下创建configmap资源：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;cm.yaml &#x2F;root&#x2F;default&#x2F;cm-test.yaml</span><br><span class="line">sed -i &quot;s&amp;namespace: infra&amp;namespace: default&amp;&quot; &#x2F;root&#x2F;default&#x2F;cm-test.yaml</span><br><span class="line">kubectl apply -f  &#x2F;root&#x2F;default&#x2F;cm-test.yaml</span><br></pre></td></tr></table></figure><p>然后修改这个容器的资源配置清单,挂载configmap资源：一定要注意格式跟缩进<del>~</del></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cp default&#x2F;nginx-ds.yml default&#x2F;nginx-ds-cm.yml</span><br><span class="line">[root@wang-200 ~]# vim default&#x2F;nginx-ds-cm.yml (添加部分)</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: configmap-volume</span><br><span class="line">          mountPath: &#x2F;usr&#x2F;lib&#x2F;dubbo-properties</span><br><span class="line">          subPath: dubbo-properties</span><br><span class="line">      volumes:</span><br><span class="line">      - name: configmap-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: dubbo-monitor-cm</span><br><span class="line">          defaultMode: 420</span><br><span class="line">[root@wang-200 ~]# kubectl apply -f &#x2F;root&#x2F;default&#x2F;nginx-ds-cm.yml</span><br></pre></td></tr></table></figure><p> 然后重启pod</p><p>登录进容器中，查看：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl7blo5ahj30xf01sdg0.jpg" alt="新增配置文件dubbo-properties">     </p><p> 经过对比，我们原来/usr/lib/下的文件还在，并且新增了一个配置文件dubbo-properties这个配置文件。</p><h2 id="交付apollo配置中心到k8s"><a href="#交付apollo配置中心到k8s" class="headerlink" title="交付apollo配置中心到k8s"></a>交付apollo配置中心到k8s</h2><p>apollo官网：<a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener">官方地址</a></p><h3 id="apollo架构图："><a href="#apollo架构图：" class="headerlink" title="apollo架构图："></a>apollo架构图：</h3><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfl7lktr2qj30mw0fxk12.jpg" alt="apollo架构图"></p><h3 id="安装mysql数据库"><a href="#安装mysql数据库" class="headerlink" title="安装mysql数据库"></a>安装mysql数据库</h3><p>apollo需要使用数据库，这里使用mysql，注意版本需要在5.6以上：</p><p>本次环境mysql部署在192.168.70.12上，使用mariadb：10.1以上版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;MariaDB.repo</span><br><span class="line">[mariadb]</span><br><span class="line">name &#x3D; MariaDB</span><br><span class="line">baseurl &#x3D; https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;mariadb&#x2F;yum&#x2F;10.1&#x2F;centos7-amd64&#x2F;</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;mariadb&#x2F;yum&#x2F;RPM-GPG-KEY-MariaDB</span><br><span class="line">gpgcheck&#x3D;1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>导入key并安装</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm --import https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;mariadb&#x2F;yum&#x2F;RPM-GPG-KEY-MariaDB</span><br><span class="line">yum install MariaDB-server -y</span><br></pre></td></tr></table></figure><p>简单配置mysql：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# vi &#x2F;etc&#x2F;my.cnf.d&#x2F;server.cnf</span><br><span class="line">[mysqld]</span><br><span class="line">character_set_server &#x3D; utf8mb4</span><br><span class="line">collation_server &#x3D; utf8mb4_general_ci</span><br><span class="line">init_connect &#x3D; &quot;SET NAMES &#39;utf8mb4&#39;&quot;</span><br><span class="line"></span><br><span class="line">[root@wang-12 ~]# vi &#x2F;etc&#x2F;my.cnf.d&#x2F;mysql-clients.cnf</span><br><span class="line">[mysql]</span><br><span class="line">default-character-set &#x3D; utf8mb4</span><br></pre></td></tr></table></figure><p>启动数据库并设置开机自启</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start mariadb</span><br><span class="line">systemctl enable mariadb</span><br></pre></td></tr></table></figure><p>设置开启密码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysqladmin -u root password</span><br></pre></td></tr></table></figure><p>登录检查字符集：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# mysql -uroot -p</span><br><span class="line">MariaDB [(none)]&gt; \s</span><br><span class="line">--------------</span><br><span class="line">mysql  Ver 15.1 Distrib 10.1.45-MariaDB, for Linux (x86_64) using readline 5.1</span><br><span class="line"></span><br><span class="line">Connection id:          6</span><br><span class="line">Current database:</span><br><span class="line">Current user:           root@localhost</span><br><span class="line">SSL:                    Not in use</span><br><span class="line">Current pager:          stdout</span><br><span class="line">Using outfile:          &#39;&#39;</span><br><span class="line">Using delimiter:        ;</span><br><span class="line">Server:                 MariaDB</span><br><span class="line">Server version:         10.1.45-MariaDB MariaDB Server</span><br><span class="line">Protocol version:       10</span><br><span class="line">Connection:             Localhost via UNIX socket</span><br><span class="line">Server characterset:    utf8mb4      # 字符集</span><br><span class="line">Db     characterset:    utf8mb4      # 字符集</span><br><span class="line">Client characterset:    utf8mb4      # 字符集</span><br><span class="line">Conn.  characterset:    utf8mb4      # 字符集</span><br><span class="line">UNIX socket:            &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock</span><br><span class="line">Uptime:                 3 min 59 sec</span><br></pre></td></tr></table></figure><p>授权用户运维主机登陆</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; grant all on *.* to &quot;root&quot;@&quot;192.168.70.200&quot;  identified by &#39;admin&#39; WITH GRANT OPTION;          </span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><h4 id="添加mysql-od-com域名解析："><a href="#添加mysql-od-com域名解析：" class="headerlink" title="添加mysql.od.com域名解析："></a>添加mysql.od.com域名解析：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# vim &#x2F;var&#x2F;named&#x2F;od.com.zone </span><br><span class="line">mysql           A       192.168.70.12</span><br><span class="line"></span><br><span class="line">[root@wang-12 ~]# systemctl restart named</span><br><span class="line">[root@wang-12 ~]# dig -t A mysql.od.com +short</span><br><span class="line">192.168.70.12</span><br></pre></td></tr></table></figure><h3 id="初始化脚本"><a href="#初始化脚本" class="headerlink" title="初始化脚本"></a>初始化脚本</h3><p>执行数据库初始化脚本：<a href="https://github.com/ctripcorp/apollo/blob/1.5.1/scripts/db/migration/configdb/V1.0.0__initialization.sql" target="_blank" rel="noopener">configdb初始化脚本</a></p><p>下载脚本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget -O apolloconfig.sql  https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ctripcorp&#x2F;apollo&#x2F;1.5.1&#x2F;scripts&#x2F;db&#x2F;migration&#x2F;configdb&#x2F;V1.0.0__initialization.sql</span><br></pre></td></tr></table></figure><p>执行初始化脚本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -h wang-12 -p &lt; apolloconfig.sql</span><br></pre></td></tr></table></figure><p>检查数据库：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gflsc3w05mj30al05mjrt.jpg" alt="ApolloConfigDB数据库"></p><p> 给数据库授权：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant INSERT,DELETE,UPDATE,SELECT on ApolloConfigDB.* to &#39;apolloconfig&#39;@&#39;192.168.70.%&#39;  identified by &quot;123456&quot;;</span><br></pre></td></tr></table></figure><p> 修改初始化数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; update ApolloConfigDB.ServerConfig set ServerConfig.Value&#x3D;&quot;http:&#x2F;&#x2F;config.od.com&#x2F;eureka&quot; where ServerConfig.Key&#x3D;&quot;eureka.service.url&quot;;</span><br></pre></td></tr></table></figure><p>交付顺序：</p><p>　　1、apolloconfigservice</p><p>　　2、adminservice</p><p>　　3、portal</p><p>下载apolloconfigservice的包：放到200上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;ctripcorp&#x2F;apollo&#x2F;releases&#x2F;download&#x2F;v1.5.1&#x2F;apollo-configservice-1.5.1-github.zip -O &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apollo-configservice-1.5.1-github.zip</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;ctripcorp&#x2F;apollo&#x2F;releases&#x2F;download&#x2F;v1.5.1&#x2F;apollo-adminservice-1.5.1-github.zip -O &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apollo-adminservice-1.5.1-github.zip</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;ctripcorp&#x2F;apollo&#x2F;releases&#x2F;download&#x2F;v1.5.1&#x2F;apollo-portal-1.5.1-github.zip -O &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apollo-portal-1.5.1-github.zip</span><br></pre></td></tr></table></figure><h3 id="交付apolloconfigservice"><a href="#交付apolloconfigservice" class="headerlink" title="交付apolloconfigservice"></a>交付apolloconfigservice</h3><p>解压安装包，制作镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;dockerfile&#x2F;apollo-configservice</span><br><span class="line">unzip -o &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apollo-configservice-1.5.1-github.zip -d &#x2F;data&#x2F;dockerfile&#x2F;apollo-configservice&#x2F;</span><br><span class="line">cd &#x2F;data&#x2F;dockerfile&#x2F;apollo-configservice&#x2F;</span><br></pre></td></tr></table></figure><p>修改连接数据库配置：</p><p><code>vim config/application-github.properties</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.datasource.url &#x3D; jdbc:mysql:&#x2F;&#x2F;mysql.od.com:3306&#x2F;ApolloConfigDB?characterEncoding&#x3D;utf8</span><br><span class="line">spring.datasource.username &#x3D; apolloconfig</span><br><span class="line">spring.datasource.password &#x3D; 123456</span><br></pre></td></tr></table></figure><p>修改启动脚本：</p><p>将官网上的startup.sh内容替换进来 <a href="https://github.com/ctripcorp/apollo/blob/1.5.1/scripts/apollo-on-kubernetes/apollo-config-server/scripts/startup-kubernetes.sh" target="_blank" rel="noopener">脚本地址</a></p><p> 添加一行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">APOLLO_CONFIG_SERVICE_NAME&#x3D;$(hostname -i)</span><br></pre></td></tr></table></figure><p>自行优化JVM</p><p>添加执行权限</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod u+x scripts&#x2F;startup.sh</span><br></pre></td></tr></table></figure><h4 id="通过dockerfile构建镜像"><a href="#通过dockerfile构建镜像" class="headerlink" title="通过dockerfile构建镜像"></a>通过dockerfile构建镜像</h4><p>编写dockerfile：<a href="https://github.com/ctripcorp/apollo/blob/1.5.1/scripts/apollo-on-kubernetes/apollo-config-server/Dockerfile" target="_blank" rel="noopener"> 官方地址</a></p><p>Dockerfile</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM harbor.od.com&#x2F;base&#x2F;jre8:8u112</span><br><span class="line"></span><br><span class="line">ENV VERSION 1.5.1</span><br><span class="line"></span><br><span class="line">RUN ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime &amp;&amp;\</span><br><span class="line">    echo &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone</span><br><span class="line"></span><br><span class="line">ADD apollo-configservice-$&#123;VERSION&#125;.jar &#x2F;apollo-configservice&#x2F;apollo-configservice.jar</span><br><span class="line">ADD config&#x2F; &#x2F;apollo-configservice&#x2F;config</span><br><span class="line">ADD scripts&#x2F; &#x2F;apollo-configservice&#x2F;scripts</span><br><span class="line"></span><br><span class="line">CMD [&quot;&#x2F;apollo-configservice&#x2F;scripts&#x2F;startup.sh&quot;]</span><br></pre></td></tr></table></figure><p>通过dockerfile构建镜像并推送到镜像仓库</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build . -t harbor.od.com&#x2F;infra&#x2F;apollo-configservice:v1.5.1</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;apollo-configservice:v1.5.1</span><br></pre></td></tr></table></figure><h3 id="编写资源配置清单"><a href="#编写资源配置清单" class="headerlink" title="编写资源配置清单"></a>编写资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-configservice</span><br></pre></td></tr></table></figure><p>cm.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: apollo-configservice-cm</span><br><span class="line">  namespace: infra</span><br><span class="line">data:</span><br><span class="line">  application-github.properties: |</span><br><span class="line">    # DataSource</span><br><span class="line">    spring.datasource.url &#x3D; jdbc:mysql:&#x2F;&#x2F;mysql.od.com:3306&#x2F;ApolloConfigDB?characterEncoding&#x3D;utf8</span><br><span class="line">    spring.datasource.username &#x3D; apolloconfig</span><br><span class="line">    spring.datasource.password &#x3D; 123456</span><br><span class="line">    eureka.service.url &#x3D; http:&#x2F;&#x2F;config.od.com&#x2F;eureka</span><br><span class="line">  app.properties: |</span><br><span class="line">    appId&#x3D;100003171</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-configservice&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: apollo-configservice</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: apollo-configservice</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: apollo-configservice</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: apollo-configservice </span><br><span class="line">        name: apollo-configservice</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">      - name: configmap-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: apollo-configservice-cm</span><br><span class="line">      containers:</span><br><span class="line">      - name: apollo-configservice</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;apollo-configservice:v1.5.1</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: configmap-volume</span><br><span class="line">          mountPath: &#x2F;apollo-configservice&#x2F;config</span><br><span class="line">        terminationMessagePath: &#x2F;dev&#x2F;termination-log</span><br><span class="line">        terminationMessagePolicy: File</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-configservice&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: apollo-configservice</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector: </span><br><span class="line">    app: apollo-configservice</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-configservice&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: apollo-configservice</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: config.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: apollo-configservice</span><br><span class="line">          servicePort: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单："><a href="#应用资源配置清单：" class="headerlink" title="应用资源配置清单："></a>应用资源配置清单：</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-configservice&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-configservice&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-configservice&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>检查启动情况</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-configservice]# kubectl get pod -n infra</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">apollo-configservice-5f6555448-slw6h   1&#x2F;1     Running   0          24s</span><br></pre></td></tr></table></figure><p>查看pod启动日志</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 2020-06-09 13:21:20.370  INFO 40 --- [ost-startStop-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...</span><br><span class="line">2020-06-09 13:21:20.799  INFO 40 --- [ost-startStop-1] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.</span><br></pre></td></tr></table></figure><p> 需要等到eureka启动以后才可以，接下来使用浏览器访问config.od.com:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gflyzk21pxj31hm0u0wne.jpg" alt="config.od.com访问界面"></p><h2 id="交付adminservice"><a href="#交付adminservice" class="headerlink" title="交付adminservice"></a>交付adminservice</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;dockerfile&#x2F;apollo-adminservice</span><br><span class="line">unzip -o &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apollo-adminservice-1.5.1-github.zip -d &#x2F;data&#x2F;dockerfile&#x2F;apollo-adminservice&#x2F;</span><br><span class="line">cd &#x2F;data&#x2F;dockerfile&#x2F;apollo-adminservice&#x2F;</span><br></pre></td></tr></table></figure><p>由于使用了configmap资源将配置文件挂载出来了，所以不在修改配置文件，如需修改配置文件，请参考部署apollo-configservice时候的修改方法：</p><p>修改startup.sh: <a href="https://github.com/ctripcorp/apollo/blob/master/scripts/apollo-on-kubernetes/apollo-admin-server/scripts/startup-kubernetes.sh" target="_blank" rel="noopener">官方地址</a></p><p>将端口修改为：8080</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-adminservice]# vim scripts&#x2F;startup.sh</span><br><span class="line">SERVER_PORT&#x3D;8080</span><br><span class="line">APOLLO_ADMIN_SERVICE_NAME&#x3D;$(hostname -i)</span><br><span class="line">[root@wang-200 apollo-adminservice]# chmod u+x scripts&#x2F;startup.sh</span><br></pre></td></tr></table></figure><p>制作dockerfile：</p><p>dockerfile</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM stanleyws&#x2F;jre8:8u112</span><br><span class="line"></span><br><span class="line">ENV VERSION 1.5.1</span><br><span class="line"></span><br><span class="line">RUN ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime &amp;&amp;\</span><br><span class="line">    echo &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone</span><br><span class="line"></span><br><span class="line">ADD apollo-adminservice-$&#123;VERSION&#125;.jar &#x2F;apollo-adminservice&#x2F;apollo-adminservice.jar</span><br><span class="line">ADD config&#x2F; &#x2F;apollo-adminservice&#x2F;config</span><br><span class="line">ADD scripts&#x2F; &#x2F;apollo-adminservice&#x2F;scripts</span><br><span class="line"></span><br><span class="line">CMD [&quot;&#x2F;apollo-adminservice&#x2F;scripts&#x2F;startup.sh&quot;]</span><br></pre></td></tr></table></figure><p>通过dockerfile制作镜像并推送到镜像仓库</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build -t harbor.od.com&#x2F;infra&#x2F;apollo-adminservice:v1.5.1 .</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;apollo-adminservice:v1.5.1</span><br></pre></td></tr></table></figure><h3 id="制作资源配置清单"><a href="#制作资源配置清单" class="headerlink" title="制作资源配置清单"></a>制作资源配置清单</h3><p>创建文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-adminservice</span><br></pre></td></tr></table></figure><p>cm.yaml </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-adminservice&#x2F;cm.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: apollo-adminservice-cm</span><br><span class="line">  namespace: infra</span><br><span class="line">data:</span><br><span class="line">  application-github.properties: |</span><br><span class="line">    # DataSource</span><br><span class="line">    spring.datasource.url &#x3D; jdbc:mysql:&#x2F;&#x2F;mysql.od.com:3306&#x2F;ApolloConfigDB?characterEncoding&#x3D;utf8</span><br><span class="line">    spring.datasource.username &#x3D; apolloconfig</span><br><span class="line">    spring.datasource.password &#x3D; 123456</span><br><span class="line">    eureka.service.url &#x3D; http:&#x2F;&#x2F;config.od.com&#x2F;eureka</span><br><span class="line">  app.properties: |</span><br><span class="line">    appId&#x3D;100003172</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-adminservice&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: apollo-adminservice</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: apollo-adminservice</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: apollo-adminservice</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: apollo-adminservice </span><br><span class="line">        name: apollo-adminservice</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">      - name: configmap-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: apollo-adminservice-cm</span><br><span class="line">      containers:</span><br><span class="line">      - name: apollo-adminservice</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;apollo-adminservice:v1.5.1</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: configmap-volume</span><br><span class="line">          mountPath: &#x2F;apollo-adminservice&#x2F;config</span><br><span class="line">        terminationMessagePath: &#x2F;dev&#x2F;termination-log</span><br><span class="line">        terminationMessagePolicy: File</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-1"><a href="#应用资源配置清单-1" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-adminservice&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-adminservice&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><p>查看pod启动情况</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-adminservice]# kubectl get pod -n infra</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">apollo-adminservice-5cccf97c64-g2pl6   1&#x2F;1     Running   0          74s</span><br></pre></td></tr></table></figure><p>查看程序启动日志</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 2020-06-09 13:39:38.269  INFO 40 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)</span><br><span class="line">2020-06-09 13:39:38.664  INFO 40 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]</span><br></pre></td></tr></table></figure><p> 通过config.od.com检查是否注册到了eureka：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gflzgb20blj31u00asmzz.jpg" alt="config注册到eureka"></p><h2 id="交付portal"><a href="#交付portal" class="headerlink" title="交付portal"></a>交付portal</h2><p>解压portal压缩包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;dockerfile&#x2F;apollo-portal</span><br><span class="line">unzip -o &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apollo-portal-1.5.1-github.zip -d &#x2F;data&#x2F;dockerfile&#x2F;apollo-portal&#x2F;</span><br><span class="line">cd &#x2F;data&#x2F;dockerfile&#x2F;apollo-portal&#x2F;</span><br></pre></td></tr></table></figure><p>由于portal使用的是另一个portaldb，我们需要在数据库中新建portdb，并初始化：<a href="https://github.com/ctripcorp/apollo/blob/master/scripts/db/migration/portaldb/V1.0.0__initialization.sql" target="_blank" rel="noopener">初始化脚本</a></p><p>下载下来脚本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget -O apollo-portal.sql https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ctripcorp&#x2F;apollo&#x2F;1.5.1&#x2F;scripts&#x2F;db&#x2F;migration&#x2F;portaldb&#x2F;V1.0.0__initialization.sql</span><br></pre></td></tr></table></figure><p>初始化apollo-portal数据库</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -h wang-12 -p &lt; apollo-portal.sql</span><br></pre></td></tr></table></figure><p>创建用户并授权：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-portal]# mysql -h wang-12 -p</span><br><span class="line">MariaDB [(none)]&gt; grant INSERT,DELETE,UPDATE,SELECT on ApolloPortalDB.* to &quot;apolloportal&quot;@&quot;192.168.70.%&quot; identified by &quot;123456&quot;;</span><br></pre></td></tr></table></figure><p>查看数据库中的部门</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [ApolloPortalDB]&gt; select * from ServerConfig\G ;</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">                       Id: 2</span><br><span class="line">                      Key: organizations</span><br><span class="line">                    Value: [&#123;&quot;orgId&quot;:&quot;TEST1&quot;,&quot;orgName&quot;:&quot;样例部门1&quot;&#125;,&#123;&quot;orgId&quot;:&quot;TEST2&quot;,&quot;orgName&quot;:&quot;样例部门2&quot;&#125;]</span><br><span class="line">                  Comment: 部门列表</span><br><span class="line">                IsDeleted:  </span><br><span class="line">     DataChange_CreatedBy: default</span><br></pre></td></tr></table></figure><p>修改数据库,创建部门</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update ServerConfig set Value&#x3D;&#39;[&#123;&quot;orgId&quot;:&quot;od01&quot;,&quot;orgName&quot;:&quot;Linux学院&quot;&#125;,&#123;&quot;orgId&quot;:&quot;od02&quot;,&quot;orgName&quot;:&quot;云计算学院&quot;&#125;,&#123;&quot;orgId&quot;:&quot;od03&quot;,&quot;orgName&quot;:&quot;Python学院&quot;&#125;]&#39; where Id&#x3D;2;</span><br></pre></td></tr></table></figure><p> 由于使用concigmap资源，故之做介绍，不在这里修改：</p><p>配置portal meta serice：</p><p>这里列出的是支持的环境列表配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-portal]# vim &#x2F;data&#x2F;dockerfile&#x2F;apollo-portal&#x2F;config&#x2F;apollo-env.properties</span><br></pre></td></tr></table></figure><p>修改startup.sh <a href="https://raw.githubusercontent.com/ctripcorp/apollo/1.5.1/scripts/apollo-on-kubernetes/apollo-portal-server/scripts/startup-kubernetes.sh" target="_blank" rel="noopener">官方地址raw</a>  <a href="https://github.com/ctripcorp/apollo/blob/master/scripts/apollo-on-kubernetes/apollo-portal-server/scripts/startup-kubernetes.sh" target="_blank" rel="noopener">官方地址html</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-portal]# vim scripts&#x2F;startup.sh</span><br><span class="line">SERVER_PORT&#x3D;8080</span><br><span class="line">APOLLO_PORTAL_SERVICE_NAME&#x3D;$(hostname -i)</span><br><span class="line"></span><br><span class="line">[root@wang-200 apollo-portal]# chmod u+x scripts&#x2F;startup.sh</span><br></pre></td></tr></table></figure><h3 id="制作镜像"><a href="#制作镜像" class="headerlink" title="制作镜像"></a>制作镜像</h3><p>Dockerfile文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM stanleyws&#x2F;jre8:8u112</span><br><span class="line"></span><br><span class="line">ENV VERSION 1.5.1</span><br><span class="line"></span><br><span class="line">RUN ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime &amp;&amp;\</span><br><span class="line">    echo &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone</span><br><span class="line"></span><br><span class="line">ADD apollo-portal-$&#123;VERSION&#125;.jar &#x2F;apollo-portal&#x2F;apollo-portal.jar</span><br><span class="line">ADD config&#x2F; &#x2F;apollo-portal&#x2F;config</span><br><span class="line">ADD scripts&#x2F; &#x2F;apollo-portal&#x2F;scripts</span><br><span class="line"></span><br><span class="line">CMD [&quot;&#x2F;apollo-portal&#x2F;scripts&#x2F;startup.sh&quot;]</span><br></pre></td></tr></table></figure><p>通过dockerfile制作镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build . -t harbor.od.com&#x2F;infra&#x2F;apollo-portal:v1.5.1</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;apollo-portal:v1.5.1</span><br></pre></td></tr></table></figure><h3 id="编写资源配置清单-1"><a href="#编写资源配置清单-1" class="headerlink" title="编写资源配置清单"></a>编写资源配置清单</h3><p>创建资源配置清单文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal</span><br></pre></td></tr></table></figure><p>cm.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal&#x2F;cm.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: apollo-portal-cm</span><br><span class="line">  namespace: infra</span><br><span class="line">data:</span><br><span class="line">  application-github.properties: |</span><br><span class="line">    # DataSource</span><br><span class="line">    spring.datasource.url &#x3D; jdbc:mysql:&#x2F;&#x2F;mysql.od.com:3306&#x2F;ApolloPortalDB?characterEncoding&#x3D;utf8</span><br><span class="line">    spring.datasource.username &#x3D; apolloportal</span><br><span class="line">    spring.datasource.password &#x3D; 123456</span><br><span class="line">  app.properties: |</span><br><span class="line">    appId&#x3D;100003173</span><br><span class="line">  apollo-env.properties: |</span><br><span class="line">    dev.meta&#x3D;http:&#x2F;&#x2F;config.od.com</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: apollo-portal</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: apollo-portal</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: apollo-portal</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: apollo-portal </span><br><span class="line">        name: apollo-portal</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">      - name: configmap-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: apollo-portal-cm</span><br><span class="line">      containers:</span><br><span class="line">      - name: apollo-portal</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;apollo-portal:v1.5.1</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: configmap-volume</span><br><span class="line">          mountPath: &#x2F;apollo-portal&#x2F;config</span><br><span class="line">        terminationMessagePath: &#x2F;dev&#x2F;termination-log</span><br><span class="line">        terminationMessagePolicy: File</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: apollo-portal</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector: </span><br><span class="line">    app: apollo-portal</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: apollo-portal</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: portal.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: apollo-portal</span><br><span class="line">          servicePort: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-2"><a href="#应用资源配置清单-2" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-portal&#x2F;cm.yaml</span><br><span class="line">kubectl create -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-portal&#x2F;deploy.yaml</span><br><span class="line">kubectl create -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-portal&#x2F;svc.yaml</span><br><span class="line">kubectl create -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;apollo-portal&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>查看pod运行状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 apollo-portal]# kubectl get pod -n infra | grep portal</span><br><span class="line">apollo-portal-57bc86966d-vzc46         1&#x2F;1     Running   0          24s</span><br></pre></td></tr></table></figure><p>网页访问 portal.od.com</p><p>默认用户名：apollo</p><p>默认密码：  admin</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm4nstac8j31j40mqtip.jpg" alt="apollo登陆界面"></p><p>登陆成功以后，先改密码，好习惯 :)</p><p>到此，apollo的三个组件都已经交付到k8s里了。</p><h2 id="配置服务使用apollo配置中心"><a href="#配置服务使用apollo配置中心" class="headerlink" title="配置服务使用apollo配置中心"></a>配置服务使用apollo配置中心</h2><p>使用配置中心，需要开发对代码进行调整，将一些配置，通过变量的形式配置到apollo中，服务通过配置中心来获取具体的配置</p><p>在配置中心修改新增如下配置：</p><p>dubbo-demo-service  dubbo服务提供者</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm4ut85dij31jq0muq6i.jpg" alt="增加配置"></p><p>新增配置，并且发布</p><p>配置信息1: dubbo.registry  zookeeper://zk1.od.com:2181  zookeeper源地址</p><p>配置信息2: dubbo.port     20880    dubbo服务监听端口</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm58kil3dj31yk0rm7a8.jpg" alt="apollo添加参数"></p><p> 重新打包镜像，使用apollo版本的代码：</p><p> 修改deploy.yaml，将镜像使用我们刚刚打包的这个：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# vim &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-server&#x2F;deploy.yml </span><br><span class="line">      - name: dubbo-demo-service</span><br><span class="line">        image: harbor.od.com&#x2F;app&#x2F;dubbo-demo-service:apollo_20200609_1800</span><br><span class="line">        env:</span><br><span class="line">        - name: C_OPTS</span><br><span class="line">          value: -Denv&#x3D;dev -Dapollo.meta&#x3D;http:&#x2F;&#x2F;config.od.com</span><br></pre></td></tr></table></figure><p> 应用资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-server&#x2F;deploy.yml</span><br></pre></td></tr></table></figure><p>等服务更新后，我们看到dubbo-demo-service已经注册进来了</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm5usrrmhj31nu0gkq6p.jpg" alt="dubbo-demo-service注册成功"></p><h3 id="创建dubbo服务消费者"><a href="#创建dubbo服务消费者" class="headerlink" title="创建dubbo服务消费者"></a>创建dubbo服务消费者</h3><p>apollo中新建一个项目：dubbo-demo-web,新建配置dubbo.registry,值为zookeeper地址</p><p>项目信息：dubbo-demo-web  dubbo服务消费者</p><p>配置信息1:  dubbo.registry    zookeeper://zk1.od.com:2181  zookeeper源地址</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm5nc3xc0j31yo0ksafg.jpg" alt="项目和配置"></p><p> 重新打包dubbo-demo-consumer镜像，使用apollo版本的代码：</p><p> 修改deploy.yaml，将镜像使用我们刚刚打包的这个：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# vim &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer&#x2F;deploy.yml </span><br><span class="line">      - name: dubbo-demo-consumer</span><br><span class="line">        image: harbor.od.com&#x2F;app&#x2F;dubbo-demo-consumer:apollo_20200609_1800</span><br><span class="line">        env:</span><br><span class="line">        - name: C_OPTS</span><br><span class="line">          value: -Denv&#x3D;dev -Dapollo.meta&#x3D;http:&#x2F;&#x2F;config.od.com</span><br></pre></td></tr></table></figure><p> 应用资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><p>重启后验证注册成功。</p><h3 id="通过dubbo-monitor查看"><a href="#通过dubbo-monitor查看" class="headerlink" title="通过dubbo-monitor查看"></a>通过dubbo-monitor查看</h3><p>注意zookeeper源地址</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm7d8sihlj31sw09adie.jpg" alt="consumer和service注册到zookeeper"></p><h2 id="分环境使用apollo配置中心"><a href="#分环境使用apollo配置中心" class="headerlink" title="分环境使用apollo配置中心"></a>分环境使用apollo配置中心</h2><p>要进行分环境，需要将现有实验环境进行拆分</p><p><strong>portal服务，可以各个环境共用，但是apollo-adminservice和apollo-configservice必须要分开。</strong></p><h3 id="准备zookeeper"><a href="#准备zookeeper" class="headerlink" title="准备zookeeper"></a>准备zookeeper</h3><p>zk环境拆分为test和prod环境</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# vi &#x2F;var&#x2F;named&#x2F;od.com.zone</span><br><span class="line">zk-test         A       192.168.70.11</span><br><span class="line">zk-prod         A       192.168.70.12</span><br></pre></td></tr></table></figure><p>重启named并测试</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# systemctl restart named       </span><br><span class="line">[root@wang-12 ~]# dig -t A zk-test.od.com +short    </span><br><span class="line">192.168.70.11</span><br></pre></td></tr></table></figure><p>namespace 分环境，创建test 和prod</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create ns test</span><br><span class="line">kubectl create ns prod</span><br></pre></td></tr></table></figure><p>创建secret，确保harbor的账号“harbor”存在</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create secret docker-registry harbor --docker-server&#x3D;harbor.od.com --docker-username&#x3D;harbor --docker-password&#x3D;Harbor12345 -n test</span><br><span class="line">kubectl create secret docker-registry harbor --docker-server&#x3D;harbor.od.com --docker-username&#x3D;harbor --docker-password&#x3D;Harbor12345 -n prod</span><br></pre></td></tr></table></figure><h3 id="准备数据库"><a href="#准备数据库" class="headerlink" title="准备数据库"></a>准备数据库</h3><p>数据库进行拆分，因实验资源有限，故使用分库的形式模拟分环境</p><p>修改数据库初始化脚本，分别创建ApolloConfigTestDB和ApolloConfigProdDB</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp apolloconfig.sql apolloconfig-test.sql</span><br><span class="line">sed -i &quot;s&amp;ApolloConfigDB&amp;ApolloConfigTestDB&amp;&quot; apolloconfig-test.sql </span><br><span class="line">mysql -h wang-12 -p &lt; apolloconfig-test.sql </span><br><span class="line"></span><br><span class="line">cp apolloconfig.sql apolloconfig-prod.sql</span><br><span class="line">sed -i &quot;s&amp;ApolloConfigDB&amp;ApolloConfigProdDB&amp;&quot; apolloconfig-prod.sql </span><br><span class="line">mysql -h wang-12 -p &lt; apolloconfig-prod.sql</span><br></pre></td></tr></table></figure><p>示例图：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm7zc48fjj30lk02d3yr.jpg" alt="示例图"></p><p> 修改数据库中eureka的地址，这里用到了两个新的域名，自行在bind9中添加解析(我用的默认解析)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; update ApolloConfigTestDB.ServerConfig set ServerConfig.Value&#x3D;&quot;http:&#x2F;&#x2F;config-test.od.com&#x2F;eureka&quot; where ServerConfig.Key&#x3D;&quot;eureka.service.url&quot;;</span><br><span class="line"></span><br><span class="line">MariaDB [(none)]&gt; grant INSERT,DELETE,UPDATE,SELECT on ApolloConfigTestDB.* to &quot;apolloconfig&quot;@&quot;192.168.70.%&quot; identified by &quot;123456&quot;;</span><br><span class="line"></span><br><span class="line">MariaDB [(none)]&gt; update ApolloConfigProdDB.ServerConfig set ServerConfig.Value&#x3D;&quot;http:&#x2F;&#x2F;config-prod.od.com&#x2F;eureka&quot; where ServerConfig.Key&#x3D;&quot;eureka.service.url&quot;;</span><br><span class="line"></span><br><span class="line">MariaDB [(none)]&gt; grant INSERT,DELETE,UPDATE,SELECT on ApolloConfigProdDB.* to &quot;apolloconfig&quot;@&quot;192.168.70.%&quot; identified by &quot;123456&quot;;</span><br></pre></td></tr></table></figure><p>修改portal数据，支持fat和pro环境：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update ApolloPortalDB.ServerConfig set Value&#x3D;&#39;fat,pro&#39; where Id&#x3D;1;</span><br></pre></td></tr></table></figure><p>修改portal的cm资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# vim &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal&#x2F;cm.yaml</span><br><span class="line">  apollo-env.properties: |</span><br><span class="line">    fat.meta&#x3D;http:&#x2F;&#x2F;config-test.od.com</span><br><span class="line">    pro.meta&#x3D;http:&#x2F;&#x2F;config-prod.od.com</span><br><span class="line"></span><br><span class="line">[root@wang-200 ~]# kubectl apply -f &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;apollo-portal&#x2F;cm.yaml</span><br></pre></td></tr></table></figure><p>通过浏览器，我们确认数据已经改变</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfm87rqx22j31po0nedjw.jpg" alt="image-20200609184417637"></p><p>分别创建修改两个环境的资源配置文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;test&#x2F;&#123;apollo-adminservice,apollo-configservice,dubbo-demo-server,dubbo-demo-consumer&#125;</span><br><span class="line">mkdir -p &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;prod&#x2F;&#123;apollo-adminservice,apollo-configservice,dubbo-demo-server,dubbo-demo-consumer&#125;</span><br></pre></td></tr></table></figure><h4 id="部署test环境的apollo-configservice"><a href="#部署test环境的apollo-configservice" class="headerlink" title="部署test环境的apollo-configservice"></a>部署test环境的apollo-configservice</h4><p>将之前的资源配置清单cp到对应环境的目录中，进行修改：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp apollo-configservice&#x2F;* test&#x2F;apollo-configservice&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: infra&amp;namespace: test&amp;&quot; test&#x2F;apollo-configservice&#x2F;*.yaml</span><br><span class="line">sed -i &quot;s&amp;ApolloConfigDB&amp;ApolloConfigTestDB&amp;&quot; test&#x2F;apollo-configservice&#x2F;cm.yaml </span><br><span class="line">sed -i &quot;s&amp;http:&#x2F;&#x2F;config.od.com&#x2F;eureka&amp;http:&#x2F;&#x2F;config-test.od.com&#x2F;eureka&amp;&quot; test&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">sed -i &quot;s&amp;config.od.com&amp;config-test.od.com&amp;&quot; test&#x2F;apollo-configservice&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>执行资源配置清单</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f test&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f test&#x2F;apollo-configservice&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f test&#x2F;apollo-configservice&#x2F;svc.yaml </span><br><span class="line">kubectl apply -f test&#x2F;apollo-configservice&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p> 服务已经注册进来了</p><h4 id="部署test环境的apollo-adminservice"><a href="#部署test环境的apollo-adminservice" class="headerlink" title="部署test环境的apollo-adminservice"></a>部署test环境的apollo-adminservice</h4><p>修改apollo-adminservice的资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp apollo-adminservice&#x2F;* test&#x2F;apollo-adminservice&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: infra&amp;namespace: test&amp;&quot; test&#x2F;apollo-adminservice&#x2F;*.yaml</span><br><span class="line">sed -i &quot;s&amp;ApolloConfigDB&amp;ApolloConfigTestDB&amp;&quot; test&#x2F;apollo-adminservice&#x2F;cm.yaml </span><br><span class="line">sed -i &quot;s&amp;http:&#x2F;&#x2F;config.od.com&#x2F;eureka&amp;http:&#x2F;&#x2F;config-test.od.com&#x2F;eureka&amp;&quot; test&#x2F;apollo-adminservice&#x2F;cm.yaml</span><br></pre></td></tr></table></figure><p>应用资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f test&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f test&#x2F;apollo-configservice&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><h4 id="web端验证"><a href="#web端验证" class="headerlink" title="web端验证"></a>web端验证</h4><p><a href="http://config-test.od.com/" target="_blank" rel="noopener">http://config-test.od.com/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn0ptbb6uj31s60fitc0.jpg" alt="image-20200610111024199"></p><h4 id="部署prod环境的apollo-configservice"><a href="#部署prod环境的apollo-configservice" class="headerlink" title="部署prod环境的apollo-configservice"></a>部署prod环境的apollo-configservice</h4><p>将之前的资源配置清单cp到对应环境的目录中，进行修改：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp apollo-configservice&#x2F;* prod&#x2F;apollo-configservice&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: infra&amp;namespace: prod&amp;&quot; prod&#x2F;apollo-configservice&#x2F;*.yaml</span><br><span class="line">sed -i &quot;s&amp;ApolloConfigDB&amp;ApolloConfigProdDB&amp;&quot; prod&#x2F;apollo-configservice&#x2F;cm.yaml </span><br><span class="line">sed -i &quot;s&amp;http:&#x2F;&#x2F;config.od.com&#x2F;eureka&amp;http:&#x2F;&#x2F;config-prod.od.com&#x2F;eureka&amp;&quot; prod&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">sed -i &quot;s&amp;config.od.com&amp;config-prod.od.com&amp;&quot; prod&#x2F;apollo-configservice&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>执行资源配置清单</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prod&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f prod&#x2F;apollo-configservice&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f prod&#x2F;apollo-configservice&#x2F;svc.yaml </span><br><span class="line">kubectl apply -f prod&#x2F;apollo-configservice&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p> 服务已经注册进来了</p><h4 id="部署prod环境的apollo-adminservice"><a href="#部署prod环境的apollo-adminservice" class="headerlink" title="部署prod环境的apollo-adminservice"></a>部署prod环境的apollo-adminservice</h4><p>修改apollo-adminservice的资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp apollo-adminservice&#x2F;* prod&#x2F;apollo-adminservice&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: infra&amp;namespace: prod&amp;&quot; prod&#x2F;apollo-adminservice&#x2F;*.yaml</span><br><span class="line">sed -i &quot;s&amp;ApolloConfigDB&amp;ApolloConfigProdDB&amp;&quot; prod&#x2F;apollo-adminservice&#x2F;cm.yaml </span><br><span class="line">sed -i &quot;s&amp;http:&#x2F;&#x2F;config.od.com&#x2F;eureka&amp;http:&#x2F;&#x2F;config-prod.od.com&#x2F;eureka&amp;&quot; prod&#x2F;apollo-adminservice&#x2F;cm.yaml</span><br></pre></td></tr></table></figure><p>应用资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prod&#x2F;apollo-configservice&#x2F;cm.yaml</span><br><span class="line">kubectl apply -f prod&#x2F;apollo-configservice&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><h4 id="web端验证-1"><a href="#web端验证-1" class="headerlink" title="web端验证"></a>web端验证</h4><p><a href="http://config-prod.od.com/" target="_blank" rel="noopener">http://config-prod.od.com/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn286y2wfj31sc0fewhw.jpg" alt="config-prod示例图"></p><p>两个服务都已经注册进来了，删除portal数据库中存储的关于之前项目的配置，接下来启动portal项目：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mysql -h mysql.od.com -p</span><br><span class="line">MariaDB [(none)]&gt; use ApolloPortalDB ;</span><br><span class="line">MariaDB [ApolloPortalDB]&gt; truncate table App;</span><br><span class="line">MariaDB [ApolloPortalDB]&gt; truncate table AppNamespace;</span><br></pre></td></tr></table></figure><p>查看pod是否已经起来了</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n infra | grep apollo-portal</span><br><span class="line">apollo-portal-57bc86966d-s7qcn         1&#x2F;1     Running   0          66s</span><br></pre></td></tr></table></figure><h3 id="添加系统参数"><a href="#添加系统参数" class="headerlink" title="添加系统参数"></a>添加系统参数</h3><p>管理员工具 - 系统参数  <a href="http://portal.od.com/server_config.html" target="_blank" rel="noopener">http://portal.od.com/server_config.html</a></p><p>key : apollo.portal.envs ;    value : fat, pro ;    comment : 可支持的环境列表</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn5y9dttkj31di0moq5y.jpg" alt="添加系统参数"></p><p>打开portal.od.com验证，并且创建两个项目：</p><p>首先创建dubbo-demo-service</p><p>项目信息：</p><p>Appid: dubbo-demo-service  应用名称：dubbo服务提供者</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn62maid2j31o00mgjvy.jpg" alt="image-20200610141542406"></p><p> 添加配置：两个环境都添加上：注意连接地址一个是zk-test.od.com,一个是zk-prod.od.com</p><p>服务1:  key: dubbo.registry        value: zookeeper://zk-test.od.com:2181     command: dubbo数据源</p><p>服务2:  key: dubbo.port        value: 20880     command:  dubbo端口号</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn689il9rj31s20d8tch.jpg" alt="image-20200610142108166"></p><p> 接下来创建dubbo-demo-web项目：同样是两个环境都发布，注意一个是zk-test.od.com,一个是zk-prod.od.com</p><p>项目信息： Appid: dubbo-demo-web             应用名称: dubbo服务消费者    部门：云计算学院(od02)</p><p>服务1:  key: dubbo.registry           value: zookeeper://zk-test.od.com:2181        command: dubbo数据源</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn6bmc1ncj31rq0ag77c.jpg" alt="image-20200610142421764"></p><h3 id="交付dubbo服务分环境交付"><a href="#交付dubbo服务分环境交付" class="headerlink" title="交付dubbo服务分环境交付"></a>交付dubbo服务分环境交付</h3><h4 id="交付test环境的dubbo-demo-server"><a href="#交付test环境的dubbo-demo-server" class="headerlink" title="交付test环境的dubbo-demo-server"></a>交付test环境的dubbo-demo-server</h4><p>同样操作，修改之前项目的资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp dubbo-server&#x2F;* test&#x2F;dubbo-demo-server&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: app&amp;namespace: test&amp;&quot; test&#x2F;dubbo-demo-server&#x2F;deploy.yaml</span><br><span class="line">sed -i &quot;s&amp;config.od.com&amp;config-test.od.com&amp;&quot; test&#x2F;dubbo-demo-server&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><p>应用资源配置清单</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f test&#x2F;dubbo-demo-server&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><h4 id="交付test环境的dubbo-demo-consumer"><a href="#交付test环境的dubbo-demo-consumer" class="headerlink" title="交付test环境的dubbo-demo-consumer"></a>交付test环境的dubbo-demo-consumer</h4><p>修改之前项目的资源配置清单</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp dubbo-consumer&#x2F;* test&#x2F;dubbo-demo-consumer&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: app&amp;namespace: test&amp;&quot; test&#x2F;dubbo-demo-consumer&#x2F;*.yaml</span><br><span class="line">sed -i &quot;s&amp;config.od.com&amp;config-test.od.com&amp;&quot; test&#x2F;dubbo-demo-consumer&#x2F;deploy.yaml</span><br><span class="line">sed -i &quot;s&amp;demo.od.com&amp;demo-test.od.com&amp;&quot; test&#x2F;dubbo-demo-consumer&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p> 应用test环境的dubbo-consumer资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f test&#x2F;dubbo-demo-consumer&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f test&#x2F;dubbo-demo-consumer&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f test&#x2F;dubbo-demo-consumer&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><h4 id="交付prod环境的dubbo-demo-server服务"><a href="#交付prod环境的dubbo-demo-server服务" class="headerlink" title="交付prod环境的dubbo-demo-server服务"></a>交付prod环境的dubbo-demo-server服务</h4><h4 id="交付test环境的dubbo-demo-server-1"><a href="#交付test环境的dubbo-demo-server-1" class="headerlink" title="交付test环境的dubbo-demo-server"></a>交付test环境的dubbo-demo-server</h4><p>同样操作，修改之前项目的资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp dubbo-server&#x2F;* prod&#x2F;dubbo-demo-server&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: app&amp;namespace: prod&amp;&quot; prod&#x2F;dubbo-demo-server&#x2F;deploy.yaml</span><br><span class="line">sed -i &quot;s&amp;config.od.com&amp;config-prod.od.com&amp;&quot; prod&#x2F;dubbo-demo-server&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><p>应用资源配置清单</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prod&#x2F;dubbo-demo-server&#x2F;deploy.yaml</span><br></pre></td></tr></table></figure><h4 id="交付prod环境的dubbo-demo-consumer服务"><a href="#交付prod环境的dubbo-demo-consumer服务" class="headerlink" title="交付prod环境的dubbo-demo-consumer服务"></a>交付prod环境的dubbo-demo-consumer服务</h4><p>修改之前项目的资源配置清单</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp dubbo-consumer&#x2F;* prod&#x2F;dubbo-demo-consumer&#x2F;</span><br><span class="line">sed -i &quot;s&amp;namespace: app&amp;namespace: prod&amp;&quot; prod&#x2F;dubbo-demo-consumer&#x2F;*.yaml</span><br><span class="line">sed -i &quot;s&amp;config.od.com&amp;config-prod.od.com&amp;&quot; prod&#x2F;dubbo-demo-consumer&#x2F;deploy.yaml</span><br><span class="line">sed -i &quot;s&amp;demo.od.com&amp;demo-prod.od.com&amp;&quot; prod&#x2F;dubbo-demo-consumer&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p> 应用test环境的dubbo-consumer资源配置清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prod&#x2F;dubbo-demo-consumer&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f prod&#x2F;dubbo-demo-consumer&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f prod&#x2F;dubbo-demo-consumer&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>访问web界面就有返回值了</p><p><a href="http://demo-test.od.com/hello" target="_blank" rel="noopener">http://demo-test.od.com/hello</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn6rz9tv5j318s0eujto.jpg" alt="image-20200610144004965"></p><p><a href="http://demo-prod.od.com/hello?name=prod" target="_blank" rel="noopener">http://demo-prod.od.com/hello?name=prod</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfn705vne8j311i0e476h.jpg" alt="image-20200610144756768"></p><p>这是如果我们在测试环境发版成功并测试没有问题，就可以将生产也改为相同的版本就可以了。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 实战交付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 老男孩 </tag>
            
            <tag> 实战交付 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二、交付-使用blue ocean流水线构建</title>
      <link href="/2020/06/05/%E4%BA%8C%E3%80%81%E4%BA%A4%E4%BB%98-%E4%BD%BF%E7%94%A8blue-ocean%E6%B5%81%E6%B0%B4%E7%BA%BF%E6%9E%84%E5%BB%BA/"/>
      <url>/2020/06/05/%E4%BA%8C%E3%80%81%E4%BA%A4%E4%BB%98-%E4%BD%BF%E7%94%A8blue-ocean%E6%B5%81%E6%B0%B4%E7%BA%BF%E6%9E%84%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="交付dubbo-demo-service到k8s"><a href="#交付dubbo-demo-service到k8s" class="headerlink" title="交付dubbo-demo-service到k8s"></a>交付dubbo-demo-service到k8s</h2><h3 id="使用jenkins创建一个新的项目"><a href="#使用jenkins创建一个新的项目" class="headerlink" title="使用jenkins创建一个新的项目"></a>使用jenkins创建一个新的项目</h3><p>dubbo-demo,选择流水线构建</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhfh5cyt9j30pf0afta7.jpg" alt="创建新的项目"></p><p> 勾选保存构建历史和指定项目为参数化构建项目：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhfifql1nj30ky09rdgg.jpg" alt="保存构建历史和参数化构建"></p><p>添加构建参数：以下配置项，是王导根据多年生产经验总结出来的<strong>甩锅大法</strong>：</p><p>Jenkins流水线配置的十个参数</p><ul><li>app_name -&gt; 项目名称–例：dubbo-demo-service</li><li>image_name -&gt; docker镜像名称–例：app/dubbo-demo-service</li><li>git_repo -&gt; 项目的git地址–例:<a href="https://gitee.com/wangzhangtao/dubbo-demo-service.git" target="_blank" rel="noopener">https://gitee.com/wangzhangtao/dubbo-demo-service.git</a></li><li>git_ver -&gt; 项目的git版本号cid（或分支）–例：master(尽量使用commit id)</li><li>add_tag -&gt; 镜像标签，日期时间戳–例：$git_ver_$add_tag=master_191124_1400</li><li>mvn_dir -&gt; 编译项目的目录–例：./</li><li>target_dir -&gt; 编译后jar包存放的地址–例：./dubbo-demo-service/target</li><li>mvn_cmd -&gt; 执行编译所用的命令，可选参数-e -q,忽略标准输出，只输出错误输出， mvn clean package -Dmaven.test.skip=true</li><li>base_image -&gt; 项目的docker底包, –例：base/jre8:8u112</li><li>maven -&gt; maven软件的版本；–例：3.6.1</li></ul><p>除了base_image和maven是choice parameter，其他都是string parameter</p><p>添加完成后，效果如图：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhgay3l0oj30m70j0tan.jpg" alt="image-20200605153619266"></p><p> 编写pipeline:仔细查看这个pipeline，里面都是我们上面编写的参数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent any </span><br><span class="line">    stages &#123;</span><br><span class="line">      stage(&#39;pull&#39;) &#123; &#x2F;&#x2F;get project code from repo </span><br><span class="line">        steps &#123;</span><br><span class="line">          sh &quot;git clone $&#123;params.git_repo&#125; $&#123;params.app_name&#125;&#x2F;$&#123;env.BUILD_NUMBER&#125; &amp;&amp; cd $&#123;params.app_name&#125;&#x2F;$&#123;env.BUILD_NUMBER&#125; &amp;&amp; git checkout $&#123;params.git_ver&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      stage(&#39;build&#39;) &#123; &#x2F;&#x2F;exec mvn cmd</span><br><span class="line">        steps &#123;</span><br><span class="line">          sh &quot;cd $&#123;params.app_name&#125;&#x2F;$&#123;env.BUILD_NUMBER&#125;  &amp;&amp; &#x2F;var&#x2F;jenkins_home&#x2F;maven-$&#123;params.maven&#125;&#x2F;bin&#x2F;$&#123;params.mvn_cmd&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      stage(&#39;package&#39;) &#123; &#x2F;&#x2F;move jar file into project_dir</span><br><span class="line">        steps &#123;</span><br><span class="line">          sh &quot;cd $&#123;params.app_name&#125;&#x2F;$&#123;env.BUILD_NUMBER&#125; &amp;&amp; cd $&#123;params.target_dir&#125; &amp;&amp; mkdir project_dir &amp;&amp; mv *.jar .&#x2F;project_dir&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      stage(&#39;image&#39;) &#123; &#x2F;&#x2F;build image and push to registry</span><br><span class="line">        steps &#123;</span><br><span class="line">          writeFile file: &quot;$&#123;params.app_name&#125;&#x2F;$&#123;env.BUILD_NUMBER&#125;&#x2F;Dockerfile&quot;, text: &quot;&quot;&quot;FROM harbor.od.com&#x2F;$&#123;params.base_image&#125;</span><br><span class="line">ADD $&#123;params.target_dir&#125;&#x2F;project_dir &#x2F;opt&#x2F;project_dir&quot;&quot;&quot;</span><br><span class="line">          sh &quot;cd  $&#123;params.app_name&#125;&#x2F;$&#123;env.BUILD_NUMBER&#125; &amp;&amp; docker build -t harbor.od.com&#x2F;$&#123;params.image_name&#125;:$&#123;params.git_ver&#125;_$&#123;params.add_tag&#125; . &amp;&amp; docker push harbor.od.com&#x2F;$&#123;params.image_name&#125;:$&#123;params.git_ver&#125;_$&#123;params.add_tag&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="第一次构建服务"><a href="#第一次构建服务" class="headerlink" title="第一次构建服务"></a>第一次构建服务</h3><p><strong>填写完以后执行bulid：第一次构建需要下载很多依赖包，时间很长，看别人抽根烟，喝杯茶~</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhik1hqidj30pc0jqace.jpg" alt="image-20200605165414887"></p><p> 经过漫长的等待后，已经构建完成了，可以点击open blue ocean 查看构建历史及过程：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhjlcbxtvj30v80dfdgu.jpg" alt="部署过程"></p><p> 检查harbor是否已经有这版镜像：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhjme9p1uj30p009kdgx.jpg" alt="刚刚推送的镜像"></p><h3 id="交付dubbo-demo-service服务到k8s"><a href="#交付dubbo-demo-service服务到k8s" class="headerlink" title="交付dubbo-demo-service服务到k8s"></a>交付dubbo-demo-service服务到k8s</h3><p>准备yml文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-server</span><br><span class="line">cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-server</span><br></pre></td></tr></table></figure><p>deploy.yml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-server&#x2F;deploy.yml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: dubbo-demo-service</span><br><span class="line">  namespace: app</span><br><span class="line">  labels: </span><br><span class="line">    name: dubbo-demo-service</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: dubbo-demo-service</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: dubbo-demo-service</span><br><span class="line">        name: dubbo-demo-service</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: dubbo-demo-service</span><br><span class="line">        image: harbor.od.com&#x2F;app&#x2F;dubbo-demo-service:master_20200605_1500</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 20880</span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">        - name: JAR_BALL</span><br><span class="line">          value: dubbo-server.jar</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>由于我们使用的harbor私有镜像的项目是app，是个私有项目，所以需要创建secret资源：</p><p>创建 app命名空间：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-server]# kubectl create ns app</span><br><span class="line">namespace&#x2F;app created</span><br></pre></td></tr></table></figure><p>创建secret资源：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create secret docker-registry harbor --docker-server&#x3D;harbor.od.com --docker-username&#x3D;admin --docker-password&#x3D;Harbor12345 -n app</span><br></pre></td></tr></table></figure><p>应用资源配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-server]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-server&#x2F;deploy.yml</span><br><span class="line">deployment.extensions&#x2F;dubbo-demo-service created</span><br></pre></td></tr></table></figure><h3 id="检查构建结果"><a href="#检查构建结果" class="headerlink" title="检查构建结果"></a>检查构建结果</h3><p>检查pod是否创建：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-server]# kubectl get pod -n app </span><br><span class="line">NAME                                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">dubbo-demo-service-859f546558-l9mvr   1&#x2F;1     Running   0          2m51s</span><br></pre></td></tr></table></figure><p> 检查是否启动成功：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-server]# kubectl logs dubbo-demo-service-859f546558-l9mvr -n app</span><br><span class="line">2020-06-05 17:53:54.796  INFO 1 --- [           main] com.od.dubbotest.Application             : Started Application in 4.73 seconds (JVM running for 6.757)</span><br><span class="line">Dubbo server started</span><br><span class="line">Dubbo 服务端已经启动</span><br></pre></td></tr></table></figure><p>检查dubbo-server服务是否已经注册到了zookeeper：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkCli.sh</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls &#x2F;</span><br><span class="line">[dubbo, zookeeper]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] ls &#x2F;dubbo</span><br><span class="line">[com.od.dubbotest.api.HelloService]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] ls &#x2F;dubbo&#x2F;com.od.dubbotest.api.HelloService</span><br><span class="line">[configurators, providers]</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] ls &#x2F;dubbo&#x2F;com.od.dubbotest.api.HelloService&#x2F;providers</span><br><span class="line">[dubbo%3A%2F%2F172.16.24.7%3A20880%2Fcom.od.dubbotest.api.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-demo-service%26dubbo%3D2.5.3%26interface%3Dcom.od.dubbotest.api.HelloService%26methods%3Dhello%26pid%3D1%26side%3Dprovider%26timestamp%3D1591350834758, dubbo%3A%2F%2F172.16.24.7%3A20880%2Fcom.od.dubbotest.api.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-demo-service%26dubbo%3D2.5.3%26interface%3Dcom.od.dubbotest.api.HelloService%26methods%3Dhello%26pid%3D1%26side%3Dprovider%26timestamp%3D1591350833638]</span><br></pre></td></tr></table></figure><h2 id="交付dubbo-monitor监控服务到k8s"><a href="#交付dubbo-monitor监控服务到k8s" class="headerlink" title="交付dubbo-monitor监控服务到k8s"></a>交付dubbo-monitor监控服务到k8s</h2><h3 id="制作dubbo-monitor镜像"><a href="#制作dubbo-monitor镜像" class="headerlink" title="制作dubbo-monitor镜像"></a>制作dubbo-monitor镜像</h3><h4 id="在运维主机下载安装包"><a href="#在运维主机下载安装包" class="headerlink" title="在运维主机下载安装包"></a>在运维主机下载安装包</h4><blockquote><p>官网 <a href="https://github.com/Jeromefromcn/dubbo-monitor.git" target="_blank" rel="noopener">dubbo-monitor源码包 </a></p></blockquote><p><code>[root@wang-200 dubbo-monitor]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget -O &#x2F;data&#x2F;soft&#x2F;centos7&#x2F;dubbo-monitor-master.zip https:&#x2F;&#x2F;github.com&#x2F;Jeromefromcn&#x2F;dubbo-monitor&#x2F;archive&#x2F;master.zip</span><br><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;dubbo-monitor-master.zip &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">unzip &#x2F;opt&#x2F;src&#x2F;dubbo-monitor-master.zip -d &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">mv &#x2F;opt&#x2F;src&#x2F;dubbo-monitor-master &#x2F;opt&#x2F;src&#x2F;dubbo-monitor</span><br><span class="line">cd &#x2F;opt&#x2F;src&#x2F;dubbo-monitor</span><br></pre></td></tr></table></figure><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>对应修改，不要全部删除内容。</p><p>vim /opt/src/dubbo-monitor/dubbo-monitor-simple/conf/dubbo_origin.properties</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;zk1.od.com:2181</span><br><span class="line">dubbo.protocol.port&#x3D;20880</span><br><span class="line">dubbo.jetty.port&#x3D;8080</span><br><span class="line">dubbo.jetty.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;monitor</span><br><span class="line">dubbo.statistics.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;statistics</span><br><span class="line">dubbo.charts.directory&#x3D;&#x2F;dubbo-monitor-simple&#x2F;charts</span><br><span class="line">dubbo.log4j.file&#x3D;logs&#x2F;dubbo-monitor.log</span><br></pre></td></tr></table></figure><p>优化修改Dockerfile并限制jvm资源，将最后的exec命令的后台&amp;符号删除，并且将exec命令下面的都干掉：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -r -i -e &#39;&#x2F;^nohup&#x2F;&#123;p;:a;N;$!ba;d&#125;&#39;  .&#x2F;dubbo-monitor-simple&#x2F;bin&#x2F;start.sh &amp;&amp; sed  -r -i -e &quot;s%^nohup(.*)%exec \1%&quot;  .&#x2F;dubbo-monitor-simple&#x2F;bin&#x2F;start.sh</span><br></pre></td></tr></table></figure><p>执行docker build并上传镜像到我们的私有仓库：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp -a dubbo-monitor&#x2F; &#x2F;data&#x2F;dockerfile&#x2F;</span><br><span class="line">cd &#x2F;data&#x2F;dockerfile&#x2F;dubbo-monitor</span><br><span class="line">docker build . -t harbor.od.com&#x2F;infra&#x2F;dubbo-monitor:latest</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;dubbo-monitor:latest</span><br></pre></td></tr></table></figure><h3 id="制作资源配置清单"><a href="#制作资源配置清单" class="headerlink" title="制作资源配置清单"></a>制作资源配置清单</h3><p>创建文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor</span><br><span class="line">cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor</span><br></pre></td></tr></table></figure><p><strong>deploy.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: dubbo-monitor</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: dubbo-monitor</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: dubbo-monitor</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: dubbo-monitor</span><br><span class="line">        name: dubbo-monitor</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: dubbo-monitor</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;dubbo-monitor:latest</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 20880</span><br><span class="line">          protocol: TCP</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>svc.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: dubbo-monitor</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector: </span><br><span class="line">    app: dubbo-monitor</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>ingress.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-monitor&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: dubbo-monitor</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: dubbo-monitor.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: dubbo-monitor</span><br><span class="line">          servicePort: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单"><a href="#应用资源配置清单" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>执行过程</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-monitor]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;deploy.yaml</span><br><span class="line">deployment.extensions&#x2F;dubbo-monitor created</span><br><span class="line">[root@wang-200 dubbo-monitor]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;svc.yaml</span><br><span class="line">service&#x2F;dubbo-monitor created</span><br><span class="line">[root@wang-200 dubbo-monitor]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-monitor&#x2F;ingress.yaml</span><br><span class="line">ingress.extensions&#x2F;dubbo-monitor created</span><br></pre></td></tr></table></figure><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><p><a href="http://dubbo-monitor.od.com/applications.html" target="_blank" rel="noopener">http://dubbo-monitor.od.com/applications.html</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1dmz17j31le0h0q87.jpg" alt="dubbo-monitor访问界面"></p><h3 id="交付构建dubbo-consumer服务"><a href="#交付构建dubbo-consumer服务" class="headerlink" title="交付构建dubbo-consumer服务"></a>交付构建dubbo-consumer服务</h3><p>我们这里的dubbo-consumer是dubbo-demo-service的消费者：</p><p>我们之前已经在jenkins配置好了流水线，只需要填写参数就行了。</p><p>由于dubbo-consumer用的gitee的私有仓库，需要添加公钥，这里大家可以自己找个client服务来做实验。</p><p>dubbo-demo-consumer构建参数</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1d38bpj31140u0wht.jpg" alt="dubbo-demo-consumer构建图"></p><p>dubbo-demo-consumer构建过程</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1f18m4j31p90u077y.jpg" alt="dubbo-demo-consumer构建过程"></p><p>下面是我们通过jenkins构建的镜像，已经上传到我们的harbor私有仓库当中了：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1bnclxj31gm0k2mzm.jpg" alt="harbor仓库中的consumer镜像"></p><p> 这里我们使用master_20200605_1600这个用来做模拟生产发版更新实验。</p><h3 id="准备资源配置清单"><a href="#准备资源配置清单" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>创建需要的文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer</span><br><span class="line">cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer</span><br></pre></td></tr></table></figure><p>deploy.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: dubbo-demo-consumer</span><br><span class="line">  namespace: app</span><br><span class="line">  labels: </span><br><span class="line">    name: dubbo-demo-consumer</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: dubbo-demo-consumer</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: dubbo-demo-consumer</span><br><span class="line">        name: dubbo-demo-consumer</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: dubbo-demo-consumer</span><br><span class="line">        image: harbor.od.com&#x2F;app&#x2F;dubbo-demo-consumer:master_20200605_1600</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 20880</span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">        - name: JAR_BALL</span><br><span class="line">          value: dubbo-client.jar</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>svc.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: dubbo-demo-consumer</span><br><span class="line">  namespace: app</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector: </span><br><span class="line">    app: dubbo-demo-consumer</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>ingress.yaml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: dubbo-demo-consumer</span><br><span class="line">  namespace: app</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: demo.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: dubbo-demo-consumer</span><br><span class="line">          servicePort: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-1"><a href="#应用资源配置清单-1" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p>执行命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p>执行过程</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-consumer]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;deploy.yaml</span><br><span class="line">deployment.extensions&#x2F;dubbo-demo-consumer created</span><br><span class="line">[root@wang-200 dubbo-consumer]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;svc.yaml</span><br><span class="line">service&#x2F;dubbo-demo-consumer created</span><br><span class="line">[root@wang-200 dubbo-consumer]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dubbo-consumer&#x2F;ingress.yaml</span><br><span class="line">ingress.extensions&#x2F;dubbo-demo-consumer created</span><br></pre></td></tr></table></figure><p>查看pod是否运行成功</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-consumer]# kubectl get pod -n app</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">dubbo-demo-consumer-5f69cf757c-cqglt   1&#x2F;1     Running   0          48s</span><br></pre></td></tr></table></figure><p> 查看log，是否启动成功：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 dubbo-consumer]# kubectl logs -f dubbo-demo-consumer-5f69cf757c-cqglt -n app</span><br><span class="line">Dubbo client started</span><br><span class="line">Dubbo 消费者端启动</span><br></pre></td></tr></table></figure><p>检查dubbo-monitor是否已经注册成功：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1e3x3jj31oc096whk.jpg" alt="dubbo-monitor注册图"></p><p> 浏览器访问<a href="http://demo.od.com/hello?name=slim" target="_blank" rel="noopener">http://demo.od.com/hello?name=slim</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1c3av7j30yq0bewg1.jpg" alt="demo页面访问展示"></p><h3 id="第一次系统升级演示"><a href="#第一次系统升级演示" class="headerlink" title="第一次系统升级演示"></a>第一次系统升级演示</h3><p>​    接下来我们模拟升级发版，我们提前修改了代码，并提交到了git仓库，发版的前提是使用jenkins提前构建了镜像并且上传到了我们的私有harbor仓库中，具体的构建流程不在赘述，只需要将远程git仓库的版本修改后构建就行了。</p><p>修改源码<a href="https://gitee.com/wangzhangtao/dubbo-demo-web/blob/master/dubbo-client/src/main/java/com/od/dubbotest/action/HelloAction.java" target="_blank" rel="noopener">dubbo-client/src/main/java/com/od/dubbotest/action/HelloAction.java</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">String str&#x3D;&quot;&lt;h1&gt;这是Dubbo 消费者端(springboot）第一次升级&lt;&#x2F;h1&gt;&quot;;</span><br></pre></td></tr></table></figure><p>修改dp.yaml资源配置清单，修改harbor镜像仓库中对应的tag版本：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1ckmm2j31fq0imtbi.jpg" alt="harbor镜像仓库中consumer新版本"></p><p>vim /data/k8s/yaml/dubbo-consumer/deploy.yaml </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: dubbo-demo-consumer</span><br><span class="line">    image: harbor.od.com&#x2F;app&#x2F;dubbo-demo-consumer:master_20200605_1700</span><br></pre></td></tr></table></figure><p> 应用修改后的资源配置清单，当然也可以在dashboard中进行在线修改：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl apply -f &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dubbo-consumer&#x2F;deploy.yaml</span><br><span class="line">deployment.extensions&#x2F;dubbo-demo-consumer configured</span><br></pre></td></tr></table></figure><p> 已经启动起来了，使用浏览器验证：<a href="http://demo.od.com/hello?name=slim" target="_blank" rel="noopener">http://demo.od.com/hello?name=slim</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfky1ek84vj315g0a6wgf.jpg" alt="consumer第一次升级">至此，我们一套完成的dubbo服务就已经交付到k8s集群当中了，并且也演示了如何发版。</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 实战交付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 老男孩 </tag>
            
            <tag> 实战交付 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一、交付-基础环境准备</title>
      <link href="/2020/06/05/%E4%B8%80%E3%80%81%E4%BA%A4%E4%BB%98-%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
      <url>/2020/06/05/%E4%B8%80%E3%80%81%E4%BA%A4%E4%BB%98-%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<h2 id="实验架构图"><a href="#实验架构图" class="headerlink" title="实验架构图"></a>实验架构图</h2><p><img src="http://wang.ikongjian.com/img/kubernetes/install/2020033123005972.png" alt="实验架构图"></p><h2 id="实验主机说明"><a href="#实验主机说明" class="headerlink" title="实验主机说明"></a>实验主机说明</h2><p>操作系统：7.6.1810； 内核：3.10.0</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th><th>硬件配置</th></tr></thead><tbody><tr><td>wang-200.host.com (zzgw7-200)</td><td>192.168.70.200</td><td>运维节点</td><td>4核8G-100G</td></tr><tr><td>wang-11.host.com (zzgw7-11)</td><td>192.168.70.11</td><td>k8s代理节点</td><td>2核4G-100G</td></tr><tr><td>wang-12.host.com (zzgw7-12)</td><td>192.168.70.12</td><td>k8s代理节点</td><td>2核4G-100G</td></tr><tr><td>wang-21.host.com (zzgw7-21)</td><td>192.168.70.21</td><td>k8s控制节点</td><td>2核4G-100G</td></tr><tr><td>wang-22.host.com (zzgw7-22)</td><td>192.168.70.22</td><td>k8s控制节点</td><td>2核4G-100G</td></tr><tr><td>wang-23.host.com (zzgw7-21)</td><td>192.168.70.23</td><td>k8s控制节点, 工作节点</td><td>2核4G-100G</td></tr><tr><td>wang-24.host.com (zzgw7-22)</td><td>192.168.70.24</td><td>k8s工作节点</td><td>4核8G-100G</td></tr></tbody></table><h2 id="交付架构图"><a href="#交付架构图" class="headerlink" title="交付架构图"></a>交付架构图</h2><p>本次交付的服务架构图：因为zookeeper属于有状态服务，不建议将有状态服务，交付到k8s，如mysql，zk等。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfgcyc2yfdj319g0kqate.jpg" alt="服务架构图"></p><h2 id="部署zookeeper-单节点"><a href="#部署zookeeper-单节点" class="headerlink" title="部署zookeeper(单节点)"></a>部署zookeeper(单节点)</h2><h3 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h3><blockquote><p>官网地址  :)</p></blockquote><p>准备文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;src</span><br><span class="line">mkdir &#x2F;usr&#x2F;java</span><br></pre></td></tr></table></figure><p>拷贝安装包并解压</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;jdk-8u221-linux-x64.tar.gz &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;jdk-8u221-linux-x64.tar.gz -C &#x2F;usr&#x2F;java&#x2F;</span><br><span class="line">ln -s &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_221 &#x2F;usr&#x2F;java&#x2F;jdk</span><br></pre></td></tr></table></figure><p><strong>配置默认全局变量</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;profile</span><br><span class="line">#JAVA HOME</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk</span><br><span class="line">export PATH&#x3D;\$PATH:\$JAVA_HOME&#x2F;bin:\$JAVA_HOME&#x2F;sbin</span><br><span class="line">export CLASSPATH&#x3D;\$CLASSPATH:\$JAVA_HOME&#x2F;lib:\$JAVA_HOME&#x2F;lib&#x2F;tools.jar</span><br><span class="line">EOF</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><p><strong>检查java是否可用</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# java version</span><br><span class="line">错误: 找不到或无法加载主类 version</span><br><span class="line">[root@wang-11 ~]# java -version</span><br><span class="line">java version &quot;1.8.0_221&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_221-b11)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)</span><br></pre></td></tr></table></figure><h3 id="下载zookeeper"><a href="#下载zookeeper" class="headerlink" title="下载zookeeper"></a>下载zookeeper</h3><p>下载zookeeper: <a href="https://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">下载地址</a>   <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz" target="_blank" rel="noopener">版本3.4.14</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;zookeeper-3.4.14.tar.gz &#x2F;opt&#x2F;src&#x2F;zookeeper-3.4.14.tar.gz</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;zookeeper-3.4.14.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;zookeeper-3.4.14  &#x2F;opt&#x2F;zookeeper</span><br><span class="line">mkdir -pv &#x2F;data&#x2F;zookeeper&#x2F;data &#x2F;data&#x2F;zookeeper&#x2F;logs</span><br></pre></td></tr></table></figure><h4 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h4><p><code>vi /opt/zookeeper/conf/zoo.cfg</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tickTime&#x3D;2000</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line">dataDir&#x3D;&#x2F;data&#x2F;zookeeper&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;data&#x2F;zookeeper&#x2F;logs</span><br><span class="line">clientPort&#x3D;2181</span><br></pre></td></tr></table></figure><h4 id="配置DNS"><a href="#配置DNS" class="headerlink" title="配置DNS"></a>配置DNS</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;var&#x2F;named&#x2F;od.com.zone</span><br><span class="line">zk1             A       192.168.70.11</span><br><span class="line">systemctl reload named</span><br></pre></td></tr></table></figure><h4 id="重启named并检测"><a href="#重启named并检测" class="headerlink" title="重启named并检测"></a>重启named并检测</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# systemctl restart named   </span><br><span class="line">[root@wang-12 ~]# dig -t A zk1.od.com +short</span><br><span class="line">192.168.70.11</span><br></pre></td></tr></table></figure><h3 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start</span><br></pre></td></tr></table></figure><h3 id="查看zookeeper情况"><a href="#查看zookeeper情况" class="headerlink" title="查看zookeeper情况"></a>查看zookeeper情况</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: standalone</span><br></pre></td></tr></table></figure><p> 到此，zookeeper就搭建好了。</p><h2 id="交付jenkins到k8s集群"><a href="#交付jenkins到k8s集群" class="headerlink" title="交付jenkins到k8s集群"></a>交付jenkins到k8s集群</h2><h3 id="准备jenkins基础镜像"><a href="#准备jenkins基础镜像" class="headerlink" title="准备jenkins基础镜像"></a>准备jenkins基础镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull jenkins&#x2F;jenkins:2.190.3</span><br><span class="line">docker tag jenkins&#x2F;jenkins:2.190.3 harbor.od.com&#x2F;public&#x2F;jenkins:v2.190.3</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;jenkins:v2.190.3</span><br></pre></td></tr></table></figure><h3 id="优化Jenkins镜像"><a href="#优化Jenkins镜像" class="headerlink" title="优化Jenkins镜像"></a>优化Jenkins镜像</h3><p>为了适应我们的环境，我们的jenkins不能直接使用，需要进行配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;data&#x2F;dockerfile&#x2F;jenkins&#x2F;</span><br><span class="line">cd &#x2F;data&#x2F;dockerfile&#x2F;jenkins</span><br></pre></td></tr></table></figure><p><code>vi Dockerfile</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM harbor.od.com&#x2F;public&#x2F;jenkins:v2.190.3</span><br><span class="line">USER root  </span><br><span class="line">RUN &#x2F;bin&#x2F;cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime &amp;&amp;\ </span><br><span class="line">    echo &#39;Asia&#x2F;Shanghai&#39; &gt;&#x2F;etc&#x2F;timezone  #修改时区 改成东八区</span><br><span class="line"></span><br><span class="line">#加载用户密钥，dubbo服务拉取代码使用的ssh</span><br><span class="line">ADD id_rsa &#x2F;root&#x2F;.ssh&#x2F;id_rsa  </span><br><span class="line">#加载宿主机的docker配置文件，登录远程仓库的认证信息加载到容器里面。</span><br><span class="line">ADD config.json &#x2F;root&#x2F;.docker&#x2F;config.json  </span><br><span class="line"># 在jenkins容器内安装docker 客户端，jenkins要执行docker build，docker引擎用的是宿主机的docker引擎</span><br><span class="line">ADD get-docker.sh &#x2F;get-docker.sh </span><br><span class="line"></span><br><span class="line">RUN echo &quot;    StrictHostKeyChecking no&quot; &gt;&gt; &#x2F;etc&#x2F;ssh&#x2F;ssh_config &amp;&amp;\</span><br><span class="line">    &#x2F;get-docker.sh  # 跳过 ssh时候输入 yes 步骤，并执行安装docker</span><br></pre></td></tr></table></figure><p>将私钥加载到jenkins，将公钥配置到git仓库中，否则不能拉取代码：</p><p> 接下来创建Dockerfile中需要的文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -fsSL get.docker.com -o get-docker.sh</span><br><span class="line">chmod u+x get-docker.sh</span><br></pre></td></tr></table></figure><p>拷贝私钥,dubbo服务拉去代码使用ssh</p><p>拷贝docker认证配置文件,<strong>加载宿主机docker配置文件，登陆远程仓库的认证信息到容器里</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;root&#x2F;.ssh&#x2F;id_rsa .&#x2F;</span><br><span class="line">cp &#x2F;root&#x2F;.docker&#x2F;config.json .&#x2F;</span><br></pre></td></tr></table></figure><p>创建运维私有仓库，打开我们的harbor.od.com创建一个infra的私有仓库：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfh9bsnziqj30h305x74g.jpg" alt="infra私有仓库"></p><p> 然后build镜像：过程漫长，可以抽根烟，喝杯茶了</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build . -t harbor.od.com&#x2F;infra&#x2F;jenkins:v2.190.3</span><br><span class="line">docker push harbor.od.com&#x2F;infra&#x2F;jenkins:v2.190.3</span><br></pre></td></tr></table></figure><h3 id="为jenkins创建名称空间"><a href="#为jenkins创建名称空间" class="headerlink" title="为jenkins创建名称空间"></a>为jenkins创建名称空间</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 jenkins]# kubectl create ns infra</span><br><span class="line">namespace&#x2F;infra created</span><br><span class="line">[root@wang-200 jenkins]# kubectl get ns | grep infra</span><br><span class="line">infra             Active   13s</span><br></pre></td></tr></table></figure><p>创建一条secret，用于访问我们的私有仓库infra：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create secret docker-registry harbor --docker-server&#x3D;harbor.od.com --docker-username&#x3D;admin --docker-password&#x3D;Harbor12345 -n infra</span><br></pre></td></tr></table></figure><p>解释一下上面的命令：创建一条secret，资源类型是docker-registry，名字是  harbor，docker-server=harbor.od.com ，docker-username=admin  ，docker-password=Harbor12345 -n 指定私有仓库名称infra</p><h3 id="创建nfs共享数据盘"><a href="#创建nfs共享数据盘" class="headerlink" title="创建nfs共享数据盘"></a>创建nfs共享数据盘</h3><p> 为了让jenkins中一些需要持久化的数据，能够存储，我们需要使用共享存储，然后进行挂载：这里使用最简单的NFS共享存储，因为k8s默认支持nfs模块</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 jenkins]# mkdir &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home</span><br><span class="line">[root@wang-200 jenkins]# vi &#x2F;etc&#x2F;exports</span><br><span class="line">&#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home 192.168.70.1&#x2F;24(insecure,rw,sync,no_root_squash)</span><br><span class="line"></span><br><span class="line">[root@wang-200 jenkins]# systemctl reload nfs</span><br></pre></td></tr></table></figure><h3 id="准备jenkins资源配置清单"><a href="#准备jenkins资源配置清单" class="headerlink" title="准备jenkins资源配置清单"></a>准备jenkins资源配置清单</h3><p>创建ymal文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 jenkins]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;jenkins&#x2F;</span><br><span class="line">[root@wang-200 jenkins]# cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;jenkins&#x2F;</span><br></pre></td></tr></table></figure><p>这里挂载了宿主机的docker.sock，使容器内的docker客户端可以直接与宿主机的docker引擎进行通信</p><p>在使用私有仓库的时候，资源清单中，一定要声明：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">imagePullSecrets:</span><br><span class="line">- name: harbor</span><br></pre></td></tr></table></figure><p><strong>deploy.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;jenkins&#x2F;deploy.yaml</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: infra</span><br><span class="line">  labels: </span><br><span class="line">    name: jenkins</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels: </span><br><span class="line">      name: jenkins</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels: </span><br><span class="line">        app: jenkins </span><br><span class="line">        name: jenkins</span><br><span class="line">    spec:</span><br><span class="line">      volumes:</span><br><span class="line">      - name: data</span><br><span class="line">        nfs: </span><br><span class="line">          server: wang-200</span><br><span class="line">          path: &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home</span><br><span class="line">      - name: docker</span><br><span class="line">        hostPath: </span><br><span class="line">          path: &#x2F;run&#x2F;docker.sock   </span><br><span class="line">          type: &#39;&#39;</span><br><span class="line">      containers:</span><br><span class="line">      - name: jenkins</span><br><span class="line">        image: harbor.od.com&#x2F;infra&#x2F;jenkins:v2.190.3</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">        - name: JAVA_OPTS</span><br><span class="line">          value: -Xmx512m -Xms512m</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: data</span><br><span class="line">          mountPath: &#x2F;var&#x2F;jenkins_home</span><br><span class="line">        - name: docker</span><br><span class="line">          mountPath: &#x2F;run&#x2F;docker.sock</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: harbor</span><br><span class="line">      securityContext: </span><br><span class="line">        runAsUser: 0</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate: </span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">      maxSurge: 1</span><br><span class="line">  revisionHistoryLimit: 7</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>svc.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;jenkins&#x2F;svc.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: jenkins</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>ingress.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;jenkins&#x2F;ingress.yaml</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">metadata: </span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: infra</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: jenkins.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend: </span><br><span class="line">          serviceName: jenkins</span><br><span class="line">          servicePort: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单"><a href="#应用资源配置清单" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p><strong>执行命令</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;jenkins&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;jenkins&#x2F;svc.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;jenkins&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p><strong>运行过程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 jenkins]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;jenkins&#x2F;deploy.yaml</span><br><span class="line">deployment.extensions&#x2F;jenkins created</span><br><span class="line">[root@wang-200 jenkins]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;jenkins&#x2F;svc.yaml</span><br><span class="line">service&#x2F;jenkins created</span><br><span class="line">[root@wang-200 jenkins]# </span><br><span class="line">[root@wang-200 jenkins]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;jenkins&#x2F;ingress.yaml</span><br><span class="line">ingress.extensions&#x2F;jenkins created</span><br></pre></td></tr></table></figure><p>查看我们创建的pod：这个启动时间还是挺长的，大概要几分钟时间</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 jenkins]# kubectl get pod -n infra</span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">jenkins-65b9b6d56-46qnt   1&#x2F;1     Running   0          56s</span><br></pre></td></tr></table></figure><p> 检查jenkins需要持久化的数据是否保存下来了：wang-200</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhd910i5fj30tw035q41.jpg" alt="jenkins数据块"></p><h4 id="访问UI界面"><a href="#访问UI界面" class="headerlink" title="访问UI界面"></a>访问UI界面</h4><p><a href="http://jenkins.od.com/" target="_blank" rel="noopener">http://jenkins.od.com/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfhdfve9urj31j40su78w.jpg" alt="jenkins安装界面"></p><h4 id="替换jenkins更新源"><a href="#替换jenkins更新源" class="headerlink" title="替换jenkins更新源"></a>替换jenkins更新源</h4><p>建议更新数据源后再下载插件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home&#x2F;</span><br><span class="line">sed -i &#39;s&#x2F;http:\&#x2F;\&#x2F;updates.jenkins-ci.org\&#x2F;download&#x2F;https:\&#x2F;\&#x2F;mirrors.tuna.tsinghua.edu.cn\&#x2F;jenkins&#x2F;g&#39; updates&#x2F;default.json &amp;&amp; sed -i &#39;s&#x2F;http:\&#x2F;\&#x2F;www.google.com&#x2F;https:\&#x2F;\&#x2F;www.baidu.com&#x2F;g&#39; updates&#x2F;default.json</span><br></pre></td></tr></table></figure><p>删除pod,重启Jenkins</p><p>然后再安装默认插件，发现速度特别快 :)</p><h4 id="安装jenkins"><a href="#安装jenkins" class="headerlink" title="安装jenkins"></a>安装jenkins</h4><p><strong>创建第一个管理员用户admin</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfheakxe26j31kb0u0tey.jpg" alt="登陆成功后界面"></p><p>安全配置：</p><p>搜索蓝海插件并安装：Blue Ocean</p><h3 id="验证jenkins容器状态"><a href="#验证jenkins容器状态" class="headerlink" title="验证jenkins容器状态"></a>验证jenkins容器状态</h3><p><strong>进入pod中</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod -n infra</span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">jenkins-65b9b6d56-9h54h   1&#x2F;1     Running   0          5m38s</span><br><span class="line">[root@wang-200 ~]# kubectl -n infra exec -it jenkins-65b9b6d56-9h54h &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p><strong>是否是root用户</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@jenkins-65b9b6d56-9h54h:&#x2F;# whoami</span><br><span class="line">root</span><br></pre></td></tr></table></figure><p><strong>时区是否是东八区</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@jenkins-65b9b6d56-9h54h:&#x2F;# date</span><br><span class="line">Fri Jun  5 14:31:59 CST 2020</span><br></pre></td></tr></table></figure><p><strong>是否使用宿主机docker引擎,在容器内查看宿主机上的docker资源情况</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@jenkins-65b9b6d56-9h54h:&#x2F;# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS              PORTS                NAMES</span><br><span class="line">65f0f58f370e        bf4556c81529                        &quot;&#x2F;sbin&#x2F;tini -- &#x2F;usr&#x2F;…&quot;   7 minutes ago       Up 7 minutes                             k8s_jenkins_jenkins-65b9b6d56-9h54h_infra_d7f03239-744c-4f66-a5d4-d94fe42c5eaf_0</span><br></pre></td></tr></table></figure><p><strong>是否能免密访问gitee</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@jenkins-65b9b6d56-9h54h:&#x2F;# ssh -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa -T git@gitee.com</span><br><span class="line">Hi wangzt! You&#39;ve successfully authenticated, but GITEE.COM does not provide shell access</span><br></pre></td></tr></table></figure><p><strong>是否能访问harbor私有仓库</strong> </p><p>原因是我们挂载了宿主机的docker config.json</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@jenkins-65b9b6d56-9h54h:&#x2F;# docker login harbor.od.com</span><br><span class="line">Authenticating with existing credentials...</span><br><span class="line">WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><p>完成验证以上内容后，证明我们基于本次实验环境的jenkins容器已经安装配置完成了。</p><h2 id="安装配置maven"><a href="#安装配置maven" class="headerlink" title="安装配置maven"></a>安装配置maven</h2><blockquote><p>maven 官方地址：<a href="https://archive.apache.org/dist/maven/maven-3/" target="_blank" rel="noopener">官方地址</a>  <a href="https://archive.apache.org/dist/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz" target="_blank" rel="noopener">maven-3.6.1</a></p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;centos7&#x2F;apache-maven-3.6.1-bin.tar.gz &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">mkdir &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home&#x2F;maven-3.6.1</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;apache-maven-3.6.1-bin.tar.gz -C &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home&#x2F;maven-3.6.1</span><br><span class="line">cd &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;jenkins_home&#x2F;maven-3.6.1</span><br><span class="line">mv apache-maven-3.6.1&#x2F;* .</span><br><span class="line">rm -rf apache-maven-3.6.1</span><br></pre></td></tr></table></figure><p>初始化maven配置：</p><p><code>vim /data/nfs/v1/jenkins_home/maven-3.6.1/conf/settings.xml</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;mirror&gt;</span><br><span class="line">  &lt;id&gt;nexus-aliyun&lt;&#x2F;id&gt;</span><br><span class="line">  &lt;mirrorOf&gt;*&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">  &lt;name&gt;Nexus aliyun&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br></pre></td></tr></table></figure><h2 id="制作JAVA运行基础镜像"><a href="#制作JAVA运行基础镜像" class="headerlink" title="制作JAVA运行基础镜像"></a>制作JAVA运行基础镜像</h2><p>dubbo微服务底包镜像</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull stanleyws&#x2F;jre8:8u112</span><br><span class="line">docker tag fa3a085d6ef1 harbor.od.com&#x2F;public&#x2F;jre:8u112</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;jre:8u112</span><br></pre></td></tr></table></figure><p>创建Dockerfile：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;dockerfile&#x2F;jre8</span><br><span class="line">cd &#x2F;data&#x2F;dockerfile&#x2F;jre8</span><br></pre></td></tr></table></figure><p><code>vi Dockerfile</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM harbor.od.com&#x2F;public&#x2F;jre:8u112</span><br><span class="line">RUN &#x2F;bin&#x2F;cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime &amp;&amp;\</span><br><span class="line">    echo &#39;Asia&#x2F;Shanghai&#39; &gt;&#x2F;etc&#x2F;timezone</span><br><span class="line">ADD config.yml &#x2F;opt&#x2F;prom&#x2F;config.yml</span><br><span class="line">ADD jmx_javaagent-0.3.1.jar &#x2F;opt&#x2F;prom&#x2F;</span><br><span class="line">WORKDIR &#x2F;opt&#x2F;project_dir</span><br><span class="line">ADD entrypoint.sh &#x2F;entrypoint.sh</span><br><span class="line">CMD [&quot;&#x2F;entrypoint.sh&quot;]</span><br></pre></td></tr></table></figure><p>创建Dockerfile所需文件：</p><p><code>vi config.yml</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--- </span><br><span class="line">rules: </span><br><span class="line"> - pattern: &#39;.*&#39;</span><br></pre></td></tr></table></figure><p>下载jmx_javaagent,监控jvm信息</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#x2F;io&#x2F;prometheus&#x2F;jmx&#x2F;jmx_prometheus_javaagent&#x2F;0.3.1&#x2F;jmx_prometheus_javaagent-0.3.1.jar -O jmx_javaagent-0.3.1.jar</span><br></pre></td></tr></table></figure><p>创建entrypoint.sh：<strong>使用exec 来运行java的jar包，能够使脚本将自己的pid 为‘1’ 传递给java进程，避免docker容器因没有前台进程而退出。并且不要加&amp;符。</strong></p><p>vim entrypoint.sh</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">M_OPTS&#x3D;&quot;-Duser.timezone&#x3D;Asia&#x2F;Shanghai -javaagent:&#x2F;opt&#x2F;prom&#x2F;jmx_javaagent-0.3.1.jar&#x3D;$(hostname -i):$&#123;M_PORT:-&quot;12346&quot;&#125;:&#x2F;opt&#x2F;prom&#x2F;config.yml&quot;</span><br><span class="line">C_OPTS&#x3D;$&#123;C_OPTS&#125;</span><br><span class="line">JAR_BALL&#x3D;$&#123;JAR_BALL&#125;</span><br><span class="line">exec java -jar $&#123;M_OPTS&#125; $&#123;C_OPTS&#125; $&#123;JAR_BALL&#125;</span><br></pre></td></tr></table></figure><p>执行权限</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod u+x entrypoint.sh</span><br></pre></td></tr></table></figure><p>执行docker build：base仓库自行创建，权限公开</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build . -t harbor.od.com&#x2F;base&#x2F;jre8:8u112</span><br><span class="line">docker push harbor.od.com&#x2F;base&#x2F;jre8:8u112</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 实战交付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 老男孩 </tag>
            
            <tag> 实战交付 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>六、k8s-集群平滑升级</title>
      <link href="/2020/06/04/%E5%85%AD%E3%80%81k8s-%E9%9B%86%E7%BE%A4%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7/"/>
      <url>/2020/06/04/%E5%85%AD%E3%80%81k8s-%E9%9B%86%E7%BE%A4%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<p>鸣谢：<a href="https://www.cnblogs.com/gaorong/p/11266629.html" target="_blank" rel="noopener">代码小工</a></p><p>官方建议升级过程</p><ol><li>首先阅读相关<code>release node</code>，重点关注其中几部分： Known Issues，Action Requireed，Deprecations and removals。社区会将一些变化highlight到这里，阅读这些变化可以明确自己需要采取哪些行动。</li><li>kubernetes 建议不断地进行小版本升级，而不是一次进行大的版本跳跃。具体的兼容策略是：  slave组件可以与master组件最多延迟两个小版本(minor  version)，但是不能比master组件新。client不能与master组件落后一个小版本，但是可以高一个版本，也就是说：   v1.3的master可以与v1.1，v1.2，v1.3的slave组件一起使用，与v1.2，v1.3，v1.4   client一起使用。官方建议每次升级不要跨越两个版本，升级顺序为: master，addons，salve。</li><li>slave节点的升级是滚动升级，官方建议首先使用<code>kubectl drain</code>驱逐pod之后，然后升级kubelet，因为kubelet会有一些状态信息文件存储在node节点上，社区并不保证这些状态文件在版本间的兼容性。</li><li>虽然kubernetes建议先升级master组件，然后再升级node组件，但是实际应用过程中建议先停掉controller-manager，然后升级master组件，node组件，最后再升级controller-manager，因为controller-manager中会进行一些状态的调谐(reconcile)，对于actual status不符合desire  status的对象会触发一些操作。升级过程中尽管我们会进行充分的测试，但是也难免出现一些非预期的情况下，例如apiserver中某些资源对象的兼容性不好，或者其中的某些字段进行调整，触发controller-manager执行非预期操作，例如重建一个deployment下所有的pod，更糟糕的是，如果此时kubelet还未升级，就可能不认识新版本一些资源对象中的新增的某些字段，此时老的pod被删掉了，但是新的pod没有起来，就造成一定的服务中断。(后面会有相关的案例)</li><li>apiserver升级之前需要确保resource version被正常支持，目前kubernetes会逐步废弃掉，例如:  DaemonSet，Deployment，ReplicaSet  所使用的  extensions/v1beta1，apps/v1beta1，apps/v1beta2   将会在v1.16中完全废弃掉，届时，如果你再去读取这些版本的资源，apiserver将不会认识这些资源，任何的增删改查都无法进行，只能通过<code>etcdctl</code>进行删除。目前社区正在开发迁移工具，并且在支持该工具之前，所有的版本移除操作都会被冻结，所以目前(2019.5.20)来说是相对安全的。</li></ol><p><strong>官方建议每次升级不要跨越两个版本，升级顺序为: master，addons，salve。</strong></p><p><strong>注意：生产根据业务来规划升级时间，这里以wang-21为例。</strong></p><h3 id="环境描述"><a href="#环境描述" class="headerlink" title="环境描述"></a>环境描述</h3><p>目前使用版本为<code>V1.15.2</code>,升级版本为<code>V1.15.4</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get node</span><br><span class="line">NAME               STATUS   ROLES         AGE   VERSION</span><br><span class="line">wang-23.host.com   Ready    master,node   28h   v1.15.2</span><br><span class="line">wang-24.host.com   Ready    node          28h   v1.15.2</span><br></pre></td></tr></table></figure><p>显示的版本号实际上是kubelet的版本号</p><h3 id="准备-V1-15-4版本软件"><a href="#准备-V1-15-4版本软件" class="headerlink" title="准备 V1.15.4版本软件"></a>准备 <code>V1.15.4</code>版本软件</h3><blockquote><p>官网地址 <em><a href="https://dl.k8s.io/v1.15.4/kubernetes-server-linux-amd64.tar.gz" target="_blank" rel="noopener">https://dl.k8s.io/v1.15.4/kubernetes-server-linux-amd64.tar.gz</a></em> </p></blockquote><p><code>[root@wang-200 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;k8s&#x2F;kubernetes-server-linux-amd64-v1.15.4.tar.gz &#x2F;opt&#x2F;src&#x2F;kubernetes-server-linux-amd64-v1.15.4.tar.gz</span><br><span class="line"></span><br><span class="line"># 默认是kubernetes目录</span><br><span class="line">mkdir &#x2F;opt&#x2F;kubernetes-v1.15.4</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;kubernetes-server-linux-amd64-v1.15.4.tar.gz -C &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F; # 指定文件夹，否则会覆盖&#x2F;opt&#x2F;kubernetes这个文件夹</span><br><span class="line"></span><br><span class="line">mv &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;kubernetes&#x2F;* &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;</span><br><span class="line">rm -rf &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;kubernetes*</span><br><span class="line">rm -rf &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;*_tag</span><br><span class="line">rm -rf &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;*.tar</span><br></pre></td></tr></table></figure><p><strong>最终文件结构</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# tree &#x2F;opt&#x2F;kubernetes-v1.15.4</span><br><span class="line">&#x2F;opt&#x2F;kubernetes-v1.15.4</span><br><span class="line">├── addons</span><br><span class="line">├── LICENSES</span><br><span class="line">└── server</span><br><span class="line">    └── bin</span><br><span class="line">        ├── apiextensions-apiserver</span><br><span class="line">        ├── cloud-controller-manager</span><br><span class="line">        ├── hyperkube</span><br><span class="line">        ├── kubeadm</span><br><span class="line">        ├── kube-apiserver</span><br><span class="line">        ├── kube-controller-manager</span><br><span class="line">        ├── kubectl</span><br><span class="line">        ├── kubelet</span><br><span class="line">        ├── kube-proxy</span><br><span class="line">        ├── kube-scheduler</span><br><span class="line">        └── mounter</span><br><span class="line"></span><br><span class="line">3 directories, 12 files</span><br></pre></td></tr></table></figure><h3 id="升级控制节点"><a href="#升级控制节点" class="headerlink" title="升级控制节点"></a>升级控制节点</h3><p><strong>生存环境需要修改nginx.conf,把升级节点从upstream中注释掉</strong></p><p><strong>拷贝脚本与证书</strong></p><p>升级master节点wang-21</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r wang-200:&#x2F;opt&#x2F;kubernetes-v1.15.4 &#x2F;opt&#x2F;kubernetes-v1.15.4</span><br><span class="line">cp -a &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;server&#x2F;bin&#x2F;certs &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">cp -a &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;server&#x2F;bin&#x2F;conf &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">cp &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;server&#x2F;bin&#x2F;*.sh &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">rm -f &#x2F;opt&#x2F;kubernetes</span><br><span class="line">ln -s &#x2F;opt&#x2F;kubernetes-v1.15.4 &#x2F;opt&#x2F;kubernetes</span><br></pre></td></tr></table></figure><p>重启服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">supervisorctl restart kube-apiserver-70-21 kube-scheduler-70-21 kube-controller-manager-70-21</span><br><span class="line"># systemctl restart supervisord</span><br><span class="line">kubectl get cs</span><br></pre></td></tr></table></figure><p>如果启动失败，就<code>ps -ef | grep kube</code>,看看还有没有孤儿进程，如果有就杀死再重启。</p><h3 id="升级工作节点"><a href="#升级工作节点" class="headerlink" title="升级工作节点"></a>升级工作节点</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get node</span><br><span class="line">NAME               STATUS   ROLES         AGE   VERSION</span><br><span class="line">wang-23.host.com   Ready    master,node   29h   v1.15.2</span><br><span class="line">wang-24.host.com   Ready    node          29h   v1.15.2</span><br></pre></td></tr></table></figure><h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl delete node wang-24.host.com</span><br><span class="line">node &quot;wang-24.host.com&quot; deleted</span><br><span class="line">[root@wang-200 ~]# kubectl get node</span><br><span class="line">NAME               STATUS   ROLES         AGE   VERSION</span><br><span class="line">wang-23.host.com   Ready    master,node   30h   v1.15.2</span><br></pre></td></tr></table></figure><h4 id="拷贝脚本与证书"><a href="#拷贝脚本与证书" class="headerlink" title="拷贝脚本与证书"></a><strong>拷贝脚本与证书</strong></h4><p>升级master节点wang-21</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r wang-200:&#x2F;opt&#x2F;kubernetes-v1.15.4 &#x2F;opt&#x2F;kubernetes-v1.15.4</span><br><span class="line">cp -a &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;server&#x2F;bin&#x2F;certs &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">cp -a &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;server&#x2F;bin&#x2F;conf &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">cp &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;server&#x2F;bin&#x2F;*.sh &#x2F;opt&#x2F;kubernetes-v1.15.4&#x2F;server&#x2F;bin&#x2F;</span><br><span class="line">rm -f &#x2F;opt&#x2F;kubernetes</span><br><span class="line">ln -s &#x2F;opt&#x2F;kubernetes-v1.15.4 &#x2F;opt&#x2F;kubernetes</span><br></pre></td></tr></table></figure><h4 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# supervisorctl restart kube-kubelet-70-24 kube-proxy-70-24</span><br></pre></td></tr></table></figure><p>再次验证，发现版本已经升级</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get node</span><br><span class="line">NAME               STATUS   ROLES         AGE     VERSION</span><br><span class="line">wang-23.host.com   Ready    master,node   30h     v1.15.2</span><br><span class="line">wang-24.host.com   Ready    &lt;none&gt;        2m10s   v1.15.4</span><br></pre></td></tr></table></figure><p>我们把所有控制节点和工作节点升级完，服务就算升级完成了。</p><h3 id="恭喜你，二进制部署结束了"><a href="#恭喜你，二进制部署结束了" class="headerlink" title="恭喜你，二进制部署结束了"></a>恭喜你，二进制部署结束了</h3>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>五、k8s-部署Addons组件</title>
      <link href="/2020/06/03/%E4%BA%94%E3%80%81k8s-%E9%83%A8%E7%BD%B2addons%E7%BB%84%E4%BB%B6/"/>
      <url>/2020/06/03/%E4%BA%94%E3%80%81k8s-%E9%83%A8%E7%BD%B2addons%E7%BB%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="K8S的CNI网络插件-Flannel"><a href="#K8S的CNI网络插件-Flannel" class="headerlink" title="K8S的CNI网络插件-Flannel"></a>K8S的CNI网络插件-Flannel</h2><p>集群规划</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com（为了展现效果，暂不部署）</td><td>192.168.70.21</td><td>flannel</td></tr><tr><td>wang-22.host.com（为了展现效果，暂不部署）</td><td>192.168.70.22</td><td>flannel</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>flannel</td></tr><tr><td>wang-24.host.com</td><td>192.168.70.24</td><td>flannel</td></tr></tbody></table><p>注意：这里部署以wang-24.host.com主机为例，其他运算节点类似</p><h3 id="在运维主机下载软件，解压"><a href="#在运维主机下载软件，解压" class="headerlink" title="在运维主机下载软件，解压"></a>在运维主机下载软件，解压</h3><p>源码包<em><a href="https://github.com/coreos/flannel/releases/download/v0.11.0/flannel-v0.11.0-linux-amd64.tar.gz" target="_blank" rel="noopener">https://github.com/coreos/flannel/releases/download/v0.11.0/flannel-v0.11.0-linux-amd64.tar.gz</a></em></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# wget -O &#x2F;data&#x2F;soft&#x2F;k8s&#x2F;flannel-v0.11.0-linux-amd64.tar.gz https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;flannel&#x2F;releases&#x2F;download&#x2F;v0.11.0&#x2F;flannel-v0.11.0-linux-amd64.tar.gz  # 喝一杯茶</span><br></pre></td></tr></table></figure><h3 id="拷贝安装包到服务器"><a href="#拷贝安装包到服务器" class="headerlink" title="拷贝安装包到服务器"></a>拷贝安装包到服务器</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;k8s&#x2F;flannel-v0.11.0-linux-amd64.tar.gz &#x2F;opt&#x2F;src&#x2F;</span><br><span class="line">mkdir &#x2F;opt&#x2F;flannel-v0.11.0</span><br><span class="line">ln -s &#x2F;opt&#x2F;flannel-v0.11.0&#x2F; &#x2F;opt&#x2F;flannel</span><br><span class="line"># scp -r wang-200:&#x2F;opt&#x2F;flannel&#x2F;* &#x2F;opt&#x2F;flannel&#x2F;</span><br><span class="line">tar xf &#x2F;opt&#x2F;src&#x2F;flannel-v0.11.0-linux-amd64.tar.gz -C &#x2F;opt&#x2F;flannel-v0.11.0&#x2F;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# ls &#x2F;opt&#x2F;flannel-v0.11.0&#x2F;</span><br><span class="line">flanneld  mk-docker-opts.sh  README.md</span><br></pre></td></tr></table></figure><h4 id="拷贝证书"><a href="#拷贝证书" class="headerlink" title="拷贝证书"></a>拷贝证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;flannel&#x2F;cert</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;ca.pem &#x2F;opt&#x2F;flannel&#x2F;cert&#x2F; </span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;client.pem &#x2F;opt&#x2F;flannel&#x2F;cert&#x2F;  </span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;client-key.pem &#x2F;opt&#x2F;flannel&#x2F;cert&#x2F;</span><br></pre></td></tr></table></figure><h3 id="操作etcd，增加wang-gw"><a href="#操作etcd，增加wang-gw" class="headerlink" title="操作etcd，增加wang-gw"></a>操作etcd，增加wang-gw</h3><p>启动flannel之前，需要在etcd中添加网络配置记录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 写入etcd</span><br><span class="line">[root@wang-23 ~]# etcdctl set &#x2F;coreos.com&#x2F;network&#x2F;config &#39;&#123;&quot;Network&quot;: &quot;172.16.0.0&#x2F;16&quot;, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;host-gw&quot;&#125;&#125;&#39;    </span><br><span class="line">&#123;&quot;Network&quot;: &quot;172.16.0.0&#x2F;16&quot;, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;host-gw&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@wang-23 ~]# etcdctl  get &#x2F;coreos.com&#x2F;network&#x2F;config</span><br><span class="line">&#123;&quot;Network&quot;: &quot;172.16.0.0&#x2F;16&quot;, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;host-gw&quot;&#125;&#125;</span><br></pre></td></tr></table></figure><p>wang-gw：直接路由的方式，将容器网络的路由信息直接更新到主机的路由表中，仅适用于二层直接可达的网络</p><h3 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;flannel&#x2F;subnet.env</span><br><span class="line">FLANNEL_NETWORK&#x3D;172.16.0.0&#x2F;16        </span><br><span class="line">FLANNEL_SUBNET&#x3D;172.16.24.1&#x2F;24        </span><br><span class="line">FLANNEL_MTU&#x3D;1500</span><br><span class="line">FLANNEL_IPMASQ&#x3D;false</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改对应的主机</span><br><span class="line">sed -i &quot;s&amp;172.16.24.1&#x2F;24&amp;172.16.$&#123;HOSTNUM&#125;.1&#x2F;24&amp;&quot; &#x2F;opt&#x2F;flannel&#x2F;subnet.env</span><br></pre></td></tr></table></figure><blockquote><p><em>注意：lannel集群各主机的配置略有不同，SUBNET需要更改</em></p><p>FLANNEL_NETWORK=172.16.0.0/16        #pod资源的IP范围<br>FLANNEL_SUBNET=172.16.24.1/24        #本机的IP范围</p></blockquote><h3 id="创建flanneld启动脚本"><a href="#创建flanneld启动脚本" class="headerlink" title="创建flanneld启动脚本"></a>创建flanneld启动脚本</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;flannel&#x2F;flanneld.sh</span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">.&#x2F;flanneld \\</span><br><span class="line">  --public-ip&#x3D;192.168.70.24 \\</span><br><span class="line">  --etcd-endpoints&#x3D;https:&#x2F;&#x2F;192.168.70.21:2379,https:&#x2F;&#x2F;192.168.70.22:2379,https:&#x2F;&#x2F;192.168.70.23:2379 \\</span><br><span class="line">  --etcd-keyfile&#x3D;.&#x2F;cert&#x2F;client-key.pem \\</span><br><span class="line">  --etcd-certfile&#x3D;.&#x2F;cert&#x2F;client.pem \\</span><br><span class="line">  --etcd-cafile&#x3D;.&#x2F;cert&#x2F;ca.pem \\</span><br><span class="line">  --iface&#x3D;ens160 \\</span><br><span class="line">  --subnet-file&#x3D;.&#x2F;subnet.env \\</span><br><span class="line">  --healthz-port&#x3D;2401</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -i &quot;s&amp;--public-ip&#x3D;192.168.70.24&amp;--public-ip&#x3D;192.168.70.$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;opt&#x2F;flannel&#x2F;flanneld.sh</span><br></pre></td></tr></table></figure><blockquote><p>–public-ip=192.168.70.21 主机IP地址<br>–iface=ens160  注意虚拟机网卡</p></blockquote><p><strong>授权、创建日志目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x &#x2F;opt&#x2F;flannel&#x2F;flanneld.sh </span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs&#x2F;flanneld</span><br></pre></td></tr></table></figure><h3 id="创建supervisor配置"><a href="#创建supervisor配置" class="headerlink" title="创建supervisor配置"></a>创建supervisor配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;flannel.ini</span><br><span class="line">[program:flanneld-70-24]</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;flannel&#x2F;flanneld.sh            ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                  ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;flannel                      ; directory to cwd to before exec (def no cwd)</span><br><span class="line">autostart&#x3D;true                              ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                            ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;30                                ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                              ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                               ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                             ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                             ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;root                                   ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;true                        ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;flanneld&#x2F;flanneld.stdout.log       ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                    ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                 ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                 ; emit events on stdout writes (default false)</span><br><span class="line">stopasgroup&#x3D;true                            ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程</span><br><span class="line">killasgroup&#x3D;true                            ;默认为false，向进程组发送kill信号，包括子进程</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -i &quot;s&amp;flanneld-70-24&amp;flanneld-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;flannel.ini</span><br></pre></td></tr></table></figure><h3 id="启动服务并检查"><a href="#启动服务并检查" class="headerlink" title="启动服务并检查"></a>启动服务并检查</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# supervisorctl update</span><br><span class="line">flanneld-70-24: added process group</span><br><span class="line">[root@wang-24 ~]# supervisorctl status</span><br><span class="line">flanneld-70-24                   STARTING  </span><br><span class="line">kube-kubelet-70-24               RUNNING   pid 52982, uptime 1:38:54</span><br><span class="line">kube-proxy-70-24                 RUNNING   pid 53669, uptime 1:01:36</span><br></pre></td></tr></table></figure><p><strong>检查etcd数据库</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-23 ~]# etcdctl ls &#x2F;coreos.com&#x2F;network&#x2F;subnets</span><br><span class="line">&#x2F;coreos.com&#x2F;network&#x2F;subnets&#x2F;172.16.24.0-24</span><br><span class="line">[root@wang-23 ~]# etcdctl get &#x2F;coreos.com&#x2F;network&#x2F;subnets&#x2F;172.16.24.0-24</span><br><span class="line">&#123;&quot;PublicIP&quot;:&quot;192.168.70.24&quot;,&quot;BackendType&quot;:&quot;host-gw&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="安装部署集群其他节点-略过"><a href="#安装部署集群其他节点-略过" class="headerlink" title="安装部署集群其他节点(略过)"></a>安装部署集群其他节点(略过)</h3><h3 id="检查路由"><a href="#检查路由" class="headerlink" title="检查路由"></a>检查路由</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 flannel]# route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.70.1    0.0.0.0         UG    100    0        0 ens160</span><br><span class="line">172.16.23.0     192.168.70.23   255.255.255.0   UG    0      0        0 ens160</span><br><span class="line">172.16.24.0     0.0.0.0         255.255.255.0   U     0      0        0 docker0</span><br><span class="line">192.168.70.0    0.0.0.0         255.255.255.0   U     100    0        0 ens160</span><br></pre></td></tr></table></figure><p>访问其他主机上的pod</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 flannel]# curl -I 172.16.23.2</span><br><span class="line">HTTP&#x2F;1.1 200 OK</span><br><span class="line">Server: nginx&#x2F;1.7.9</span><br><span class="line">Date: Wed, 03 Jun 2020 03:44:27 GMT</span><br><span class="line">Content-Type: text&#x2F;html</span><br><span class="line">Content-Length: 612</span><br><span class="line">Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;54999765-264&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br></pre></td></tr></table></figure><h3 id="K8S资源配置清单的内网http服务"><a href="#K8S资源配置清单的内网http服务" class="headerlink" title="K8S资源配置清单的内网http服务"></a>K8S资源配置清单的内网http服务</h3><p>创建nginx配置文件</p><p><code>[root@wang-200 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;doc.k8s.od.com.conf  </span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  doc.k8s.od.com;</span><br><span class="line">    # index index.html index.htm index.jsp;</span><br><span class="line">    # root &#x2F;data&#x2F;k8s;</span><br><span class="line"></span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        autoindex on;</span><br><span class="line">        autoindex_exact_size off;</span><br><span class="line">        default_type text&#x2F;plain;</span><br><span class="line">        root &#x2F;data&#x2F;k8s&#x2F;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    access_log &#x2F;data&#x2F;logs&#x2F;k8s-doc.log;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>创建目录并加载代码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;data&#x2F;k8s&#x2F;install &#x2F;data&#x2F;k8s&#x2F;yaml</span><br><span class="line">mkdir -p &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;coredns</span><br><span class="line">nginx -t</span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><p><strong>浏览器访问测试</strong>`</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfeyylg1wsj31920d0767.jpg" alt="image-20200603120508191"></p><h3 id="在各运算节点上优化iptables规则"><a href="#在各运算节点上优化iptables规则" class="headerlink" title="在各运算节点上优化iptables规则"></a>在各运算节点上优化iptables规则</h3><p>注意：iptables规则各主机的略有不同，其他运算节点上执行时注意修改。</p><p><strong>安装iptables</strong></p><p><code>vim /data/k8s/install/install_iptables.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line">yum install -y iptables-services</span><br><span class="line">systemctl start iptables</span><br><span class="line">systemctl enable iptables</span><br><span class="line"></span><br><span class="line">iptables -t nat -D POSTROUTING -s 172.16.$&#123;HOSTNUM&#125;.0&#x2F;24 ! -o docker0 -j MASQUERADE</span><br><span class="line">iptables -t nat -I POSTROUTING -s 172.16.$&#123;HOSTNUM&#125;.0&#x2F;24 ! -d 172.16.0.0&#x2F;16 ! -o docker0 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">iptables -D INPUT -j REJECT --reject-with icmp-host-prohibited</span><br><span class="line">iptables -D FORWARD -j REJECT --reject-with icmp-host-prohibited </span><br><span class="line"></span><br><span class="line">iptables-save &gt; &#x2F;etc&#x2F;sysconfig&#x2F;iptables</span><br></pre></td></tr></table></figure><p>运行安装脚本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sSL http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;install&#x2F;install_iptables.sh | sh</span><br></pre></td></tr></table></figure><h3 id="手动添加路由规则-略过，仅供参考"><a href="#手动添加路由规则-略过，仅供参考" class="headerlink" title="手动添加路由规则(略过，仅供参考)"></a>手动添加路由规则(略过，仅供参考)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">route add -net 172.16.23.0&#x2F;24 gw 192.168.70.23 dev ens160</span><br><span class="line">route add -net 172.16.24.0&#x2F;24 gw 192.168.70.24 dev ens160</span><br><span class="line">iptables -t filter -I FORWARD -d 172.16.0.0&#x2F;16 -j ACCEPT</span><br></pre></td></tr></table></figure><h2 id="K8S的服务发现插件-CoreDNS"><a href="#K8S的服务发现插件-CoreDNS" class="headerlink" title="K8S的服务发现插件-CoreDNS"></a>K8S的服务发现插件-CoreDNS</h2><h3 id="准备coredns镜像"><a href="#准备coredns镜像" class="headerlink" title="准备coredns镜像"></a>准备coredns镜像</h3><p><code>[root@wang-200 k8s]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull coredns&#x2F;coredns:1.6.5</span><br><span class="line">docker tag coredns&#x2F;coredns:1.6.5 harbor.od.com&#x2F;public&#x2F;coredns:v1.6.5</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;coredns:v1.6.5</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单"><a href="#准备资源配置清单" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p><strong>进入存放资源清单目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cd &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;coredns&#x2F;</span><br></pre></td></tr></table></figure><p><strong>rbac.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;coredns&#x2F;rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">      kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">      addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;bootstrapping: rbac-defaults</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - endpoints</span><br><span class="line">  - services</span><br><span class="line">  - pods</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io&#x2F;autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io&#x2F;bootstrapping: rbac-defaults</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: EnsureExists</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>configmap.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;coredns&#x2F;configmap.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        log</span><br><span class="line">        health</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local 10.2.0.0&#x2F;16</span><br><span class="line">        forward . 192.168.70.12</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">       &#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>deployment.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;coredns&#x2F;deployment.yaml</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: coredns</span><br><span class="line">    kubernetes.io&#x2F;name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: coredns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: coredns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;coredns:v1.6.5</span><br><span class="line">        args:</span><br><span class="line">        - -conf</span><br><span class="line">        - &#x2F;etc&#x2F;coredns&#x2F;Corefile</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;coredns</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: &#x2F;health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>service.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;coredns&#x2F;service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: coredns</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io&#x2F;name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: coredns</span><br><span class="line">  clusterIP: 10.2.0.2</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>检查资源配置清单</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 coredns]# ll</span><br><span class="line">总用量 16</span><br><span class="line">-rw-r--r--. 1 root root  320 6月   3 14:10 configmap.yaml</span><br><span class="line">-rw-r--r--. 1 root root 1294 6月   3 14:11 deployment.yaml</span><br><span class="line">-rw-r--r--. 1 root root  954 6月   3 14:10 rbac.yaml</span><br><span class="line">-rw-r--r--. 1 root root  384 6月   3 14:11 service.yaml</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单"><a href="#应用资源配置清单" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p><strong>应用命令</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;configmap.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;deployment.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;service.yaml</span><br></pre></td></tr></table></figure><p><strong>显示过程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 coredns]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;rbac.yaml</span><br><span class="line">serviceaccount&#x2F;coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io&#x2F;system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;system:coredns created</span><br><span class="line">[root@wang-200 coredns]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;configmap.yaml</span><br><span class="line">configmap&#x2F;coredns created</span><br><span class="line">[root@wang-200 coredns]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;deployment.yaml</span><br><span class="line">deployment.apps&#x2F;coredns created</span><br><span class="line">[root@wang-200 coredns]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;coredns&#x2F;service.yaml</span><br><span class="line">service&#x2F;coredns created</span><br></pre></td></tr></table></figure><h3 id="查看创建的资源"><a href="#查看创建的资源" class="headerlink" title="查看创建的资源"></a>查看创建的资源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 coredns]# kubectl get all -n kube-system</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod&#x2F;coredns-9bc44c684-9b9kj   1&#x2F;1     Running   0          80s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NAME              TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">service&#x2F;coredns   ClusterIP   10.2.0.2     &lt;none&gt;        53&#x2F;UDP,53&#x2F;TCP,9153&#x2F;TCP   78s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NAME                      READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps&#x2F;coredns   1&#x2F;1     1            1           80s</span><br><span class="line"></span><br><span class="line">NAME                                DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps&#x2F;coredns-9bc44c684   1         1         1       80s</span><br></pre></td></tr></table></figure><h3 id="验证coredns"><a href="#验证coredns" class="headerlink" title="验证coredns"></a>验证coredns</h3><p><strong>执行命令</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig -t A wang-21.host.com @192.168.70.12 +short</span><br><span class="line">dig -t A wang-21.host.com @10.2.0.2 +short</span><br><span class="line">dig -t A www.baidu.com @192.168.70.12 +short</span><br><span class="line">dig -t A www.baidu.com @10.2.0.2 +short</span><br></pre></td></tr></table></figure><p><strong>显示过程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 flannel]# dig -t A wang-21.host.com @192.168.70.12 +short</span><br><span class="line">192.168.70.21</span><br><span class="line">[root@wang-24 flannel]# dig -t A wang-21.host.com @10.2.0.2 +short</span><br><span class="line">192.168.70.21</span><br><span class="line">[root@wang-24 flannel]# dig -t A www.baidu.com @192.168.70.12 +short</span><br><span class="line">www.a.shifen.com.</span><br><span class="line">180.101.49.11</span><br><span class="line">180.101.49.12</span><br><span class="line">[root@wang-24 flannel]# dig -t A www.baidu.com @10.2.0.2 +short</span><br><span class="line">www.a.shifen.com.</span><br><span class="line">180.101.49.12</span><br><span class="line">180.101.49.11</span><br></pre></td></tr></table></figure><h2 id="K8S的服务暴露插件-Traefik"><a href="#K8S的服务暴露插件-Traefik" class="headerlink" title="K8S的服务暴露插件-Traefik"></a>K8S的服务暴露插件-Traefik</h2><h3 id="ingress控制器"><a href="#ingress控制器" class="headerlink" title="ingress控制器"></a>ingress控制器</h3><p>​        Traefik是一个用Golang开发的轻量级的Http反向代理和负载均衡器。由于可以自动配置和刷新backend节点，目前可以被绝大部分容器平台支持，例如Kubernetes，Swarm，Rancher等。由于traefik会实时与Kubernetes API交互,所以对于Service的节点变化，traefik的反应会更加迅速。总体来说traefik可以在Kubernetes中完美的运行.</p><h3 id="准备traefik镜像"><a href="#准备traefik镜像" class="headerlink" title="准备traefik镜像"></a><strong>准备traefik镜像</strong></h3><p><code>[root@wang-200 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull traefik:v1.7.2</span><br><span class="line">docker tag traefik:v1.7.2 harbor.od.com&#x2F;public&#x2F;traefik:v1.7.2</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;traefik:v1.7.2</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-1"><a href="#准备资源配置清单-1" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p>官网yaml文件地址：<a href="https://github.com/containous/traefik/tree/v1.7/examples/k8s" target="_blank" rel="noopener">https://github.com/containous/traefik/tree/v1.7/examples/k8s</a></p><p><strong>创建并进入资源清单目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir -p &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;traefik</span><br></pre></td></tr></table></figure><p><strong>rbac.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;traefik&#x2F;rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">      - endpoints</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - extensions</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>daemonset.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;traefik&#x2F;daemonset.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: traefik-ingress</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: traefik-ingress</span><br><span class="line">        name: traefik-ingress</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: traefik-ingress-controller</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - image: harbor.od.com&#x2F;public&#x2F;traefik:v1.7.2</span><br><span class="line">        name: traefik-ingress</span><br><span class="line">        ports:</span><br><span class="line">        - name: controller</span><br><span class="line">          containerPort: 80 </span><br><span class="line">          hostPort: 81              </span><br><span class="line">        - name: admin-web      </span><br><span class="line">          containerPort: 8080</span><br><span class="line">        securityContext:</span><br><span class="line">          capabilities:</span><br><span class="line">            drop:</span><br><span class="line">            - ALL</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">        args:</span><br><span class="line">        - --api</span><br><span class="line">        - --kubernetes</span><br><span class="line">        - --logLevel&#x3D;INFO</span><br><span class="line">        - --insecureskipverify&#x3D;true</span><br><span class="line">        - --kubernetes.endpoint&#x3D;https:&#x2F;&#x2F;api.k8s.od.com:8443      </span><br><span class="line">        - --accesslog</span><br><span class="line">        - --accesslog.filepath&#x3D;&#x2F;var&#x2F;log&#x2F;traefik_access.log</span><br><span class="line">        - --traefiklog</span><br><span class="line">        - --traefiklog.filepath&#x3D;&#x2F;var&#x2F;log&#x2F;traefik.log</span><br><span class="line">        - --metrics.prometheus</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>service.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;traefik&#x2F;service.yaml</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-service</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: traefik-ingress</span><br><span class="line">  ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      name: controller</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 8080</span><br><span class="line">      name: admin-web</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>ingress.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;traefik&#x2F;ingress.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: traefik.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: &#x2F;</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: traefik-ingress-service</span><br><span class="line">          servicePort: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-1"><a href="#应用资源配置清单-1" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p><strong>执行命令</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;daemonset.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;service.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p><strong>执行过程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;rbac.yaml</span><br><span class="line">serviceaccount&#x2F;traefik-ingress-controller created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io&#x2F;traefik-ingress-controller created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;traefik-ingress-controller created</span><br><span class="line"></span><br><span class="line">[root@wang-21 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;daemonset.yaml</span><br><span class="line">daemonset.extensions&#x2F;traefik-ingress created</span><br><span class="line"></span><br><span class="line">[root@wang-21 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;service.yaml</span><br><span class="line">service&#x2F;traefik-ingress-service created</span><br><span class="line"></span><br><span class="line">[root@wang-21 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;traefik&#x2F;ingress.yaml</span><br><span class="line">ingress.extensions&#x2F;traefik-web-ui created</span><br></pre></td></tr></table></figure><p><strong>检查创建的资源</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-23 ~]# kubectl get pods -n kube-system </span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-9bc44c684-9b9kj   1&#x2F;1     Running   0          3h16m</span><br><span class="line">traefik-ingress-nn4vn     1&#x2F;1     Running   0          3h8m</span><br><span class="line">traefik-ingress-tnw7n     1&#x2F;1     Running   0          3h8m</span><br></pre></td></tr></table></figure><p><strong>如果报错如下：</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Warning  FailedCreatePodSandBox  29s (x6207 over 3h5m)  kubelet, wang-24.host.com  (combined from similar events): Failed create pod sandbox: rpc error: code &#x3D; Unknown desc &#x3D; failed to start sandbox container for pod &quot;traefik-ingress-tnw7n&quot;: Error response from daemon: driver failed programming external connectivity on endpoint k8s_POD_traefik-ingress-tnw7n_kube-system_45d3c9bf-0633-44f0-8048-91061b74a7e2_6215 (b578fba313008f91ed117d5d5112c74ca2d07b5e460c20a862b7ad07207f5f72):  (iptables failed: iptables --wait -t filter -A DOCKER ! -i docker0 -o docker0 -p tcp -d 172.16.24.4 --dport 80 -j ACCEPT: iptables: No chain&#x2F;target&#x2F;match by that name.</span><br></pre></td></tr></table></figure><blockquote><p>解决方法：重启docker</p></blockquote><h3 id="添加A记录解析"><a href="#添加A记录解析" class="headerlink" title="添加A记录解析"></a>添加A记录解析</h3><p>配置Nginx反向</p><p><code>wang-12</code>和<code>wang-11</code>两台主机上的nginx均需要配置</p><p><code>[root@wang-11 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;od.com.conf</span><br><span class="line">upstream default_backend_traefik &#123;</span><br><span class="line">    server 192.168.70.23:81    max_fails&#x3D;3 fail_timeout&#x3D;10s;</span><br><span class="line">    server 192.168.70.24:81    max_fails&#x3D;3 fail_timeout&#x3D;10s;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name *.od.com;</span><br><span class="line">    access_log &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;od.com.log;</span><br><span class="line"></span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;default_backend_traefik;</span><br><span class="line">        proxy_set_header Host       \$http_host;</span><br><span class="line">        proxy_set_header x-forwarded-for \$proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="重新加载配置文件"><a href="#重新加载配置文件" class="headerlink" title="重新加载配置文件"></a>重新加载配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;data&#x2F;logs&#x2F;nginx</span><br><span class="line">nginx -t</span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><blockquote><p> <strong>注：泛域名，访问任何业务域，会调用vip，分发流量至traefik81端口</strong></p></blockquote><h3 id="浏览器访问"><a href="#浏览器访问" class="headerlink" title="浏览器访问"></a>浏览器访问</h3><p><a href="http://traefik.od.com/dashboard/" target="_blank" rel="noopener">http://traefik.od.com/dashboard/</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gff8ezfmdsj31ro0u0dlq.jpg" alt="image-20200603173213883"></p><h2 id="K8S的GUI资源管理插件-dashboard"><a href="#K8S的GUI资源管理插件-dashboard" class="headerlink" title="K8S的GUI资源管理插件-dashboard"></a>K8S的GUI资源管理插件-dashboard</h2><h3 id="准备dashboard镜像"><a href="#准备dashboard镜像" class="headerlink" title="准备dashboard镜像"></a>准备dashboard镜像</h3><p><code>[root@wang-200 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># docker search kubernetes-dashboard-amd64 其他地址可能快点</span><br><span class="line">docker pull k8scn&#x2F;kubernetes-dashboard-amd64:v1.8.3</span><br><span class="line">docker tag k8scn&#x2F;kubernetes-dashboard-amd64:v1.8.3 harbor.od.com&#x2F;public&#x2F;kubernetes-dashboard:v1.8.3</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;kubernetes-dashboard:v1.8.3</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-2"><a href="#准备资源配置清单-2" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p><strong>创建并进入dashboard资源清单目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dashboard</span><br></pre></td></tr></table></figure><p><strong>rbac.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dashboard&#x2F;rbac.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>deployment.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dashboard&#x2F;deployment.yaml </span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kubernetes-dashboard</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubernetes-dashboard</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;kubernetes-dashboard:v1.8.3</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 300Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 50m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8443</span><br><span class="line">          protocol: TCP</span><br><span class="line">        args:</span><br><span class="line">          # PLATFORM-SPECIFIC ARGS HERE</span><br><span class="line">          - --auto-generate-certificates</span><br><span class="line">          - --token-ttl&#x3D;43200 </span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          mountPath: &#x2F;tmp</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">            path: &#x2F;</span><br><span class="line">            port: 8443</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: tmp-volume</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      serviceAccountName: kubernetes-dashboard-admin</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">        operator: &quot;Exists&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>service.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dashboard&#x2F;service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  ports:</span><br><span class="line">  - port: 443</span><br><span class="line">    targetPort: 8443</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>ingress.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;dashboard&#x2F;ingress.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io&#x2F;ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: dashboard.od.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          serviceName: kubernetes-dashboard</span><br><span class="line">          servicePort: 443</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-2"><a href="#应用资源配置清单-2" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;deployment.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;service.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;ingress.yaml</span><br></pre></td></tr></table></figure><p><strong>执行过程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;rbac.yaml</span><br><span class="line">serviceaccount&#x2F;kubernetes-dashboard-admin created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;kubernetes-dashboard-admin created</span><br><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;deployment.yaml</span><br><span class="line">deployment.apps&#x2F;kubernetes-dashboard created</span><br><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;service.yaml</span><br><span class="line">service&#x2F;kubernetes-dashboard created</span><br><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;dashboard&#x2F;ingress.yaml</span><br><span class="line">ingress.extensions&#x2F;kubernetes-dashboard created</span><br></pre></td></tr></table></figure><p><strong>查看创建的资源</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pods -n kube-system|grep dashboard</span><br><span class="line">kubernetes-dashboard-59dfb9868d-hsgwn   1&#x2F;1     Running   0          35s</span><br><span class="line">[root@wang-200 ~]# kubectl get svc -n kube-system|grep dashboard</span><br><span class="line">kubernetes-dashboard      ClusterIP   10.2.244.60    &lt;none&gt;        443&#x2F;TCP                  41s</span><br><span class="line">[root@wang-200 ~]# kubectl get ingress -n kube-system|grep dashboard</span><br><span class="line">kubernetes-dashboard   dashboard.od.com             80      46s</span><br></pre></td></tr></table></figure><h3 id="配置认证"><a href="#配置认证" class="headerlink" title="配置认证"></a>配置认证</h3><p>使用token(令牌)需要https协议，因为treafik代理的http，所以要创建证书去https访问dashboard</p><p><strong>cfssl签发证书</strong></p><p><code>[root@wang-200 ~]# cd /opt/certs/</code></p><p>设置证书信息</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;certs&#x2F;od.com-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;*.od.com&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;od&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>签发证书</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;server od.com-csr.json |cfssl-json -bare od.com</span><br><span class="line">[root@wang-200 certs]# ls od.com*</span><br><span class="line">od.com.csr  od.com-csr.json  od.com-key.pem  od.com.pem</span><br></pre></td></tr></table></figure><p><strong>拷贝证书</strong></p><p>代理节点(wang-12, wang-11)</p><p><code>[root@wang-11 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;etc&#x2F;nginx&#x2F;certs</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;od.com.pem &#x2F;etc&#x2F;nginx&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;od.com-key.pem &#x2F;etc&#x2F;nginx&#x2F;certs&#x2F;</span><br></pre></td></tr></table></figure><p>创建nginx 配置</p><p><code>[root@wang-11 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;dashboard.od.com.conf</span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name dashboard.od.com;   </span><br><span class="line">    rewrite ^(.*)$ https:&#x2F;&#x2F;\$&#123;server_name&#125;\$1 permanent;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name dashboard.od.com;</span><br><span class="line">    access_log &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;dashboard.od.com.log;</span><br><span class="line"></span><br><span class="line">    ssl_certificate &quot;certs&#x2F;od.com.pem&quot;;</span><br><span class="line">    ssl_certificate_key &quot;certs&#x2F;od.com-key.pem&quot;;</span><br><span class="line">    ssl_session_cache shared:SSL:1m;</span><br><span class="line">    ssl_session_timeout  10m;</span><br><span class="line">    ssl_ciphers HIGH:!aNULL:!MD5;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;default_backend_traefik;</span><br><span class="line">        proxy_set_header Host       \$http_host;</span><br><span class="line">        proxy_set_header x-forwarded-for \$proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>加载配置</strong></p><p><code>[root@wang-11 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><h4 id="访问页面"><a href="#访问页面" class="headerlink" title="访问页面"></a>访问页面</h4><p><a href="https://dashboard.od.com" target="_blank" rel="noopener">https://dashboard.od.com</a></p><p>登陆页面，可以使用token令牌登陆</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfg7eyf6qjj317i0p6juc.jpg" alt="登陆窗口"></p><p>登陆以后展示页面</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfg7g9tk03j310m0l4di5.jpg" alt="在这里插入图片描述"></p><h2 id="K8S的资源监控插件-Heapster（官方已废弃）"><a href="#K8S的资源监控插件-Heapster（官方已废弃）" class="headerlink" title="K8S的资源监控插件-Heapster（官方已废弃）"></a>K8S的资源监控插件-Heapster（官方已废弃）</h2><p>该项目将被官方废弃（RETIRED），在1.8版本以后由metricserver替代</p><p>准备heapster镜像</p><p><code>[root@wang-200 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull quay.io&#x2F;bitnami&#x2F;heapster:1.5.4</span><br><span class="line">docker tag quay.io&#x2F;bitnami&#x2F;heapster:1.5.4 harbor.od.com&#x2F;public&#x2F;heapster:v1.5.4</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;heapster:v1.5.4</span><br></pre></td></tr></table></figure><h3 id="准备资源配置清单-3"><a href="#准备资源配置清单-3" class="headerlink" title="准备资源配置清单"></a>准备资源配置清单</h3><p><strong>创建并进入资源配置清单目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;heapster</span><br></pre></td></tr></table></figure><p><strong>rbac.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;heapster&#x2F;rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: heapster</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:heapster</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>deploy.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;heapster&#x2F;deploy.yaml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        task: monitoring</span><br><span class="line">        k8s-app: heapster</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: heapster</span><br><span class="line">      containers:</span><br><span class="line">      - name: heapster</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;heapster:v1.5.4</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;opt&#x2F;bitnami&#x2F;heapster&#x2F;bin&#x2F;heapster</span><br><span class="line">        - --source&#x3D;kubernetes:https:&#x2F;&#x2F;kubernetes.default</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>svc.yaml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;k8s&#x2F;yaml&#x2F;heapster&#x2F;svc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    task: monitoring</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &#39;true&#39;</span><br><span class="line">    kubernetes.io&#x2F;name: Heapster</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8082</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: heapster</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置清单-3"><a href="#应用资源配置清单-3" class="headerlink" title="应用资源配置清单"></a>应用资源配置清单</h3><p><strong>执行命令</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;heapster&#x2F;rbac.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;heapster&#x2F;deploy.yaml</span><br><span class="line">kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;heapster&#x2F;svc.yaml</span><br></pre></td></tr></table></figure><p><strong>命令执行过程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;heapster&#x2F;rbac.yaml</span><br><span class="line">serviceaccount&#x2F;heapster created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;heapster created</span><br><span class="line"></span><br><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;heapster&#x2F;deploy.yaml</span><br><span class="line">deployment.extensions&#x2F;heapster created</span><br><span class="line"></span><br><span class="line">[root@wang-200 ~]# kubectl apply -f http:&#x2F;&#x2F;doc.k8s.od.com&#x2F;yaml&#x2F;heapster&#x2F;svc.yaml</span><br><span class="line">service&#x2F;heapster created</span><br></pre></td></tr></table></figure><p><strong>查看创建的资源</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pods -n kube-system|grep heapster</span><br><span class="line">heapster-b5b9f794-snkp5                 1&#x2F;1     Running   0          42s</span><br></pre></td></tr></table></figure><h3 id="重启dashboard，访问"><a href="#重启dashboard，访问" class="headerlink" title="重启dashboard，访问"></a>重启dashboard，访问</h3><p><a href="https://dashboard.od.com" target="_blank" rel="noopener">https://dashboard.od.com</a></p><p>CPU使用率和内存使用率</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfg88dmqe4j30xm08a750.jpg" alt="image-20200604141129557"></p><p>容器组资源</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfg88peza6j30x8093gn5.jpg" alt="image-20200604141148174"></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四、k8s-部署node组件</title>
      <link href="/2020/06/02/%E5%9B%9B%E3%80%81k8s-%E9%83%A8%E7%BD%B2node%E7%BB%84%E4%BB%B6/"/>
      <url>/2020/06/02/%E5%9B%9B%E3%80%81k8s-%E9%83%A8%E7%BD%B2node%E7%BB%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="准备pause基础镜像"><a href="#准备pause基础镜像" class="headerlink" title="准备pause基础镜像"></a>准备pause基础镜像</h2><h3 id="为什么需要这个pause基础镜像？"><a href="#为什么需要这个pause基础镜像？" class="headerlink" title="为什么需要这个pause基础镜像？"></a>为什么需要这个pause基础镜像？</h3><p>原因：需要用一个pause基础镜像把这台机器的pod拉起来，因为kubelet是干活的节点，它帮我们调度docker引擎，边车模式，让kebelet控制一个小镜像，先于我们的业务容器起来，让它帮我们业务容器去设置：UTC、NET、IPC，让它先把命名空间占上，业务容易还没起来的时候，pod的ip已经分配出来 </p><h3 id="下载pause镜像"><a href="#下载pause镜像" class="headerlink" title="下载pause镜像"></a>下载pause镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull kubernetes&#x2F;pause</span><br></pre></td></tr></table></figure><h3 id="提交至docker私有仓库（harbor）中"><a href="#提交至docker私有仓库（harbor）中" class="headerlink" title="提交至docker私有仓库（harbor）中"></a>提交至docker私有仓库（harbor）中</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# docker tag kubernetes&#x2F;pause harbor.od.com&#x2F;public&#x2F;pause</span><br><span class="line">[root@wang-200 ~]# docker push harbor.od.com&#x2F;public&#x2F;pause</span><br><span class="line">The push refers to repository [harbor.od.com&#x2F;public&#x2F;pause]</span><br><span class="line">5f70bf18a086: Mounted from public&#x2F;nginx </span><br><span class="line">e16a89738269: Pushed </span><br><span class="line">latest: digest: sha256:b31bfb4d0213f254d361e0079deaaebefa4f82ba7aa76ef82e90b4935ad5b105 size: 938</span><br></pre></td></tr></table></figure><h2 id="部署-kubelet服务"><a href="#部署-kubelet服务" class="headerlink" title="部署 kubelet服务"></a>部署 kubelet服务</h2><h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com（为了展现效果，暂不部署）</td><td>192.168.70.21</td><td>kubelet</td></tr><tr><td>wang-22.host.com（为了展现效果，暂不部署）</td><td>192.168.70.22</td><td>kubelet</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>kubelet</td></tr><tr><td>wang-24.host.com</td><td>192.168.70.24</td><td>kubelet</td></tr></tbody></table><h3 id="创建签名证书"><a href="#创建签名证书" class="headerlink" title="创建签名证书"></a>创建签名证书</h3><p><strong>创建生成证书签名请求（csr）的json配置文件</strong></p><p> <code>[root@wang-200 certs]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;certs&#x2F;kubelet-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;k8s-kubelet&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.70.21&quot;,</span><br><span class="line">    &quot;192.168.70.22&quot;,</span><br><span class="line">    &quot;192.168.70.23&quot;,</span><br><span class="line">    &quot;192.168.70.24&quot;,</span><br><span class="line">    &quot;192.168.70.25&quot;,</span><br><span class="line">    &quot;192.168.70.26&quot;,</span><br><span class="line">    &quot;192.168.70.27&quot;,</span><br><span class="line">    &quot;192.168.70.28&quot;,</span><br><span class="line">    &quot;192.168.70.29&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;od&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>生成证书与私钥文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;server kubelet-csr.json | cfssl-json -bare kubelet</span><br><span class="line"></span><br><span class="line">[root@wang-200 certs]# ls kubelet*</span><br><span class="line">kubelet.csr  kubelet-csr.json  kubelet-key.pem  kubelet.pem</span><br></pre></td></tr></table></figure><h3 id="创建配置文件kubelet-kubeconfig"><a href="#创建配置文件kubelet-kubeconfig" class="headerlink" title="创建配置文件kubelet.kubeconfig"></a>创建配置文件kubelet.kubeconfig</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;</span><br><span class="line">cd &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;</span><br></pre></td></tr></table></figure><p><strong>set-cluster</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config set-cluster myk8s \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;https:&#x2F;&#x2F;api.k8s.od.com:8443 \</span><br><span class="line">  --kubeconfig&#x3D;kubelet.kubeconfig</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#返回结果：</span><br><span class="line">Cluster &quot;myk8s&quot; set.</span><br></pre></td></tr></table></figure><p><strong>set-credentials</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config set-credentials k8s-node \</span><br><span class="line">  --client-certificate&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;client.pem \</span><br><span class="line">  --client-key&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;client-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;kubelet.kubeconfig</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#返回结果：</span><br><span class="line">User &quot;k8s-node&quot; set.</span><br></pre></td></tr></table></figure><p><strong>set-context</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config set-context myk8s-context \</span><br><span class="line">  --cluster&#x3D;myk8s \</span><br><span class="line">  --user&#x3D;k8s-node \</span><br><span class="line">  --kubeconfig&#x3D;kubelet.kubeconfig</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#返回结果：</span><br><span class="line">Context &quot;myk8s-context&quot; modified.</span><br></pre></td></tr></table></figure><p><strong>use-context</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 conf]# kubectl config use-context myk8s-context --kubeconfig&#x3D;kubelet.kubeconfig</span><br><span class="line">Switched to context &quot;myk8s-context&quot;.</span><br></pre></td></tr></table></figure><p><strong>查看生成的文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 conf]# ls</span><br><span class="line">kubelet.kubeconfig</span><br></pre></td></tr></table></figure><p><strong>拷贝文件到本地</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;kubelet.kubeconfig ~&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure><h3 id="集群角色绑定到用户"><a href="#集群角色绑定到用户" class="headerlink" title="集群角色绑定到用户"></a>集群角色绑定到用户</h3><p><strong>1.创建资源配置清单</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;k8s-node.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: k8s-node</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: User</span><br><span class="line">  name: k8s-node</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>2.根据配置文件创建用户</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建角色后会存到etcd里</span><br><span class="line">[root@wang-200 ~]# kubectl apply -f &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;k8s-node.yaml</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;k8s-node created</span><br></pre></td></tr></table></figure><p><strong>3.查询集群角色</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get clusterrolebinding k8s-node</span><br><span class="line">NAME       AGE</span><br><span class="line">k8s-node   37s</span><br></pre></td></tr></table></figure><h3 id="拷贝安装包到服务器"><a href="#拷贝安装包到服务器" class="headerlink" title="拷贝安装包到服务器"></a>拷贝安装包到服务器</h3><p>如果和控制节点在一台机器上，这一步可省略</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;kubernetes-v1.15.2</span><br><span class="line">scp -r wang-200:&#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;* &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F; &#x2F;opt&#x2F;kubernetes</span><br><span class="line">ln -s &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubectl &#x2F;usr&#x2F;bin&#x2F;kubectl</span><br></pre></td></tr></table></figure><p><strong>拷贝kueblet证书</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;kubelet.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;kubelet-key.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;ca.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;client.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;client-key.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;kubelet.kubeconfig &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;kubelet.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="创建kubelet启动脚本-wang-24例"><a href="#创建kubelet启动脚本-wang-24例" class="headerlink" title="创建kubelet启动脚本(wang-24例)"></a>创建kubelet启动脚本(wang-24例)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubelet.sh</span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">.&#x2F;kubelet \\</span><br><span class="line">  --anonymous-auth&#x3D;false \\</span><br><span class="line">  --cgroup-driver systemd \\</span><br><span class="line">  --cluster-dns 10.2.0.2 \\</span><br><span class="line">  --cluster-domain cluster.local \\</span><br><span class="line">  --runtime-cgroups&#x3D;&#x2F;systemd&#x2F;system.slice \\</span><br><span class="line">  --kubelet-cgroups&#x3D;&#x2F;systemd&#x2F;system.slice \\</span><br><span class="line">  --fail-swap-on&#x3D;&quot;false&quot; \\</span><br><span class="line">  --client-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">  --tls-cert-file .&#x2F;certs&#x2F;kubelet.pem \\</span><br><span class="line">  --tls-private-key-file .&#x2F;certs&#x2F;kubelet-key.pem \\</span><br><span class="line">  --hostname-override wang-24.host.com \\</span><br><span class="line">  --image-gc-high-threshold 20 \\</span><br><span class="line">  --image-gc-low-threshold 10 \\</span><br><span class="line">  --kubeconfig .&#x2F;conf&#x2F;kubelet.kubeconfig \\</span><br><span class="line">  --log-dir &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-kubelet \\</span><br><span class="line">  --pod-infra-container-image harbor.od.com&#x2F;public&#x2F;pause:latest \\</span><br><span class="line">  --root-dir &#x2F;data&#x2F;kubelet</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 适配对应的主机</span><br><span class="line">sed -i &quot;s&amp;wang-24.host.com&amp;wang-$&#123;HOSTNUM&#125;.host.com&amp;&quot; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubelet.sh</span><br></pre></td></tr></table></figure><blockquote><p>*注意：kubelet集群各主机的启动脚本略不同，其他节点注意修改：–hostname-override</p></blockquote><blockquote><p> –anonymous-auth=false    # 匿名登陆，这里设置为不允许</p><p> –cgroup-driver systemd     # 这里需要和docker的daemon.json保持一直</p><p> –fail-swap-on=”false”          # 设置为不关闭swap分区也正常启动，正常需要关闭swap分区的。</p><p> –hostname-override wang-21.host.com      # 主机名</p><p> –pod-infra-container-image harbor.od.com/public/pause:latest       # pause地址</p></blockquote><p><strong>授权并创建日志目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubelet.sh </span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-kubelet &#x2F;data&#x2F;kubelet</span><br></pre></td></tr></table></figure><h3 id="创建-supervisor配置"><a href="#创建-supervisor配置" class="headerlink" title="创建 supervisor配置"></a>创建 supervisor配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-kubelet.ini</span><br><span class="line">[program:kube-kubelet-70-24]</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubelet.sh         ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                            ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin                  ; directory to cwd to before exec (def no cwd) </span><br><span class="line">autostart&#x3D;true                                        ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                                      ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;22                                          ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                                        ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                                         ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                                       ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                                       ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;root                                             ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;false                                 ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-kubelet&#x2F;kubelet.stdout.log       ; stdout log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                          ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                              ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                           ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                           ; emit events on stdout writes (default false)</span><br><span class="line">stderr_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-kubelet&#x2F;kubelet.stderr.log       ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stderr_logfile_maxbytes&#x3D;64MB                          ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stderr_logfile_backups&#x3D;4                              ; # of stderr logfile backups (default 10)</span><br><span class="line">stderr_capture_maxbytes&#x3D;1MB                           ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stderr_events_enabled&#x3D;false                           ; emit events on stderr writes (default false)</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改适应其他主机</span><br><span class="line">sed -i &quot;s&amp;kube-kubelet-70-24&amp;kube-kubelet-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-kubelet.ini</span><br></pre></td></tr></table></figure><blockquote><p><em>注意：其他主机部署时请注意修改program标签</em></p></blockquote><h3 id="启动服务并检查"><a href="#启动服务并检查" class="headerlink" title="启动服务并检查"></a>启动服务并检查</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# supervisorctl update</span><br><span class="line">kube-kubelet-70-24: added process group</span><br><span class="line">[root@wang-24 kube-kubelet]# supervisorctl status</span><br><span class="line">kube-kubelet-70-24               RUNNING   pid 52982, uptime 0:00:25</span><br></pre></td></tr></table></figure><h3 id="部署启动集群其他主机-略过"><a href="#部署启动集群其他主机-略过" class="headerlink" title="部署启动集群其他主机(略过)"></a>部署启动集群其他主机(略过)</h3><p><strong>检查运算节点集群</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get node</span><br><span class="line">NAME               STATUS   ROLES    AGE    VERSION</span><br><span class="line">wang-23.host.com   Ready    &lt;none&gt;   11s    v1.15.2</span><br><span class="line">wang-24.host.com   Ready    &lt;none&gt;   5m2s   v1.15.2</span><br></pre></td></tr></table></figure><h2 id="给主机打上角色标签"><a href="#给主机打上角色标签" class="headerlink" title="给主机打上角色标签"></a>给主机打上角色标签</h2><p>标签功能是特色管理功能之一</p><h3 id="为主机打标签"><a href="#为主机打标签" class="headerlink" title="为主机打标签"></a>为主机打标签</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl label node wang-23.host.com node-role.kubernetes.io&#x2F;master&#x3D; </span><br><span class="line">node&#x2F;wang-23.host.com labeled</span><br><span class="line">[root@wang-200 ~]# kubectl label node wang-23.host.com node-role.kubernetes.io&#x2F;node&#x3D;</span><br><span class="line">node&#x2F;wang-23.host.com labeled</span><br><span class="line">[root@wang-200 ~]# kubectl label node wang-24.host.com node-role.kubernetes.io&#x2F;node&#x3D;</span><br><span class="line">node&#x2F;wang-24.host.com labeled</span><br></pre></td></tr></table></figure><h3 id="查看主机标签"><a href="#查看主机标签" class="headerlink" title="查看主机标签"></a>查看主机标签</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get node</span><br><span class="line">NAME               STATUS   ROLES         AGE   VERSION</span><br><span class="line">wang-23.host.com   Ready    master,node   14m   v1.15.2</span><br><span class="line">wang-24.host.com   Ready    node          18m   v1.15.2</span><br></pre></td></tr></table></figure><h2 id="部署-kube-proxy服务"><a href="#部署-kube-proxy服务" class="headerlink" title="部署 kube-proxy服务"></a>部署 kube-proxy服务</h2><p>集群规划</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com（为了展现效果，暂不部署）</td><td>192.168.70.21</td><td>kube-proxy</td></tr><tr><td>wang-22.host.com（为了展现效果，暂不部署）</td><td>192.168.70.22</td><td>kube-proxy</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>kube-proxy</td></tr><tr><td>wang-24.host.com</td><td>192.168.70.24</td><td>kube-proxy</td></tr></tbody></table><p>注意：这里部署以wang-24主机为例，其他运算节点类似</p><h3 id="签发kube-proxy证书"><a href="#签发kube-proxy证书" class="headerlink" title="签发kube-proxy证书"></a>签发kube-proxy证书</h3><p><strong>创建生成证书签名请求（csr）的json配置文件</strong></p><p><code>[root@wang-200 ~]# cd /opt/certs/</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; kube-proxy-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;od&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>生成kubelet证书和私钥</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;client kube-proxy-csr.json |cfssl-json -bare kube-proxy-client</span><br><span class="line"></span><br><span class="line">[root@wang-200 certs]# ls kube-proxy-*</span><br><span class="line">kube-proxy-client.csr  kube-proxy-client-key.pem  kube-proxy-client.pem  kube-proxy-csr.json</span><br></pre></td></tr></table></figure><h3 id="拷贝kube-proxy证书"><a href="#拷贝kube-proxy证书" class="headerlink" title="拷贝kube-proxy证书"></a>拷贝kube-proxy证书</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;kube-proxy-client.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;kube-proxy-client-key.pem &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br></pre></td></tr></table></figure><h3 id="创建配置文件kube-proxy-kubeconfig"><a href="#创建配置文件kube-proxy-kubeconfig" class="headerlink" title="创建配置文件kube-proxy.kubeconfig"></a>创建配置文件kube-proxy.kubeconfig</h3><p>只需要在<code>wang-200</code>主机操作，再将生成的配置文件拷贝到各规划节点即可。</p><p><strong>1.切换至conf目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cd &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf</span><br></pre></td></tr></table></figure><p><strong>set-cluster</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config set-cluster myk8s \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;https:&#x2F;&#x2F;api.k8s.od.com:8443 \</span><br><span class="line">  --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 返回结果</span><br><span class="line">Cluster &quot;myk8s&quot; set.</span><br></pre></td></tr></table></figure><p><strong>set-credentials</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;kube-proxy-client.pem \</span><br><span class="line">  --client-key&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;kube-proxy-client-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 返回结果</span><br><span class="line">User &quot;kube-proxy&quot; set.</span><br></pre></td></tr></table></figure><p><strong>set-context</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config set-context myk8s-context \</span><br><span class="line">  --cluster&#x3D;myk8s \</span><br><span class="line">  --user&#x3D;kube-proxy \</span><br><span class="line">  --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;返回结果</span><br><span class="line">Context &quot;myk8s-context&quot; created.</span><br></pre></td></tr></table></figure><p><strong>use-context</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 conf]# kubectl config use-context myk8s-context --kubeconfig&#x3D;kube-proxy.kubeconfig</span><br><span class="line">Switched to context &quot;myk8s-context&quot;.</span><br></pre></td></tr></table></figure><p><strong>查看生成配置文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 conf]# ll kube-proxy.kubeconfig</span><br><span class="line">-rw-------. 1 root root 6252 6月   3 10:06 kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="配置ipvs-转发"><a href="#配置ipvs-转发" class="headerlink" title="配置ipvs 转发"></a>配置ipvs 转发</h3><p><strong>查看ipvs模块是否开启</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# lsmod |grep ip_vs</span><br><span class="line"># 无结果,说明未开启</span><br></pre></td></tr></table></figure><p><strong>开启ipvs模块</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;data&#x2F;shell&#x2F;ipvs.sh</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">ipvs_mods_dir&#x3D;&quot;&#x2F;usr&#x2F;lib&#x2F;modules&#x2F;\$(uname -r)&#x2F;kernel&#x2F;net&#x2F;netfilter&#x2F;ipvs&quot;</span><br><span class="line">for i in \$(ls \$ipvs_mods_dir|grep -o &quot;^[^.]*&quot;)</span><br><span class="line">do</span><br><span class="line">  &#x2F;sbin&#x2F;modinfo -F filename \$i &amp;&gt;&#x2F;dev&#x2F;null</span><br><span class="line">  if [ \$? -eq 0 ];then</span><br><span class="line">    &#x2F;sbin&#x2F;modprobe \$i</span><br><span class="line">  fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh &#x2F;data&#x2F;shell&#x2F;ipvs.sh</span><br></pre></td></tr></table></figure><p><strong>检测ipvs模块是否开启</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# lsmod |grep ip_vs</span><br><span class="line">ip_vs_wrr              12697  0 </span><br><span class="line">ip_vs_wlc              12519  0 </span><br><span class="line">ip_vs_sh               12688  0 </span><br><span class="line">ip_vs_sed              12519  0 </span><br><span class="line">ip_vs_rr               12600  0 </span><br><span class="line">ip_vs_pe_sip           12740  0 </span><br><span class="line">nf_conntrack_sip       33860  1 ip_vs_pe_sip</span><br><span class="line">ip_vs_nq               12516  0 </span><br><span class="line">ip_vs_lc               12516  0 </span><br><span class="line">ip_vs_lblcr            12922  0 </span><br><span class="line">ip_vs_lblc             12819  0 </span><br><span class="line">ip_vs_ftp              13079  0 </span><br><span class="line">ip_vs_dh               12688  0 </span><br><span class="line">ip_vs                 145497  24 ip_vs_dh,ip_vs_lc,ip_vs_nq,ip_vs_rr,ip_vs_sh,ip_vs_ftp,ip_vs_sed,ip_vs_wlc,ip_vs_wrr,ip_vs_pe_sip,ip_vs_lblcr,ip_vs_lblc</span><br><span class="line">nf_nat                 26787  3 ip_vs_ftp,nf_nat_ipv4,nf_nat_masquerade_ipv4</span><br><span class="line">nf_conntrack          133095  8 ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_sip,nf_conntrack_ipv4</span><br><span class="line">libcrc32c              12644  4 xfs,ip_vs,nf_nat,nf_conntrack</span><br></pre></td></tr></table></figure><h3 id="创建kube-proxy启动脚本"><a href="#创建kube-proxy启动脚本" class="headerlink" title="创建kube-proxy启动脚本"></a>创建kube-proxy启动脚本</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-proxy.sh</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">.&#x2F;kube-proxy \\</span><br><span class="line">  --cluster-cidr 172.16.0.0&#x2F;16 \\</span><br><span class="line">  --hostname-override wang-24.host.com \\</span><br><span class="line">  --proxy-mode&#x3D;ipvs \\</span><br><span class="line">  --ipvs-scheduler&#x3D;nq \\</span><br><span class="line">  --kubeconfig .&#x2F;conf&#x2F;kube-proxy.kubeconfig</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -i &quot;s&amp;wang-24.host.com&amp;wang-$&#123;HOSTNUM&#125;.host.com&amp;&quot; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-proxy.sh</span><br></pre></td></tr></table></figure><blockquote><p><em>注意：其他主机部署时请注意修改<code>--hostname-override</code>该主机的主机名</em></p></blockquote><h3 id="检查配置、授权、创建日志目录"><a href="#检查配置、授权、创建日志目录" class="headerlink" title="检查配置、授权、创建日志目录"></a>检查配置、授权、创建日志目录</h3><p><strong>拷贝kube-proxy.kubeconfig 到wang-24</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-proxy.sh </span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-proxy</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;kube-proxy.kubeconfig &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;</span><br></pre></td></tr></table></figure><h3 id="创建supervisor配置"><a href="#创建supervisor配置" class="headerlink" title="创建supervisor配置"></a>创建supervisor配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-proxy.ini</span><br><span class="line">[program:kube-proxy-70-24]</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-proxy.sh                 ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                                       ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin                             ; directory to cwd to before exec (def no cwd)</span><br><span class="line">autostart&#x3D;true                                                   ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                                                 ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;22                                                     ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                                                   ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                                                    ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                                                  ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                                                  ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;root                                                        ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;false                                            ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-proxy&#x2F;proxy.stdout.log     ; stdout log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                                     ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                                         ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                                      ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                                      ; emit events on stdout writes (default false)</span><br><span class="line">stderr_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-proxy&#x2F;proxy.stderr.log     ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stderr_logfile_maxbytes&#x3D;64MB                                     ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stderr_logfile_backups&#x3D;4                                         ; # of stderr logfile backups (default 10)</span><br><span class="line">stderr_capture_maxbytes&#x3D;1MB                                      ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stderr_events_enabled&#x3D;false                                      ; emit events on stderr writes (default false)</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改主机名，适应对应的主机</span><br><span class="line">sed -i &quot;s&amp;kube-proxy-70-24&amp;kube-proxy-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-proxy.ini</span><br></pre></td></tr></table></figure><blockquote><p><em>注意：其他主机部署时请注意修改program标签</em></p></blockquote><h3 id="启动并检测结果"><a href="#启动并检测结果" class="headerlink" title="启动并检测结果"></a>启动并检测结果</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# supervisorctl update                          </span><br><span class="line">kube-proxy-70-24: added process group</span><br><span class="line">[root@wang-24 ~]# supervisorctl status                          </span><br><span class="line">kube-kubelet-70-24               RUNNING   pid 52982, uptime 0:37:22</span><br><span class="line">kube-proxy-70-24                 STARTING</span><br></pre></td></tr></table></figure><h3 id="安装部署集群其他主机（略过）"><a href="#安装部署集群其他主机（略过）" class="headerlink" title="安装部署集群其他主机（略过）"></a>安装部署集群其他主机（略过）</h3><h2 id="验证kubernetes集群"><a href="#验证kubernetes集群" class="headerlink" title="验证kubernetes集群"></a>验证kubernetes集群</h2><h3 id="创建资源配置清单"><a href="#创建资源配置清单" class="headerlink" title="创建资源配置清单"></a>创建资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;root&#x2F;yaml&#x2F;nginx-ds.yml</span><br><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ds</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-ds</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: my-nginx</span><br><span class="line">        image: harbor.od.com&#x2F;public&#x2F;nginx:v1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="应用资源配置"><a href="#应用资源配置" class="headerlink" title="应用资源配置"></a>应用资源配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl create -f &#x2F;root&#x2F;yaml&#x2F;nginx-ds.yml </span><br><span class="line">daemonset.extensions&#x2F;nginx-ds created</span><br></pre></td></tr></table></figure><h3 id="验证资源配置清单"><a href="#验证资源配置清单" class="headerlink" title="验证资源配置清单"></a>验证资源配置清单</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get pod</span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-ds-8p4gg   1&#x2F;1     Running   0          57s</span><br><span class="line">nginx-ds-vjct6   1&#x2F;1     Running   0          57s</span><br><span class="line">[root@wang-200 ~]# kubectl get pod -o wide</span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE   IP            NODE               NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-ds-8p4gg   1&#x2F;1     Running   0          59s   172.16.23.2   wang-23.host.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-ds-vjct6   1&#x2F;1     Running   0          59s   172.16.24.2   wang-24.host.com   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h3 id="访问pod资源测试"><a href="#访问pod资源测试" class="headerlink" title="访问pod资源测试"></a>访问pod资源测试</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-24 ~]# curl -I 172.16.24.2</span><br><span class="line">HTTP&#x2F;1.1 200 OK</span><br><span class="line">Server: nginx&#x2F;1.7.9</span><br><span class="line">Date: Wed, 03 Jun 2020 02:21:14 GMT</span><br><span class="line">Content-Type: text&#x2F;html</span><br><span class="line">Content-Length: 612</span><br><span class="line">Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;54999765-264&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@wang-24 ~]# curl -I 172.16.23.2</span><br><span class="line">curl: (7) Failed connect to 172.16.23.2:80; 连接超时</span><br></pre></td></tr></table></figure><p>问题：跨宿主机的pod资源，无法访问。</p><p>解决方案：通过CNI网络插件实现POD资源能够跨宿主机就行通信</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三、k8s-部署master组件</title>
      <link href="/2020/05/31/%E4%B8%89%E3%80%81k8s-%E9%83%A8%E7%BD%B2master%E7%BB%84%E4%BB%B6/"/>
      <url>/2020/05/31/%E4%B8%89%E3%80%81k8s-%E9%83%A8%E7%BD%B2master%E7%BB%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="部署etcd服务"><a href="#部署etcd服务" class="headerlink" title="部署etcd服务"></a>部署etcd服务</h2><h3 id="etcd集群规划"><a href="#etcd集群规划" class="headerlink" title="etcd集群规划"></a>etcd集群规划</h3><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com</td><td>192.168.70.21</td><td>etcd lead</td></tr><tr><td>wang-22.host.com</td><td>192.168.70.22</td><td>etcd follow</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>etcd follow</td></tr></tbody></table><h3 id="etcd-签发证书-wang-200主机"><a href="#etcd-签发证书-wang-200主机" class="headerlink" title="etcd 签发证书 (wang-200主机)"></a>etcd 签发证书 (wang-200主机)</h3><p><strong>创建基于根证书的config配置文件</strong></p><p><code>vim /opt/certs/ca-config.json</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;signing&quot;: &#123;</span><br><span class="line">        &quot;default&quot;: &#123;</span><br><span class="line">            &quot;expiry&quot;: &quot;175200h&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;profiles&quot;: &#123;</span><br><span class="line">            &quot;server&quot;: &#123;</span><br><span class="line">                &quot;expiry&quot;: &quot;175200h&quot;,</span><br><span class="line">                &quot;usages&quot;: [</span><br><span class="line">                    &quot;signing&quot;,</span><br><span class="line">                    &quot;key encipherment&quot;,</span><br><span class="line">                    &quot;server auth&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;client&quot;: &#123;</span><br><span class="line">                &quot;expiry&quot;: &quot;175200h&quot;,</span><br><span class="line">                &quot;usages&quot;: [</span><br><span class="line">                    &quot;signing&quot;,</span><br><span class="line">                    &quot;key encipherment&quot;,</span><br><span class="line">                    &quot;client auth&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;peer&quot;: &#123;</span><br><span class="line">                &quot;expiry&quot;: &quot;175200h&quot;,</span><br><span class="line">                &quot;usages&quot;: [</span><br><span class="line">                    &quot;signing&quot;,</span><br><span class="line">                    &quot;key encipherment&quot;,</span><br><span class="line">                    &quot;server auth&quot;,</span><br><span class="line">                    &quot;client auth&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>证书类型</p><p>client certificate：客户端使用，用于服务端认证客户端,如etcdctl、etcd proxy、fleetctl、docker客户端</p><p>server certificate：服务端使用，客户端以此验证服务端身份,例如docker服务端、kube-apiserver</p><p>peer certificate：双向证书，用于etcd集群成员间通信</p></blockquote><p><strong>创建生成自签证书的签名请求(csr)的 json配置文件</strong></p><p><code>[root@wang-200 certs]# vim /opt/certs/etcd-peer-csr.json</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;k8s-etcd&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">        &quot;192.168.70.21&quot;,</span><br><span class="line">        &quot;192.168.70.22&quot;,</span><br><span class="line">        &quot;192.168.70.23&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;od&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>hosts 段把有可能成为etcd节点的主机都填写进去。</p></blockquote><p><strong>生成证书</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;peer etcd-peer-csr.json|cfssl-json -bare etcd-peer</span><br><span class="line">[root@wang-200 certs]# ls |grep etcd</span><br><span class="line">etcd-peer.csr</span><br><span class="line">etcd-peer-csr.json</span><br><span class="line">etcd-peer-key.pem</span><br><span class="line">etcd-peer.pem</span><br></pre></td></tr></table></figure><h3 id="安装etcd服务"><a href="#安装etcd服务" class="headerlink" title="安装etcd服务"></a>安装etcd服务</h3><p><strong>下载安装包</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# mkdir &#x2F;data&#x2F;soft&#x2F;k8s&#x2F;</span><br><span class="line">[root@wang-200 certs]# wget -O &#x2F;data&#x2F;soft&#x2F;k8s&#x2F;etcd-v3.1.20-linux-amd64.tar.gz https:&#x2F;&#x2F;github.com&#x2F;etcd-io&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;v3.1.20&#x2F;etcd-v3.1.20-linux-amd64.tar.gz #较慢</span><br></pre></td></tr></table></figure><p>拷贝到指定服务器并安装</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp wang-200:&#x2F;data&#x2F;soft&#x2F;k8s&#x2F;etcd-v3.1.20-linux-amd64.tar.gz &#x2F;data&#x2F;soft&#x2F;</span><br><span class="line">tar xf &#x2F;data&#x2F;soft&#x2F;etcd-v3.1.20-linux-amd64.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">mv &#x2F;opt&#x2F;etcd-v3.1.20-linux-amd64 &#x2F;opt&#x2F;etcd-v3.1.20</span><br><span class="line">ln -s &#x2F;opt&#x2F;etcd-v3.1.20 &#x2F;opt&#x2F;etcd</span><br><span class="line">ln -s &#x2F;opt&#x2F;etcd&#x2F;etcdctl &#x2F;usr&#x2F;bin&#x2F;etcdctl</span><br></pre></td></tr></table></figure><p>创建etcd用户和相关目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">useradd -M -s &#x2F;sbin&#x2F;nologin etcd</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;etcd&#x2F;certs&#x2F;  # 存放etcd证书</span><br><span class="line">mkdir -p &#x2F;data&#x2F;etcd&#x2F;  # 存放etcd数据</span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs&#x2F;etcd-server  # 存放etcd日志</span><br><span class="line">chown -R etcd:etcd &#x2F;data&#x2F;etcd &#x2F;data&#x2F;logs&#x2F;etcd-server&#x2F;</span><br></pre></td></tr></table></figure><p>拷贝证书与私钥文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;etcd&#x2F;certs&#x2F;</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;ca.pem .</span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;etcd-peer-key.pem . </span><br><span class="line">scp wang-200:&#x2F;opt&#x2F;certs&#x2F;etcd-peer.pem .</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 certs]# ls</span><br><span class="line">ca.pem  etcd-peer-key.pem  etcd-peer.pem</span><br></pre></td></tr></table></figure><h3 id="创建etcd服务启动脚本"><a href="#创建etcd服务启动脚本" class="headerlink" title="创建etcd服务启动脚本"></a>创建etcd服务启动脚本</h3><div class="hide-toggle" style="border: 1px solid bg"><div class="hide-button toggle-title" style="background-color: bg;color: color"><i class="fa fa-caret-right fa-fw"></i><span>直接粘贴脚本</span></div>    <div class="hide-content"><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh</span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">.&#x2F;etcd --name etcd-server-70-21 \\</span><br><span class="line">       --data-dir &#x2F;data&#x2F;etcd&#x2F;etcd-server \\</span><br><span class="line">       --listen-peer-urls https:&#x2F;&#x2F;192.168.70.21:2380 \\</span><br><span class="line">       --listen-client-urls https:&#x2F;&#x2F;192.168.70.21:2379,http:&#x2F;&#x2F;127.0.0.1:2379 \\</span><br><span class="line">       --quota-backend-bytes 8000000000 \\</span><br><span class="line">       --initial-advertise-peer-urls https:&#x2F;&#x2F;192.168.70.21:2380 \\</span><br><span class="line">       --advertise-client-urls https:&#x2F;&#x2F;192.168.70.21:2379,http:&#x2F;&#x2F;127.0.0.1:2379 \\</span><br><span class="line">       --initial-cluster  etcd-server-70-21&#x3D;https:&#x2F;&#x2F;192.168.70.21:2380,etcd-server-70-22&#x3D;https:&#x2F;&#x2F;192.168.70.22:2380,etcd-server-70-23&#x3D;https:&#x2F;&#x2F;192.168.70.23:2380 \\</span><br><span class="line">       --ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">       --cert-file .&#x2F;certs&#x2F;etcd-peer.pem \\</span><br><span class="line">       --key-file .&#x2F;certs&#x2F;etcd-peer-key.pem \\</span><br><span class="line">       --client-cert-auth  \\</span><br><span class="line">       --trusted-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">       --peer-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">       --peer-cert-file .&#x2F;certs&#x2F;etcd-peer.pem \\</span><br><span class="line">       --peer-key-file .&#x2F;certs&#x2F;etcd-peer-key.pem \\</span><br><span class="line">       --peer-client-cert-auth \\</span><br><span class="line">       --peer-trusted-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">       --log-output stdout</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -i &quot;2s&amp;etcd-server-70-21&amp;etcd-server-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh</span><br><span class="line">sed -i &quot;4,8s&amp;192.168.70.21&amp;192.168.70.$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh</span><br><span class="line">chmod +x &#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh</span><br><span class="line">chown -R etcd:etcd &#x2F;opt&#x2F;etcd-v3.1.20&#x2F;</span><br></pre></td></tr></table></figure></div></div><p><code>vim /opt/etcd/etcd-server-startup.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">.&#x2F;etcd --name etcd-server-70-21 \</span><br><span class="line">       --data-dir &#x2F;data&#x2F;etcd&#x2F;etcd-server \</span><br><span class="line">       --listen-peer-urls https:&#x2F;&#x2F;192.168.70.21:2380 \</span><br><span class="line">       --listen-client-urls https:&#x2F;&#x2F;192.168.70.21:2379,http:&#x2F;&#x2F;127.0.0.1:2379 \</span><br><span class="line">       --quota-backend-bytes 8000000000 \</span><br><span class="line">       --initial-advertise-peer-urls https:&#x2F;&#x2F;192.168.70.21:2380 \</span><br><span class="line">       --advertise-client-urls https:&#x2F;&#x2F;192.168.70.21:2379,http:&#x2F;&#x2F;127.0.0.1:2379 \</span><br><span class="line">       --initial-cluster  etcd-server-70-21&#x3D;https:&#x2F;&#x2F;192.168.70.21:2380,etcd-server-70-22&#x3D;https:&#x2F;&#x2F;192.168.70.22:2380,etcd-server-70-23&#x3D;https:&#x2F;&#x2F;192.168.70.23:2380 \</span><br><span class="line">       --ca-file .&#x2F;certs&#x2F;ca.pem \</span><br><span class="line">       --cert-file .&#x2F;certs&#x2F;etcd-peer.pem \</span><br><span class="line">       --key-file .&#x2F;certs&#x2F;etcd-peer-key.pem \</span><br><span class="line">       --client-cert-auth  \</span><br><span class="line">       --trusted-ca-file .&#x2F;certs&#x2F;ca.pem \</span><br><span class="line">       --peer-ca-file .&#x2F;certs&#x2F;ca.pem \</span><br><span class="line">       --peer-cert-file .&#x2F;certs&#x2F;etcd-peer.pem \</span><br><span class="line">       --peer-key-file .&#x2F;certs&#x2F;etcd-peer-key.pem \</span><br><span class="line">       --peer-client-cert-auth \</span><br><span class="line">       --peer-trusted-ca-file .&#x2F;certs&#x2F;ca.pem \</span><br><span class="line">       --log-output stdout</span><br></pre></td></tr></table></figure><blockquote><p>#各etcd节点，脚本不同的地方(#根据宿主机IP变化)<br>    –name   etcd-server-16-21<br>    –listen-peer-urls<br>    –listen-client-urls<br>    –initial-advertise-peer-urls<br>    –advertise-client-urls</p></blockquote><p><strong>调整权限</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x &#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh</span><br><span class="line">chown -R etcd:etcd &#x2F;opt&#x2F;etcd-v3.1.20&#x2F;</span><br></pre></td></tr></table></figure><h3 id="创建etcd-server的启动配置"><a href="#创建etcd-server的启动配置" class="headerlink" title="创建etcd-server的启动配置"></a>创建etcd-server的启动配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;etcd-server.ini</span><br><span class="line">[program:etcd-server-70-21]                 ; 根据主机改变</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh    ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                  ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;etcd                         ; directory to cwd to before exec (def no cwd)</span><br><span class="line">autostart&#x3D;true                              ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                            ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;30                                ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                              ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                               ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                             ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                             ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;etcd                                   ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;true                        ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;etcd-server&#x2F;etcd.stdout.log     ; stdout log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                    ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                 ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                 ; emit events on stdout writes (default false)</span><br><span class="line">stderr_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;etcd-server&#x2F;etcd.stderr.log      ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stderr_logfile_maxbytes&#x3D;64MB                ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stderr_logfile_backups&#x3D;4                    ; # of stderr logfile backups (default 10)</span><br><span class="line">stderr_capture_maxbytes&#x3D;1MB                 ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stderr_events_enabled&#x3D;false                 ; emit events on stderr writes (default false）</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -i &quot;s&amp;etcd-server-70-21&amp;etcd-server-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;etcd-server.ini</span><br></pre></td></tr></table></figure><h3 id="启动etcd"><a href="#启动etcd" class="headerlink" title="启动etcd"></a>启动etcd</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 certs]# supervisorctl update</span><br><span class="line">etcd-server-70-21: added process group</span><br><span class="line">[root@wang-21 certs]# supervisorctl status</span><br><span class="line">etcd-server-70-21                STARTING  </span><br><span class="line">[root@wang-21 certs]# netstat -luntp|grep etcd</span><br><span class="line">tcp        0      0 192.168.70.21:2379      0.0.0.0:*               LISTEN      57940&#x2F;.&#x2F;etcd        </span><br><span class="line">tcp        0      0 127.0.0.1:2379          0.0.0.0:*               LISTEN      57940&#x2F;.&#x2F;etcd        </span><br><span class="line">tcp        0      0 192.168.70.21:2380      0.0.0.0:*               LISTEN      57940&#x2F;.&#x2F;etcd</span><br></pre></td></tr></table></figure><h3 id="检查集群状态"><a href="#检查集群状态" class="headerlink" title="检查集群状态"></a>检查集群状态</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看集群健康状态</span><br><span class="line">[root@wang-21 ~]# &#x2F;opt&#x2F;etcd&#x2F;etcdctl cluster-health</span><br><span class="line">member 220fa81c6e7fa2e1 is healthy: got healthy result from http:&#x2F;&#x2F;127.0.0.1:2379</span><br><span class="line">member 394ece5834c57ea6 is healthy: got healthy result from http:&#x2F;&#x2F;127.0.0.1:2379</span><br><span class="line">member f97020d34db750ca is healthy: got healthy result from http:&#x2F;&#x2F;127.0.0.1:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"></span><br><span class="line"># 查看etcd集群列表</span><br><span class="line">[root@wang-21 ~]# &#x2F;opt&#x2F;etcd&#x2F;etcdctl member list</span><br><span class="line">220fa81c6e7fa2e1: name&#x3D;etcd-server-70-23 peerURLs&#x3D;https:&#x2F;&#x2F;192.168.70.23:2380 clientURLs&#x3D;http:&#x2F;&#x2F;127.0.0.1:2379,https:&#x2F;&#x2F;192.168.70.23:2379 isLeader&#x3D;false</span><br><span class="line">394ece5834c57ea6: name&#x3D;etcd-server-70-21 peerURLs&#x3D;https:&#x2F;&#x2F;192.168.70.21:2380 clientURLs&#x3D;http:&#x2F;&#x2F;127.0.0.1:2379,https:&#x2F;&#x2F;192.168.70.21:2379 isLeader&#x3D;true</span><br><span class="line">f97020d34db750ca: name&#x3D;etcd-server-70-22 peerURLs&#x3D;https:&#x2F;&#x2F;192.168.70.22:2380 clientURLs&#x3D;http:&#x2F;&#x2F;127.0.0.1:2379,https:&#x2F;&#x2F;192.168.70.22:2379 isLeader&#x3D;false</span><br></pre></td></tr></table></figure><h2 id="部署-kube-apiserver服务"><a href="#部署-kube-apiserver服务" class="headerlink" title="部署 kube-apiserver服务"></a>部署 kube-apiserver服务</h2><h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com</td><td>192.168.70.21</td><td>kube-apiserver</td></tr><tr><td>wang-22.host.com</td><td>192.168.70.22</td><td>kube-apiserver</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>kube-apiserver</td></tr><tr><td>wang-11.host.com</td><td>192.168.70.11</td><td>4层负载均衡</td></tr><tr><td>wang-12.host.com</td><td>192.168.70.12</td><td>4层负载均衡</td></tr></tbody></table><p>这里<code>192.168.70.11</code>和<code>192.168.70.12</code>使用nginx做4层负载均衡器，用keepalived跑一个vip：<code>192.168.70.10</code>,代理两个kube-apiserver，实现高可用</p><h3 id="运维主机签发证书"><a href="#运维主机签发证书" class="headerlink" title="运维主机签发证书"></a>运维主机签发证书</h3><h4 id="签发client证书"><a href="#签发client证书" class="headerlink" title="签发client证书"></a>签发client证书</h4><p><strong>1. 创建生成证书签名请求（csr）的json配置文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;certs&#x2F;client-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;k8s-node&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;wang&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>2. 生成client证书和私钥</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;client client-csr.json | cfssl-json -bare client</span><br><span class="line">[root@wang-200 certs]# ls client*</span><br><span class="line">client.csr  client-csr.json  client-key.pem  client.pem</span><br></pre></td></tr></table></figure><h4 id="签发apiserver证书"><a href="#签发apiserver证书" class="headerlink" title="签发apiserver证书"></a>签发apiserver证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;certs&#x2F;apiserver-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;apiserver&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">        &quot;127.0.0.1&quot;,</span><br><span class="line">        &quot;10.2.0.1&quot;,</span><br><span class="line">        &quot;kubernetes.default&quot;,</span><br><span class="line">        &quot;kubernetes.default.svc&quot;,</span><br><span class="line">        &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">        &quot;kubernetes.default.svc.cluster.local&quot;,</span><br><span class="line">        &quot;api.k8s.od.com&quot;,</span><br><span class="line">        &quot;192.168.70.10&quot;,</span><br><span class="line">        &quot;192.168.70.11&quot;,</span><br><span class="line">        &quot;192.168.70.12&quot;,</span><br><span class="line">        &quot;192.168.70.21&quot;,</span><br><span class="line">        &quot;192.168.70.22&quot;,</span><br><span class="line">        &quot;192.168.70.23&quot;,</span><br><span class="line">        &quot;192.168.70.24&quot;,</span><br><span class="line">        &quot;192.168.70.25&quot;,</span><br><span class="line">        &quot;192.168.70.26&quot;,</span><br><span class="line">        &quot;192.168.70.27&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;od&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>2. 生成kube-apiserver证书和私钥</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;server apiserver-csr.json |cfssl-json -bare apiserver</span><br><span class="line">[root@wang-200 certs]# ls apiserver*</span><br><span class="line">apiserver.csr  apiserver-csr.json  apiserver-key.pem  apiserver.pem</span><br></pre></td></tr></table></figure><h3 id="在运维主机下载kubernetes安装包"><a href="#在运维主机下载kubernetes安装包" class="headerlink" title="在运维主机下载kubernetes安装包"></a>在运维主机下载kubernetes安装包</h3><blockquote><p>下载地址：<a href="https://github.com/kubernetes/kubernetes/releases" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/releases</a></p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget -O &#x2F;data&#x2F;soft&#x2F;k8s&#x2F;kubernetes-server-linux-amd64-v1.15.2.tar.gz https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;archive&#x2F;v1.15.2.tar.gz # 吃顿午餐</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# tar xf &#x2F;data&#x2F;soft&#x2F;k8s&#x2F;kubernetes-server-linux-amd64-v1.15.2.tar.gz -C &#x2F;opt&#x2F;</span><br><span class="line">[root@wang-200 ~]# mv &#x2F;opt&#x2F;kubernetes &#x2F;opt&#x2F;kubernetes-v1.15.2</span><br><span class="line">[root@wang-200 ~]# ln -s &#x2F;opt&#x2F;kubernetes-v1.15.2 &#x2F;opt&#x2F;kubernetes</span><br><span class="line">[root@wang-200 ~]# ln -s &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubectl &#x2F;usr&#x2F;bin&#x2F;kubectl</span><br><span class="line">[root@wang-200 ~]# cd &#x2F;opt&#x2F;kubernetes</span><br><span class="line">[root@wang-200 kubernetes-v1.15.2]# rm kubernetes-src.tar.gz </span><br><span class="line">[root@wang-200 kubernetes]# rm -f server&#x2F;bin&#x2F;*.tar</span><br><span class="line">[root@wang-200 kubernetes]# rm -f server&#x2F;bin&#x2F;*_tag</span><br><span class="line">[root@wang-200 kubernetes]# tree</span><br><span class="line">.</span><br><span class="line">├── addons</span><br><span class="line">├── LICENSES</span><br><span class="line">└── server</span><br><span class="line">    └── bin</span><br><span class="line">        ├── apiextensions-apiserver</span><br><span class="line">        ├── cloud-controller-manager</span><br><span class="line">        ├── hyperkube</span><br><span class="line">        ├── kubeadm</span><br><span class="line">        ├── kube-apiserver</span><br><span class="line">        ├── kube-controller-manager</span><br><span class="line">        ├── kubectl</span><br><span class="line">        ├── kubelet</span><br><span class="line">        ├── kube-proxy</span><br><span class="line">        ├── kube-scheduler</span><br><span class="line">        └── mounter</span><br><span class="line"></span><br><span class="line">3 directories, 12 files</span><br></pre></td></tr></table></figure><p><strong>拷贝证书</strong></p><p><code>[root@wang-200 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建证书目录</span><br><span class="line">mkdir -p &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line">cd &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;certs&#x2F;</span><br><span class="line"></span><br><span class="line"># 拷贝证书</span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;apiserver.pem .   </span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;apiserver-key.pem .   </span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;client.pem .              </span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;client-key.pem .    </span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;ca.pem .            </span><br><span class="line">cp &#x2F;opt&#x2F;certs&#x2F;ca-key.pem .</span><br></pre></td></tr></table></figure><p><strong>查看拷贝的证书</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# ls</span><br><span class="line">apiserver-key.pem  apiserver.pem  ca-key.pem  ca.pem  client-key.pem  client.pem</span><br></pre></td></tr></table></figure><h3 id="拷贝安装包"><a href="#拷贝安装包" class="headerlink" title="拷贝安装包"></a>拷贝安装包</h3><p><code>[root@wang-21 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r wang-200:&#x2F;opt&#x2F;kubernetes-v1.15.2 &#x2F;opt&#x2F;kubernetes-v1.15.2</span><br><span class="line">ln -s &#x2F;opt&#x2F;kubernetes-v1.15.2&#x2F; &#x2F;opt&#x2F;kubernetes</span><br><span class="line">ln -s &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubectl &#x2F;usr&#x2F;bin&#x2F;kubectl</span><br></pre></td></tr></table></figure><h3 id="创建配置"><a href="#创建配置" class="headerlink" title="创建配置"></a>创建配置</h3><p>k8s资源配置清单，专门给k8s做日志审计</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建资源配置清单目录</span><br><span class="line">mkdir &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;conf&#x2F;audit.yaml</span><br><span class="line">apiVersion: audit.k8s.io&#x2F;v1beta1 # This is required.</span><br><span class="line">kind: Policy</span><br><span class="line"># Don&#39;t generate audit events for all requests in RequestReceived stage.</span><br><span class="line">omitStages:</span><br><span class="line">  - &quot;RequestReceived&quot;</span><br><span class="line">rules:</span><br><span class="line">  # Log pod changes at RequestResponse level</span><br><span class="line">  - level: RequestResponse</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      # Resource &quot;pods&quot; doesn&#39;t match requests to any subresource of pods,</span><br><span class="line">      # which is consistent with the RBAC policy.</span><br><span class="line">      resources: [&quot;pods&quot;]</span><br><span class="line">  # Log &quot;pods&#x2F;log&quot;, &quot;pods&#x2F;status&quot; at Metadata level</span><br><span class="line">  - level: Metadata</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      resources: [&quot;pods&#x2F;log&quot;, &quot;pods&#x2F;status&quot;]</span><br><span class="line">  # Don&#39;t log requests to a configmap called &quot;controller-leader&quot;</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      resources: [&quot;configmaps&quot;]</span><br><span class="line">      resourceNames: [&quot;controller-leader&quot;]</span><br><span class="line">  # Don&#39;t log watch requests by the &quot;system:kube-proxy&quot; on endpoints or services</span><br><span class="line">  - level: None</span><br><span class="line">    users: [&quot;system:kube-proxy&quot;]</span><br><span class="line">    verbs: [&quot;watch&quot;]</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;endpoints&quot;, &quot;services&quot;]</span><br><span class="line">  # Don&#39;t log authenticated requests to certain non-resource URL paths.</span><br><span class="line">  - level: None</span><br><span class="line">    userGroups: [&quot;system:authenticated&quot;]</span><br><span class="line">    nonResourceURLs:</span><br><span class="line">    - &quot;&#x2F;api*&quot; # Wildcard matching.</span><br><span class="line">    - &quot;&#x2F;version&quot;</span><br><span class="line">  # Log the request body of configmap changes in kube-system.</span><br><span class="line">  - level: Request</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;configmaps&quot;]</span><br><span class="line">    # This rule only applies to resources in the &quot;kube-system&quot; namespace.</span><br><span class="line">    # The empty string &quot;&quot; can be used to select non-namespaced resources.</span><br><span class="line">    namespaces: [&quot;kube-system&quot;]</span><br><span class="line">  # Log configmap and secret changes in all other namespaces at the Metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;secrets&quot;, &quot;configmaps&quot;]</span><br><span class="line">  # Log all other resources in core and extensions at the Request level.</span><br><span class="line">  - level: Request</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">    - group: &quot;extensions&quot; # Version of group should NOT be included.</span><br><span class="line">  # A catch-all rule to log all other requests at the Metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    # Long-running requests like watches that fall under this rule will not</span><br><span class="line">    # generate an audit event in RequestReceived.</span><br><span class="line">    omitStages:</span><br><span class="line">      - &quot;RequestReceived&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="创建启动脚本"><a href="#创建启动脚本" class="headerlink" title="创建启动脚本"></a>创建启动脚本</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-apiserver.sh</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">.&#x2F;kube-apiserver \\</span><br><span class="line">  --apiserver-count 3 \\</span><br><span class="line">  --audit-log-path &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-apiserver&#x2F;audit-log \\</span><br><span class="line">  --audit-policy-file .&#x2F;conf&#x2F;audit.yaml \\</span><br><span class="line">  --authorization-mode RBAC \\</span><br><span class="line">  --client-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">  --requestheader-client-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">  --runtime-config&#x3D;settings.k8s.io&#x2F;v1alpha1&#x3D;true \\</span><br><span class="line">  --enable-admission-plugins NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset \\</span><br><span class="line">  --etcd-cafile .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">  --etcd-certfile .&#x2F;certs&#x2F;client.pem \\</span><br><span class="line">  --etcd-keyfile .&#x2F;certs&#x2F;client-key.pem \\</span><br><span class="line">  --etcd-servers https:&#x2F;&#x2F;192.168.70.21:2379,https:&#x2F;&#x2F;192.168.70.22:2379,https:&#x2F;&#x2F;192.168.70.23:2379 \\</span><br><span class="line">  --service-account-key-file .&#x2F;certs&#x2F;ca-key.pem \\</span><br><span class="line">  --service-cluster-ip-range 10.2.0.0&#x2F;16 \\</span><br><span class="line">  --service-node-port-range 3000-29999 \\</span><br><span class="line">  --target-ram-mb&#x3D;1024 \\</span><br><span class="line">  --kubelet-client-certificate .&#x2F;certs&#x2F;client.pem \\</span><br><span class="line">  --kubelet-client-key .&#x2F;certs&#x2F;client-key.pem \\</span><br><span class="line">  --log-dir  &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-apiserver \\</span><br><span class="line">  --tls-cert-file .&#x2F;certs&#x2F;apiserver.pem \\</span><br><span class="line">  --tls-private-key-file .&#x2F;certs&#x2F;apiserver-key.pem \\</span><br><span class="line">  --v 2</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 调整权限与目录</span><br><span class="line">chmod +x &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-apiserver.sh</span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-apiserver</span><br></pre></td></tr></table></figure><blockquote><p>####################### 参数说明 #######################<br>  –apiserver-count 2             // apiserver数量<br>  –audit-log-path               // 日志存放位置<br>  –audit-policy-file            // 日志审计规则文件<br>  –authorization-mode     RBAC    // RBAC –基于角色访问的控制<br>  #详细参数说明:  ./kube-apiserver  help</p></blockquote><h3 id="创建supervisor配置"><a href="#创建supervisor配置" class="headerlink" title="创建supervisor配置"></a>创建supervisor配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-apiserver.ini</span><br><span class="line">[program:kube-apiserver-70-21]</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-apiserver.sh            ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                                      ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin                            ; directory to cwd to before exec (def no cwd)</span><br><span class="line">autostart&#x3D;true                                                  ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                                                ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;30                                                    ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                                                  ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                                                   ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                                                 ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                                                 ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;root                                                       ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;true                                            ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-apiserver&#x2F;apiserver.stdout.log        ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                                    ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                                        ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                                     ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                                     ; emit events on stdout writes (default false)</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改成适应自己主机的IP地址</span><br><span class="line">sed -i &quot;1s&amp;kube-apiserver-70-21&amp;kube-apiserver-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-apiserver.ini</span><br></pre></td></tr></table></figure><h3 id="启动服务并检查"><a href="#启动服务并检查" class="headerlink" title="启动服务并检查"></a>启动服务并检查</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 certs]# supervisorctl update</span><br><span class="line">kube-apiserver-70-21: added process group</span><br><span class="line">[root@wang-21 certs]# supervisorctl status</span><br><span class="line">etcd-server-70-21                RUNNING   pid 57939, uptime 1:46:48</span><br><span class="line">kube-apiserver-70-21             STARTING  </span><br><span class="line">[root@wang-21 certs]# netstat -lntup|grep kube-api</span><br><span class="line">tcp        0      0 127.0.0.1:8080          0.0.0.0:*               LISTEN      58186&#x2F;.&#x2F;kube-apiser </span><br><span class="line">tcp6       0      0 :::6443                 :::*                    LISTEN      58186&#x2F;.&#x2F;kube-apiser</span><br></pre></td></tr></table></figure><h3 id="安装部署启动检查另外两台节点"><a href="#安装部署启动检查另外两台节点" class="headerlink" title="安装部署启动检查另外两台节点"></a>安装部署启动检查另外两台节点</h3><h3 id="配置4层反向代理"><a href="#配置4层反向代理" class="headerlink" title="配置4层反向代理"></a>配置4层反向代理</h3><p>操作主机：<code>wang-11, wang-12</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# yum install -y nginx</span><br></pre></td></tr></table></figure><p><strong>配置nginx</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br><span class="line"># 追加到文件最后</span><br><span class="line">stream &#123;</span><br><span class="line">    upstream kube-apiserver &#123;</span><br><span class="line">        server 192.168.70.21:6443     max_fails&#x3D;3 fail_timeout&#x3D;30s;</span><br><span class="line">        server 192.168.70.22:6443     max_fails&#x3D;3 fail_timeout&#x3D;30s;</span><br><span class="line">        server 192.168.70.23:6443     max_fails&#x3D;3 fail_timeout&#x3D;30s;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 8443;</span><br><span class="line">        proxy_connect_timeout 2s;</span><br><span class="line">        proxy_timeout 900s;</span><br><span class="line">        proxy_pass kube-apiserver;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>启动nginx</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br><span class="line">systemctl start nginx</span><br><span class="line">systemctl enable nginx</span><br></pre></td></tr></table></figure><h2 id="部署keepalive服务"><a href="#部署keepalive服务" class="headerlink" title="部署keepalive服务"></a>部署keepalive服务</h2><p>部署主机：<code>wang-11, wang-12</code></p><h3 id="安装keepalive"><a href="#安装keepalive" class="headerlink" title="安装keepalive"></a>安装keepalive</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# yum -y install keepalived</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><h4 id="准备三个文件，探活使用"><a href="#准备三个文件，探活使用" class="headerlink" title="准备三个文件，探活使用"></a>准备三个文件，探活使用</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">token&#x3D;&quot;5c8ffe75f67f5bb326c1f56ac298cea222f25ce7b8dcbf695a3432a564ff0b8f&quot; # 钉钉token</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;keepalived&#x2F;keepalived_check.sh </span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">ip&#x3D;&#96;ifconfig  | grep &#39;inet 192&#39; | awk &#39;&#123;print $2&#125;&#39;&#96;</span><br><span class="line">echo $ip &#96;date&#96; &gt;&gt; &#x2F;data&#x2F;logs&#x2F;keepalive&#x2F;keepalived_check.log</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;keepalived&#x2F;keepalived_master.sh  </span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">ip&#x3D;&#96;ifconfig  | grep &#39;inet 192&#39; | awk &#39;&#123;print $2&#125;&#39;&#96;</span><br><span class="line">curl &quot;https:&#x2F;&#x2F;oapi.dingtalk.com&#x2F;robot&#x2F;send?access_token&#x3D;$token&quot; \</span><br><span class="line">   -H &#39;Content-Type: application&#x2F;json&#39; -d &#39;&#123;&quot;msgtype&quot;: &quot;text&quot;,  &quot;text&quot;: &#123; &quot;content&quot;: &quot;节点&#39;\$ip&#39;的虚拟IP地址192.168.70.10成为master&quot;&#125;&#125;&#39;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;keepalived&#x2F;keepalived_backup.sh </span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">ip&#x3D;&#96;ifconfig  | grep &#39;inet 192&#39; | awk &#39;&#123;print $2&#125;&#39;&#96;</span><br><span class="line">curl &quot;https:&#x2F;&#x2F;oapi.dingtalk.com&#x2F;robot&#x2F;send?access_token&#x3D;$token&quot; \</span><br><span class="line">   -H &#39;Content-Type: application&#x2F;json&#39; -d &#39;&#123;&quot;msgtype&quot;: &quot;text&quot;,  &quot;text&quot;: &#123; &quot;content&quot;: &quot;节点&#39;\$ip&#39;的虚拟IP地址192.168.70.10成为backup&quot;&#125;&#125;&#39;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod +x &#x2F;etc&#x2F;keepalived&#x2F;keepalived_check.sh</span><br><span class="line">chmod +x &#x2F;etc&#x2F;keepalived&#x2F;keepalived_master.sh</span><br><span class="line">chmod +x &#x2F;etc&#x2F;keepalived&#x2F;keepalived_backup.sh</span><br><span class="line">mkdir &#x2F;data&#x2F;logs&#x2F;keepalive&#x2F;</span><br></pre></td></tr></table></figure><h4 id="修改keepalived配置文件"><a href="#修改keepalived配置文件" class="headerlink" title="修改keepalived配置文件"></a>修改keepalived配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     wangzt@od.com</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from xueting@od.com</span><br><span class="line">   smtp_server 192.168.70.1  #指定smtp服务器地址</span><br><span class="line">   smtp_connect_timeout 30   #指定smtp连接超时时间</span><br><span class="line">   router_id LVS_DEVEL  #运行keepalived机器的一个标识</span><br><span class="line">   vrrp_skip_check_adv_addr  # 默认是不跳过检查。检查收到的VRRP通告中的所有地址可能会比较耗时，设置此命令的意思是，如果通告与接收的上一个通告来自相同的master路由器，则不执行检查(跳过检查)。</span><br><span class="line">   # vrrp_strict 严格遵守VRRP协议。下列情况将会阻止启动Keepalived：1. 没有VIP地址。2. 单播邻居。3. 在VRRP版本2中有IPv6地址。</span><br><span class="line">   vrrp_garp_interval 0  # 在一个接口发送的两个免费ARP之间的延迟。可以精确到毫秒级。默认是0.</span><br><span class="line">   vrrp_gna_interval 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk &#123;</span><br><span class="line">     script &quot;&#x2F;etc&#x2F;keepalived&#x2F;keepalived_check.sh&quot; #执行脚本，返回为ture时执行</span><br><span class="line">     interval 10     # 每隔10秒执行一次上面的检测</span><br><span class="line">     weight 5       # 返回值正确，权重加5</span><br><span class="line">     rise 1  #上升1 ？</span><br><span class="line">     fall 2  # 重试两次</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_10 &#123;</span><br><span class="line">    state BACKUP  # 设置节点为主从</span><br><span class="line">    interface ens160  # 网卡名称，必须已存在</span><br><span class="line">    virtual_router_id 10  # 网卡id，keepalive通过此标示确认为一组</span><br><span class="line">    priority 100  # 优先级</span><br><span class="line">    advert_int 5  # 检测间隔</span><br><span class="line">    authentication &#123;  # 认证方式</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 111110</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;  # 虚拟主机IP</span><br><span class="line">        192.168.70.10</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;  # 探活检测</span><br><span class="line">      chk</span><br><span class="line">    &#125;</span><br><span class="line">    notify_master &#x2F;etc&#x2F;keepalived&#x2F;keepalived_master.sh #成为主节点时执行</span><br><span class="line">    notify_backup &#x2F;etc&#x2F;keepalived&#x2F;keepalived_backup.sh #成为备用节点时执行    </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>注意网卡名称和修改优先级</p></blockquote><h3 id="启动keepalive"><a href="#启动keepalive" class="headerlink" title="启动keepalive"></a>启动keepalive</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# systemctl start keepalived</span><br><span class="line">[root@wang-11 ~]# systemctl enable keepalived</span><br></pre></td></tr></table></figure><h3 id="验证VIP已经绑定端口"><a href="#验证VIP已经绑定端口" class="headerlink" title="验证VIP已经绑定端口"></a>验证VIP已经绑定端口</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-11 ~]# ip a | grep 70.10</span><br><span class="line">    inet 192.168.70.10&#x2F;32 scope global ens160</span><br></pre></td></tr></table></figure><p><strong>这是当节点切换时，我们就能收到告警</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfbupisdvcj30hu05amxy.jpg" alt="钉钉VIP告警"></p><h2 id="部署-kube-controller-manager服务"><a href="#部署-kube-controller-manager服务" class="headerlink" title="部署 kube-controller-manager服务"></a>部署 kube-controller-manager服务</h2><h3 id="集群规划-1"><a href="#集群规划-1" class="headerlink" title="集群规划"></a>集群规划</h3><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com</td><td>192.168.70.21</td><td>controller-manager</td></tr><tr><td>wang-22.host.com</td><td>192.168.70.22</td><td>controller-manager</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>controller-manager</td></tr></tbody></table><p>注意：这里部署文档以wang-21主机为例，另外两台主机安装部署方法类似。</p><h3 id="创建服务启动脚本"><a href="#创建服务启动脚本" class="headerlink" title="创建服务启动脚本"></a>创建服务启动脚本</h3><p><code>[root@wang-21 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-controller-manager.sh </span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">.&#x2F;kube-controller-manager \\</span><br><span class="line">  --cluster-cidr 172.16.0.0&#x2F;16 \\</span><br><span class="line">  --leader-elect true \\</span><br><span class="line">  --log-dir &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-controller-manager \\</span><br><span class="line">  --master http:&#x2F;&#x2F;127.0.0.1:8080 \\</span><br><span class="line">  --service-account-private-key-file .&#x2F;certs&#x2F;ca-key.pem \\</span><br><span class="line">  --service-cluster-ip-range 10.2.0.0&#x2F;16 \\</span><br><span class="line">  --root-ca-file .&#x2F;certs&#x2F;ca.pem \\</span><br><span class="line">  --v 2</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>授权、创建目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 ~]# chmod +x &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-controller-manager.sh </span><br><span class="line">[root@wang-21 ~]# mkdir -p &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-controller-manager</span><br></pre></td></tr></table></figure><h3 id="创建supervisor配置-1"><a href="#创建supervisor配置-1" class="headerlink" title="创建supervisor配置"></a>创建supervisor配置</h3><p><code>[root@wang-21 ~]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-controller-manager.ini</span><br><span class="line">[program:kube-controller-manager-70-21]</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-controller-manager.sh  ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                                ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin                      ; directory to cwd to before exec (def no cwd)</span><br><span class="line">autostart&#x3D;true                                            ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                                          ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;22                                              ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                                            ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                                             ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                                           ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                                           ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;root                                                 ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;false                                     ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-controller-manager&#x2F;controll.stdout.log  ; stdout log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                            ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                                ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                             ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                             ; emit events on stdout writes (default false)</span><br><span class="line">stderr_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-controller-manager&#x2F;controll.stderr.log  ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stderr_logfile_maxbytes&#x3D;64MB                            ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stderr_logfile_backups&#x3D;4                                ; # of stderr logfile backups (default 10)</span><br><span class="line">stderr_capture_maxbytes&#x3D;1MB                             ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stderr_events_enabled&#x3D;false                             ; emit events on stderr writes (default false)</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sed -i &quot;1s&amp;kube-controller-manager-70-21&amp;kube-controller-manager-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-controller-manager.ini</span><br></pre></td></tr></table></figure><h3 id="启动服务并检查-1"><a href="#启动服务并检查-1" class="headerlink" title="启动服务并检查"></a>启动服务并检查</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 ~]# supervisorctl update                                                                                                           </span><br><span class="line">kube-controller-manager-70-21: added process group</span><br><span class="line">[root@wang-21 ~]# supervisorctl status</span><br><span class="line">etcd-server-70-21                RUNNING   pid 57939, uptime 2:51:56</span><br><span class="line">kube-apiserver-70-21             RUNNING   pid 58185, uptime 1:05:13</span><br><span class="line">kube-controller-manager-70-21    STARTING</span><br></pre></td></tr></table></figure><h3 id="安装部署集群其他主机-wang-22-wang-23"><a href="#安装部署集群其他主机-wang-22-wang-23" class="headerlink" title="安装部署集群其他主机(wang-22, wang-23)"></a>安装部署集群其他主机(wang-22, wang-23)</h3><h2 id="部署-kube-scheduler服务"><a href="#部署-kube-scheduler服务" class="headerlink" title="部署 kube-scheduler服务"></a>部署 kube-scheduler服务</h2><h3 id="集群规划-2"><a href="#集群规划-2" class="headerlink" title="集群规划"></a>集群规划</h3><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>wang-21.host.com</td><td>192.168.70.21</td><td>kube-scheduler</td></tr><tr><td>wang-22.host.com</td><td>192.168.70.22</td><td>kube-scheduler</td></tr><tr><td>wang-23.host.com</td><td>192.168.70.23</td><td>kube-scheduler</td></tr></tbody></table><p>注意：这里部署文档以wang-21主机为例，另外两台主机安装部署方法类似。</p><p><code>[root@wang-21 bin]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-scheduler.sh</span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">.&#x2F;kube-scheduler \\</span><br><span class="line">  --leader-elect  \\</span><br><span class="line">  --log-dir &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-scheduler \\</span><br><span class="line">  --master http:&#x2F;&#x2F;127.0.0.1:8080 \\</span><br><span class="line">  --v 2</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>授权、创建目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +x  &#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-scheduler.sh</span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-scheduler</span><br></pre></td></tr></table></figure><h3 id="创建supervisor配置-2"><a href="#创建supervisor配置-2" class="headerlink" title="创建supervisor配置"></a>创建supervisor配置</h3><p><code>[root@wang-21 bin]#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-scheduler.ini</span><br><span class="line">[program:kube-scheduler-70-21]</span><br><span class="line">command&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-scheduler.sh                     ; the program (relative uses PATH, can take args)</span><br><span class="line">numprocs&#x3D;1                                                               ; number of processes copies to start (def 1)</span><br><span class="line">directory&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;server&#x2F;bin                                     ; directory to cwd to before exec (def no cwd)</span><br><span class="line">autostart&#x3D;true                                                           ; start at supervisord start (default: true)</span><br><span class="line">autorestart&#x3D;true                                                         ; retstart at unexpected quit (default: true)</span><br><span class="line">startsecs&#x3D;22                                                             ; number of secs prog must stay running (def. 1)</span><br><span class="line">startretries&#x3D;3                                                           ; max # of serial start failures (default 3)</span><br><span class="line">exitcodes&#x3D;0,2                                                            ; &#39;expected&#39; exit codes for process (default 0,2)</span><br><span class="line">stopsignal&#x3D;QUIT                                                          ; signal used to kill process (default TERM)</span><br><span class="line">stopwaitsecs&#x3D;10                                                          ; max num secs to wait b4 SIGKILL (default 10)</span><br><span class="line">user&#x3D;root                                                                ; setuid to this UNIX account to run the program</span><br><span class="line">redirect_stderr&#x3D;false                                                    ; redirect proc stderr to stdout (default false)</span><br><span class="line">stdout_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-scheduler&#x2F;scheduler.stdout.log ; stdout log path, NONE for none; default AUTO</span><br><span class="line">stdout_logfile_maxbytes&#x3D;64MB                                             ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stdout_logfile_backups&#x3D;4                                                 ; # of stdout logfile backups (default 10)</span><br><span class="line">stdout_capture_maxbytes&#x3D;1MB                                              ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stdout_events_enabled&#x3D;false                                              ; emit events on stdout writes (default false)</span><br><span class="line">stderr_logfile&#x3D;&#x2F;data&#x2F;logs&#x2F;kubernetes&#x2F;kube-scheduler&#x2F;scheduler.stderr.log ; stderr log path, NONE for none; default AUTO</span><br><span class="line">stderr_logfile_maxbytes&#x3D;64MB                                             ; max # logfile bytes b4 rotation (default 50MB)</span><br><span class="line">stderr_logfile_backups&#x3D;4                                                 ; # of stderr logfile backups (default 10)</span><br><span class="line">stderr_capture_maxbytes&#x3D;1MB                                              ; number of bytes in &#39;capturemode&#39; (default 0)</span><br><span class="line">stderr_events_enabled&#x3D;false                                              ; emit events on stderr writes (default false)</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改设置自己的主机</span><br><span class="line">sed -i &quot;1s&amp;kube-scheduler-70-21&amp;kube-scheduler-70-$&#123;HOSTNUM&#125;&amp;&quot; &#x2F;etc&#x2F;supervisord.d&#x2F;kube-scheduler.ini</span><br></pre></td></tr></table></figure><h3 id="启动服务并检查-2"><a href="#启动服务并检查-2" class="headerlink" title="启动服务并检查"></a>启动服务并检查</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 bin]# supervisorctl update</span><br><span class="line">kube-scheduler-70-21: added process group</span><br><span class="line">[root@wang-21 bin]# supervisorctl status</span><br><span class="line">etcd-server-70-21               RUNNING   pid 52511, uptime 4:08:05</span><br><span class="line">kube-apiserver-70-21            RUNNING   pid 52730, uptime 1:45:06</span><br><span class="line">kube-controller-manager-70-21   RUNNING   pid 52875, uptime 0:08:41</span><br><span class="line">kube-scheduler-70-21            RUNNING   pid 52892, uptime 0:00:31</span><br></pre></td></tr></table></figure><h3 id="安装部署集群其他主机-wang-22-wang-23-1"><a href="#安装部署集群其他主机-wang-22-wang-23-1" class="headerlink" title="安装部署集群其他主机(wang-22,wang-23)"></a>安装部署集群其他主机(wang-22,wang-23)</h3><h3 id="查看主控节点健康状态"><a href="#查看主控节点健康状态" class="headerlink" title="查看主控节点健康状态"></a>查看主控节点健康状态</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 bin]# kubectl get cs</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br></pre></td></tr></table></figure><h2 id="准备k8s用户配置"><a href="#准备k8s用户配置" class="headerlink" title="准备k8s用户配置"></a>准备k8s用户配置</h2><h3 id="准备json文件"><a href="#准备json文件" class="headerlink" title="准备json文件"></a>准备json文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;certs&#x2F;admin-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;cluster-admin&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;wang&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="签发证书与私钥"><a href="#签发证书与私钥" class="headerlink" title="签发证书与私钥"></a>签发证书与私钥</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;client admin-csr.json |cfssl-json -bare admin</span><br><span class="line">2020&#x2F;06&#x2F;02 16:23:28 [INFO] generate received request</span><br><span class="line">2020&#x2F;06&#x2F;02 16:23:28 [INFO] received CSR</span><br><span class="line">2020&#x2F;06&#x2F;02 16:23:28 [INFO] generating key: rsa-2048</span><br><span class="line">2020&#x2F;06&#x2F;02 16:23:29 [INFO] encoded CSR</span><br><span class="line">2020&#x2F;06&#x2F;02 16:23:29 [INFO] signed certificate with serial number 448820123648992987660922165809109462670105492676</span><br><span class="line">2020&#x2F;06&#x2F;02 16:23:29 [WARNING] This certificate lacks a &quot;hosts&quot; field. This makes it unsuitable for</span><br><span class="line">websites. For more information see the Baseline Requirements for the Issuance and Management</span><br><span class="line">of Publicly-Trusted Certificates, v.1.1.6, from the CA&#x2F;Browser Forum (https:&#x2F;&#x2F;cabforum.org);</span><br><span class="line">specifically, section 10.2.3 (&quot;Information Requirements&quot;).</span><br><span class="line">[root@wang-200 certs]# ls admin*</span><br><span class="line">admin.csr  admin-csr.json  admin-key.pem  admin.pem</span><br></pre></td></tr></table></figure><h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><p>set-cluster</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl config set-cluster myk8s --certificate-authority&#x3D;&#x2F;opt&#x2F;certs&#x2F;ca.pem --embed-certs&#x3D;true --server&#x3D;https:&#x2F;&#x2F;api.k8s.od.com:8443 --kubeconfig&#x3D;myk8s-config</span><br><span class="line">Cluster &quot;myk8s&quot; set.</span><br></pre></td></tr></table></figure><p>set-credentials</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl config set-credentials cluster-admin --client-certificate&#x3D;&#x2F;opt&#x2F;certs&#x2F;admin.pem --client-key&#x3D;&#x2F;opt&#x2F;certs&#x2F;admin-key.pem --embed-certs&#x3D;true --kubeconfig&#x3D;myk8s-config</span><br><span class="line">User &quot;cluster-admin&quot; set.</span><br></pre></td></tr></table></figure><p>set-context</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl config set-context myk8s-context --cluster&#x3D;myk8s --user&#x3D;cluster-admin --kubeconfig&#x3D;myk8s-config</span><br><span class="line">Context &quot;myk8s-context&quot; created.</span><br></pre></td></tr></table></figure><p>use-context</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl config use-context myk8s-context --kubeconfig&#x3D;myk8s-config</span><br><span class="line">Switched to context &quot;myk8s-context&quot;.</span><br></pre></td></tr></table></figure><p>拷贝文件到家目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cp myk8s-config ~&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure><h3 id="集群角色绑定用户"><a href="#集群角色绑定用户" class="headerlink" title="集群角色绑定用户"></a>集群角色绑定用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 ~]# kubectl create clusterrolebinding myk8s-admin --clusterrole&#x3D;cluster-admin --user&#x3D;cluster-admin</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io&#x2F;myk8s-admin created</span><br></pre></td></tr></table></figure><h3 id="验证cluster-admin用户"><a href="#验证cluster-admin用户" class="headerlink" title="验证cluster-admin用户"></a>验证cluster-admin用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# kubectl get cs                </span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二、k8s-前期环境准备</title>
      <link href="/2020/05/30/%E4%BA%8C%E3%80%81k8s-%E5%89%8D%E6%9C%9F%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
      <url>/2020/05/30/%E4%BA%8C%E3%80%81k8s-%E5%89%8D%E6%9C%9F%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<h2 id="部署DNS服务"><a href="#部署DNS服务" class="headerlink" title="部署DNS服务"></a>部署DNS服务</h2><p><code>部署节点wang-12</code></p><h3 id="安装Bind9服务"><a href="#安装Bind9服务" class="headerlink" title="安装Bind9服务"></a>安装Bind9服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# yum install -y bind</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# cp &#x2F;etc&#x2F;named.conf &#x2F;etc&#x2F;named.conf.bak</span><br><span class="line">[root@wang-12 ~]# vim &#x2F;etc&#x2F;named.conf</span><br><span class="line">12 options &#123;</span><br><span class="line">13         listen-on port 53 &#123; 192.168.70.13; &#125;;    # 监听地址</span><br><span class="line">14         &#x2F;&#x2F;listen-on-v6 port 53 &#123; ::1; &#125;;    # 不监听IV6</span><br><span class="line">21         allow-query     &#123; any; &#125;;            # 允许谁来访问，所有</span><br><span class="line">22         forwarders      &#123; 114.114.114.114; &#125;;    # 上级DNS，添加</span><br><span class="line">33         recursion yes;    # 递归查询</span><br><span class="line">35         dnssec-enable no;    # DNS安全扩展</span><br><span class="line">36         dnssec-validation no;</span><br></pre></td></tr></table></figure><p><strong>检查配置文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# named-checkconf</span><br></pre></td></tr></table></figure><p>没有任何输出，说明配置文件无误</p><h3 id="修改区域配置文件"><a href="#修改区域配置文件" class="headerlink" title="修改区域配置文件"></a>修改区域配置文件</h3><p>添加主机域名<code>host.com</code>，业务域<code>od.com</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# cp &#x2F;etc&#x2F;named.rfc1912.zones &#x2F;etc&#x2F;named.rfc1912.zones.bak</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;named.rfc1912.zones</span><br><span class="line"># 文件结尾添加以下内容</span><br><span class="line">zone &quot;host.com&quot; IN &#123;</span><br><span class="line">        type master;</span><br><span class="line">        file &quot;host.com.zone&quot;;</span><br><span class="line">        allow-update &#123; 192.168.70.12; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">zone &quot;od.com&quot; IN &#123;</span><br><span class="line">        type master;</span><br><span class="line">        file &quot;od.com.zone&quot;;</span><br><span class="line">        allow-update &#123; 192.168.70.12; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="添加区域数据文件"><a href="#添加区域数据文件" class="headerlink" title="添加区域数据文件"></a>添加区域数据文件</h3><p><strong>主机域配置文件</strong></p><p><code>vim /var/named/host.com.zone</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ORIGIN host.com.</span><br><span class="line">$TTL 600  ; 10minutes</span><br><span class="line">@    IN   SOA   dns.host.com.  dnsadmin.host.com. (</span><br><span class="line">                2019122301    ; serial</span><br><span class="line">                10800         ; refresh (3 hours)</span><br><span class="line">                900           ; retry (15 minutes)</span><br><span class="line">                604800        ; expire (1 week)</span><br><span class="line">                86400         ; minimum (1 day)</span><br><span class="line">                )</span><br><span class="line">                NS   dns.host.com.</span><br><span class="line">$TTL 60 ; 1 minute</span><br><span class="line">dns             A       192.168.70.12</span><br><span class="line">wang-200        A       192.168.70.200</span><br><span class="line">wang-11         A       192.168.70.11</span><br><span class="line">wang-12         A       192.168.70.12</span><br><span class="line">wang-21         A       192.168.70.21</span><br><span class="line">wang-22         A       192.168.70.22</span><br><span class="line">wang-23         A       192.168.70.23</span><br><span class="line">wang-24         A       192.168.70.24</span><br></pre></td></tr></table></figure><p><strong>业务域配置文件</strong></p><p><code>vim /var/named/od.com.zone</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ORIGIN od.com.</span><br><span class="line">$TTL 600  ; 10minutes</span><br><span class="line">@    IN   SOA   od.com.com.  dnsadmin.od.com. (</span><br><span class="line">                2019122301    ; serial</span><br><span class="line">                10800         ; refresh (3 hours)</span><br><span class="line">                900           ; retry (15 minutes)</span><br><span class="line">                604800        ; expire (1 week)</span><br><span class="line">                86400         ; minimum (1 day)</span><br><span class="line">                )</span><br><span class="line">                NS   dns.od.com.</span><br><span class="line">$TTL 60 ; 1 minute</span><br><span class="line">dns             A       192.168.70.12</span><br><span class="line">api.k8s         A       192.168.70.10</span><br><span class="line">*               A       192.168.70.10</span><br></pre></td></tr></table></figure><h3 id="启动-bind9服务"><a href="#启动-bind9服务" class="headerlink" title="启动 bind9服务"></a>启动 bind9服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# systemctl start named</span><br><span class="line">[root@wang-12 ~]# systemctl enable named</span><br><span class="line">Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;named.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;named.service.</span><br><span class="line">[root@wang-12 ~]# netstat -lntup|grep -w 53</span><br><span class="line">tcp        0      0 192.168.70.12:53        0.0.0.0:*               LISTEN      51102&#x2F;named         </span><br><span class="line">udp        0      0 192.168.70.12:53        0.0.0.0:*                           51102&#x2F;named</span><br></pre></td></tr></table></figure><h3 id="检查DNS可用性"><a href="#检查DNS可用性" class="headerlink" title="检查DNS可用性"></a>检查DNS可用性</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# dig -t A wang-11.host.com @192.168.70.12 +short  </span><br><span class="line">192.168.70.11</span><br><span class="line">[root@wang-12 ~]# dig -t A api.k8s.od.com @192.168.70.12 +short     </span><br><span class="line">192.168.70.10</span><br></pre></td></tr></table></figure><h3 id="配置DNS客户端"><a href="#配置DNS客户端" class="headerlink" title="配置DNS客户端"></a>配置DNS客户端</h3><p><strong>所有主机都需要修改</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# ansible all -m shell -a &quot;sed -i &#39;s&amp;DNS1&#x3D;114.114.114.114&amp;DNS1&#x3D;192.168.70.12&amp;&#39; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens160 &amp;&amp; systemctl restart network &quot;</span><br></pre></td></tr></table></figure><p><strong>检测结果</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# cat &#x2F;etc&#x2F;resolv.conf</span><br><span class="line"># Generated by NetworkManager</span><br><span class="line">search host.com</span><br><span class="line">nameserver 192.168.70.12</span><br></pre></td></tr></table></figure><p><strong>测试可用性</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# ping -c3 wang-11</span><br><span class="line">PING wang-11.host.com (192.168.70.11) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.70.11 (192.168.70.11): icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.318 ms</span><br><span class="line"></span><br><span class="line">[root@wang-12 ~]# ping -c3 www.baidu.com</span><br><span class="line">PING www.a.shifen.com (180.101.49.12) 56(84) bytes of data.</span><br><span class="line">64 bytes from 180.101.49.12 (180.101.49.12): icmp_seq&#x3D;1 ttl&#x3D;51 time&#x3D;20.8 ms</span><br></pre></td></tr></table></figure><h2 id="部署签发证书环境"><a href="#部署签发证书环境" class="headerlink" title="部署签发证书环境"></a>部署签发证书环境</h2><p><code>部署主机：wang-200</code></p><h3 id="安装CFSSL"><a href="#安装CFSSL" class="headerlink" title="安装CFSSL"></a>安装CFSSL</h3><p>证书签发工具CFSSL: R1.2</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssl_linux-amd64 -O &#x2F;usr&#x2F;bin&#x2F;cfssl</span><br><span class="line">wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssljson_linux-amd64 -O &#x2F;usr&#x2F;bin&#x2F;cfssl-json</span><br><span class="line">wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssl-certinfo_linux-amd64  -O  &#x2F;usr&#x2F;bin&#x2F;cfssl-certinfo</span><br><span class="line">chmod +x &#x2F;usr&#x2F;bin&#x2F;cfssl &#x2F;usr&#x2F;bin&#x2F;cfssl-json &#x2F;usr&#x2F;bin&#x2F;cfssl-certinfo</span><br></pre></td></tr></table></figure><h3 id="创建生成CA证书签名请求-csr-的json配置文件"><a href="#创建生成CA证书签名请求-csr-的json配置文件" class="headerlink" title="创建生成CA证书签名请求(csr)的json配置文件"></a>创建生成CA证书签名请求(csr)的json配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir &#x2F;opt&#x2F;certs</span><br><span class="line">[root@wang-200 ~]# cd &#x2F;opt&#x2F;certs&#x2F;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; &#x2F;opt&#x2F;certs&#x2F;ca-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes-ca&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;beijing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;wang&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;ca&quot;: &#123;</span><br><span class="line">        &quot;expiry&quot;: &quot;175200h&quot;       </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><div class="note primary">            <p>⚠️：证书的有效时间设置长一点，我的是20年</p>          </div><div class="note info">            <p>CN: Common Name，浏览器使用该字段验证网站是否合法，一般写的是域名。非常重要。浏览器使用该字段验证网站是否合法<br>C: Country， 国家<br>ST: State，州，省<br>L: Locality，地区，城市<br>O: Organization Name，组织名称，公司名称<br>OU: Organization Unit Name，组织单位名称，公司部门</p>          </div><h3 id="生成CA证书和私钥"><a href="#生成CA证书和私钥" class="headerlink" title="生成CA证书和私钥"></a>生成CA证书和私钥</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 certs]# cfssl gencert -initca ca-csr.json |cfssl-json -bare ca</span><br><span class="line">[root@wang-200 certs]# ls</span><br><span class="line">ca.csr  ca-csr.json  ca-key.pem #根证书私钥 ca.pem #根证书</span><br></pre></td></tr></table></figure><h2 id="部署-docker环境"><a href="#部署-docker环境" class="headerlink" title="部署 docker环境"></a>部署 docker环境</h2><p><code>部署主机：wang-200,wang-21, wang-22,wang-23</code></p><p><code>vim /data/shell/install_docker.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 安装docker服务</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">yum install docker-ce-18.06.0.ce -y</span><br><span class="line">sleep 3</span><br><span class="line"></span><br><span class="line"># 配置docker参数，注意不同主机，docker bip不同</span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;graph&quot;: &quot;&#x2F;data&#x2F;docker&quot;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay&quot;,</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;tpd9v3c5.mirror.aliyuncs.com&quot;],</span><br><span class="line">  &quot;insecure-registries&quot;: [&quot;registry.access.redhat.com&quot;,&quot;quay.io&quot;,&quot;harbor.od.com&quot;],</span><br><span class="line">  &quot;bip&quot;: &quot;172.16.200.1&#x2F;24&quot;,</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;],</span><br><span class="line">  &quot;live-restore&quot;: true</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sed -i &quot;s&amp;172.16.200.1&#x2F;24&amp;172.16.$&#123;HOSTNUM&#125;.1&#x2F;24&amp;&quot; &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line"></span><br><span class="line"># 启动docker</span><br><span class="line">systemctl start docker</span><br><span class="line"># 添加docker开机自启</span><br><span class="line">systemctl enable docker</span><br><span class="line"></span><br><span class="line"># 查看docker版本号</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure><p>配置执行权限并执行</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# chmod +x &#x2F;data&#x2F;shell&#x2F;install_docker.sh</span><br><span class="line">[root@wang-200 ~]# &#x2F;data&#x2F;shell&#x2F;install_docker.sh</span><br><span class="line">[root@wang-200 ~]# ansible worker -m copy -a &quot;src&#x3D;&#x2F;data&#x2F;shell&#x2F;install_docker.sh dest&#x3D;&#x2F;data&#x2F;shell&#x2F;install_docker.sh mode&#x3D;755 backup&#x3D;true&quot;</span><br><span class="line">[root@wang-200 ~]# ansible worker -m shell -a &quot;&#x2F;data&#x2F;shell&#x2F;install_docker.sh&quot;</span><br></pre></td></tr></table></figure><h2 id="安装supervisor"><a href="#安装supervisor" class="headerlink" title="安装supervisor"></a>安装supervisor</h2><p>Supervisor是用Python开发的一个client/server服务，是Linux/Unix系统下的一个进程管理工具，不支持Windows系统。它可以很方便的监听、启动、停止、重启一个或多个进程。用Supervisor管理的进程，当一个进程意外被杀死，supervisort监听到进程死后，会自动将它重新拉起，很方便的做到进程自动恢复的功能</p><h3 id="创建安装supervisor执行文件"><a href="#创建安装supervisor执行文件" class="headerlink" title="创建安装supervisor执行文件"></a>创建安装supervisor执行文件</h3><p><code>vim /data/shell/install_supervisor.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y supervisor</span><br><span class="line">systemctl start supervisord.service</span><br><span class="line">systemctl enable supervisord.service</span><br></pre></td></tr></table></figure><h3 id="拷贝文件到服务器并执行"><a href="#拷贝文件到服务器并执行" class="headerlink" title="拷贝文件到服务器并执行"></a>拷贝文件到服务器并执行</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# ansible worker -m copy -a &quot;src&#x3D;&#x2F;data&#x2F;shell&#x2F;install_supervisor.sh dest&#x3D;&#x2F;data&#x2F;shell&#x2F;install_supervisor.sh mode&#x3D;755 backup&#x3D;true&quot;</span><br><span class="line">[root@wang-200 ~]# ansible worker -m shell -a &quot;&#x2F;data&#x2F;shell&#x2F;install_supervisor.sh&quot;</span><br></pre></td></tr></table></figure><h2 id="部署docker镜像私有仓库harbor"><a href="#部署docker镜像私有仓库harbor" class="headerlink" title="部署docker镜像私有仓库harbor"></a>部署docker镜像私有仓库harbor</h2><p>部署主机：<code>wang-200</code></p><h3 id="下载软件并解压"><a href="#下载软件并解压" class="headerlink" title="下载软件并解压"></a>下载软件并解压</h3><blockquote><p>harbor官网github地址：<a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">https://github.com/goharbor/harbor</a></p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir -p &#x2F;data&#x2F;soft&#x2F;docker</span><br><span class="line">[root@wang-200 ~]# wget -O &#x2F;data&#x2F;soft&#x2F;docker&#x2F;harbor-offline-installer-v1.8.3.tgz https:&#x2F;&#x2F;storage.googleapis.com&#x2F;harbor-releases&#x2F;release-1.8.0&#x2F;harbor-offline-installer-v1.8.3.tgz # 较慢</span><br><span class="line"># https:&#x2F;&#x2F;codeload.github.com&#x2F;goharbor&#x2F;harbor&#x2F;tar.gz&#x2F;v1.8.3 在线安装包，自己摸索安装</span><br></pre></td></tr></table></figure><p><strong>解压并创建软连接</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# tar xf &#x2F;data&#x2F;soft&#x2F;docker&#x2F;harbor-offline-installer-v1.8.3.tgz -C &#x2F;opt&#x2F;</span><br><span class="line">[root@wang-200 ~]# mv &#x2F;opt&#x2F;harbor&#x2F; &#x2F;opt&#x2F;harbor-v1.8.3</span><br><span class="line">[root@wang-200 ~]# ln -s &#x2F;opt&#x2F;harbor-v1.8.3&#x2F; &#x2F;opt&#x2F;harbor</span><br></pre></td></tr></table></figure><h3 id="修改-harbor配置文件"><a href="#修改-harbor配置文件" class="headerlink" title="修改 harbor配置文件"></a>修改 harbor配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cp &#x2F;opt&#x2F;harbor&#x2F;harbor.yml &#x2F;opt&#x2F;harbor&#x2F;harbor.yml.bak</span><br><span class="line">[root@wang-200 ~]# vim &#x2F;opt&#x2F;harbor&#x2F;harbor.yml</span><br><span class="line">[root@zzgw7-200 ~]# egrep -nv &#39;^$|#&#39; &#x2F;opt&#x2F;harbor&#x2F;harbor.yml</span><br><span class="line"> 5:hostname: harbor.od.com# 配置域名访问</span><br><span class="line">10:  port: 180# 修改服务端口,防止端口冲突</span><br><span class="line">27:harbor_admin_password: Harbor12345# harbor登录密码</span><br><span class="line">35:data_volume: &#x2F;data&#x2F;harbor# harbor数据存放路径</span><br><span class="line">82:  location: &#x2F;data&#x2F;harbor&#x2F;logs# harbor日志存放路径</span><br></pre></td></tr></table></figure><h3 id="安装-docker-compose1-25-5"><a href="#安装-docker-compose1-25-5" class="headerlink" title="安装 docker-compose1.25.5"></a>安装 docker-compose1.25.5</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y python3-pip</span><br><span class="line">pip3 install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple pip -U</span><br><span class="line">pip3 install docker-compose -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple</span><br><span class="line">docker-compose -version</span><br></pre></td></tr></table></figure><h3 id="安装-Harbor"><a href="#安装-Harbor" class="headerlink" title="安装 Harbor"></a>安装 Harbor</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cd &#x2F;opt&#x2F;harbor</span><br><span class="line">[root@wang-200 harbor]# .&#x2F;install.sh</span><br></pre></td></tr></table></figure><h3 id="查看-Harbor启动状态"><a href="#查看-Harbor启动状态" class="headerlink" title="查看 Harbor启动状态"></a>查看 Harbor启动状态</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@wang-200 harbor]<span class="comment"># docker-compose ps</span></span><br><span class="line">      Name                     Command                       State                     Ports          </span><br><span class="line">------------------------------------------------------------------------------------------------------</span><br><span class="line">harbor-core         /harbor/start.sh                 Up (health: starting)                            </span><br><span class="line">harbor-db           /entrypoint.sh postgres          Up (health: starting)   5432/tcp                 </span><br><span class="line">harbor-jobservice   /harbor/start.sh                 Up                                               </span><br><span class="line">harbor-log          /bin/sh -c /usr/<span class="built_in">local</span>/bin/ ...   Up (health: starting)   127.0.0.1:1514-&gt;10514/tcp</span><br><span class="line">harbor-portal       nginx -g daemon off;             Up (health: starting)   80/tcp                   </span><br><span class="line">nginx               nginx -g daemon off;             Up (health: starting)   0.0.0.0:180-&gt;80/tcp      </span><br><span class="line">redis               docker-entrypoint.sh redis ...   Up                      6379/tcp                 </span><br><span class="line">registry            /entrypoint.sh /etc/regist ...   Up (health: starting)   5000/tcp                 </span><br><span class="line">registryctl         /harbor/start.sh                 Up (health: starting)</span><br></pre></td></tr></table></figure><h3 id="配置-harbor的DNS内网解析"><a href="#配置-harbor的DNS内网解析" class="headerlink" title="配置 harbor的DNS内网解析"></a>配置 harbor的DNS内网解析</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># sed &#39;&#x2F;^\*&#x2F;i harbor\t\tA\t192.168.70.200\t; 添加harbor的A记录&#39; &#x2F;var&#x2F;named&#x2F;od.com.zone </span><br><span class="line">[root@wang-12 ~]# vim &#x2F;var&#x2F;named&#x2F;od.com.zone</span><br><span class="line">harbor          A       192.168.70.200  ; 添加harbor的A记录</span><br></pre></td></tr></table></figure><p><strong>重启named服务并验证</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-12 ~]# systemctl restart named    </span><br><span class="line">[root@wang-12 ~]# dig -t A harbor.od.com +short</span><br><span class="line">192.168.70.200</span><br></pre></td></tr></table></figure><h3 id="配置nginx-代理harbor"><a href="#配置nginx-代理harbor" class="headerlink" title="配置nginx 代理harbor"></a>配置nginx 代理harbor</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 soft]# yum install -y nginx</span><br><span class="line">[root@wang-200 soft]# mkdir &#x2F;data&#x2F;logs&#x2F;nginx</span><br></pre></td></tr></table></figure><p><code>vim /etc/nginx/conf.d/harbor.od.com.conf</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name harbor.od.com;</span><br><span class="line">    client_max_body_size 1000m;</span><br><span class="line">    access_log &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;harbor.od.com.log;</span><br><span class="line"></span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;127.0.0.1:180;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>启动 nginx</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br><span class="line">systemctl start nginx</span><br><span class="line">systemctl enable nginx</span><br></pre></td></tr></table></figure><h3 id="Web-访问登录"><a href="#Web-访问登录" class="headerlink" title="Web 访问登录"></a>Web 访问登录</h3><p>默认登录名：<code>admin</code>     默认密码：<code>Harbor12345</code></p><p>密码可以在harbor.yml中修改</p><p><img src="http://wang.ikongjian.com/img/kubernetes/install/20200331230312971.png" alt="habor登录界面"></p><p><strong>创建新项目</strong></p><p><img src="http://wang.ikongjian.com/img/kubernetes/install/20200331230353366.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lzYV9JSQ==,size_16,color_FFFFFF,t_70" alt="创建项目"></p><h3 id="上传镜像测试"><a href="#上传镜像测试" class="headerlink" title="上传镜像测试"></a>上传镜像测试</h3><p><strong>登录harbor仓库</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# docker login harbor.od.com</span><br><span class="line">Username: admin#用户名</span><br><span class="line">Password:         #登录密码</span><br><span class="line">WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><p><strong>下载测试镜像并打给镜像打一个tag</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull nginx:1.7.9</span><br><span class="line">docker tag nginx:1.7.9 harbor.od.com&#x2F;public&#x2F;nginx:v1.7.9</span><br><span class="line">docker push harbor.od.com&#x2F;public&#x2F;nginx:v1.7.9</span><br></pre></td></tr></table></figure><p><strong>web 页面检查</strong></p><p><img src="https://img-blog.csdnimg.cn/20200331230447672.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lzYV9JSQ==,size_16,color_FFFFFF,t_70" alt="web页面检查"></p><h2 id="创建nfs服务器"><a href="#创建nfs服务器" class="headerlink" title="创建nfs服务器"></a>创建nfs服务器</h2><h3 id="安装-nfs-服务器所需的软件包"><a href="#安装-nfs-服务器所需的软件包" class="headerlink" title="安装 nfs 服务器所需的软件包"></a>安装 nfs 服务器所需的软件包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# yum install -y nfs-utils</span><br></pre></td></tr></table></figure><h3 id="修改配置文件-1"><a href="#修改配置文件-1" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# mkdir -p &#x2F;data&#x2F;nfs&#x2F;v1  </span><br><span class="line">[root@wang-200 ~]# vim &#x2F;etc&#x2F;exports</span><br><span class="line">&#x2F;data&#x2F;nfs&#x2F;v1 192.168.70.1&#x2F;24(insecure,rw,sync,no_root_squash)  # 免密可读写</span><br></pre></td></tr></table></figure><h3 id="启动nfs服务"><a href="#启动nfs服务" class="headerlink" title="启动nfs服务"></a>启动nfs服务</h3><p>运行nfs服务，还需要rpcbind的支持</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl start nfs-server</span><br><span class="line">systemctl enable rpcbind</span><br><span class="line">systemctl enable nfs-server</span><br><span class="line">exportfs -r  # 重新挂载&#x2F;etc&#x2F;exports中的设置，此外同步更新&#x2F;etc&#x2F;exports及&#x2F;var&#x2F;lib&#x2F;nfs&#x2F;xtab中的内容</span><br></pre></td></tr></table></figure><h3 id="检查nfs服务是否可用"><a href="#检查nfs服务是否可用" class="headerlink" title="检查nfs服务是否可用"></a>检查nfs服务是否可用</h3><p><strong>检查是否生效</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# exportfs</span><br><span class="line">&#x2F;data&#x2F;nfs&#x2F;v1    192.168.70.1&#x2F;24</span><br></pre></td></tr></table></figure><p><strong>客户端测试（wang-21）</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-21 ~]# yum install -y nfs-utils</span><br><span class="line">[root@wang-21 ~]# showmount -e 192.168.70.200   </span><br><span class="line">Export list for 192.168.70.200:</span><br><span class="line">&#x2F;data&#x2F;nfs&#x2F;v1 192.168.70.1&#x2F;24</span><br><span class="line">[root@wang-21 ~]# mkdir &#x2F;tmp&#x2F;testnfs</span><br><span class="line">[root@wang-21 ~]# mount -t nfs 192.168.70.200:&#x2F;data&#x2F;nfs&#x2F;v1 &#x2F;tmp&#x2F;testnfs   </span><br><span class="line">[root@wang-21 ~]# echo &quot;hello nfs server&quot; &gt; &#x2F;tmp&#x2F;testnfs&#x2F;hello</span><br></pre></td></tr></table></figure><p><strong>回到wang-200上查验</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# cat &#x2F;data&#x2F;nfs&#x2F;v1&#x2F;hello </span><br><span class="line">hello nfs server</span><br></pre></td></tr></table></figure><h3 id="在所有需要的主机上安装nfs"><a href="#在所有需要的主机上安装nfs" class="headerlink" title="在所有需要的主机上安装nfs"></a>在所有需要的主机上安装nfs</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 jenkins]# ansible all -m shell -a &quot;yum install nfs-utils -y&quot;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k8stest-二进制安装记录</title>
      <link href="/2020/05/28/k8stest-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/"/>
      <url>/2020/05/28/k8stest-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible all -m shell -a  &quot;HOSTIP&#x3D;\&#96;hostname -i\&#96;; HOSTNUM&#x3D;\$&#123;HOSTIP##*.&#125;;  echo -e export HOSTIP&#x3D;\$HOSTIP \\\nexport HOSTNUM&#x3D;\$HOSTNUM &gt;&gt; &#x2F;etc&#x2F;bashrc&quot; </span><br><span class="line">ansible all -m shell -a  &quot;systemctl restart docker&quot;</span><br></pre></td></tr></table></figure><p>![habor登录界面](<a href="http://wang.ikongjian.com/img/kubernetes/install/">http://wang.ikongjian.com/img/kubernetes/install/</a></p><div class="hide-toggle" style="border: 1px solid bg"><div class="hide-button toggle-title" style="background-color: bg;color: color"><i class="fa fa-caret-right fa-fw"></i><span>display</span></div>    <div class="hide-content"><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">content</span><br><span class="line">[root@ikj-141 hexo]# grep since source&#x2F;_data&#x2F;butterfly.yml </span><br><span class="line">since: 2020</span><br></pre></td></tr></table></figure></div></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-22 etcd]# &#x2F;opt&#x2F;etcd&#x2F;etcd-server-startup.sh</span><br><span class="line">2020-05-31 17:08:20.411202 I | etcdmain: etcd Version: 3.1.20</span><br><span class="line">2020-05-31 17:08:20.411514 I | etcdmain: Git SHA: 992dbd4d1</span><br><span class="line">2020-05-31 17:08:20.411556 I | etcdmain: Go Version: go1.8.7</span><br><span class="line">2020-05-31 17:08:20.411608 I | etcdmain: Go OS&#x2F;Arch: linux&#x2F;amd64</span><br><span class="line">2020-05-31 17:08:20.411640 I | etcdmain: setting maximum number of CPUs to 4, total number of available CPUs is 4</span><br><span class="line">2020-05-31 17:08:20.411824 N | etcdmain: the server is already initialized as member before, starting as etcd member...</span><br><span class="line">2020-05-31 17:08:20.411932 I | embed: peerTLS: cert &#x3D; .&#x2F;certs&#x2F;etcd-peer.pem, key &#x3D; .&#x2F;certs&#x2F;etcd-peer-key.pem, ca &#x3D; .&#x2F;certs&#x2F;ca.pem, trusted-ca &#x3D; .&#x2F;certs&#x2F;ca.pem, client-cert-auth &#x3D; true</span><br><span class="line">2020-05-31 17:08:20.415840 I | embed: listening for peers on https:&#x2F;&#x2F;192.168.70.22:2380</span><br><span class="line">2020-05-31 17:08:20.415961 W | embed: The scheme of client url http:&#x2F;&#x2F;127.0.0.1:2379 is HTTP while peer key&#x2F;cert files are presented. Ignored key&#x2F;cert files.</span><br><span class="line">2020-05-31 17:08:20.415999 W | embed: The scheme of client url http:&#x2F;&#x2F;127.0.0.1:2379 is HTTP while client cert auth (--client-cert-auth) is enabled. Ignored client cert auth for this url.</span><br><span class="line">2020-05-31 17:08:20.416173 I | embed: listening for client requests on 127.0.0.1:2379</span><br><span class="line">2020-05-31 17:08:20.416400 I | embed: listening for client requests on 192.168.70.22:2379</span><br><span class="line">2020-05-31 17:08:20.429883 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</span><br><span class="line">2020-05-31 17:08:20.444261 I | etcdmain: --initial-cluster must include etcd-server-70-22&#x3D;https:&#x2F;&#x2F;192.168.70.22:2380 given --initial-advertise-peer-urls&#x3D;https:&#x2F;&#x2F;192.168.70.22:2380</span><br></pre></td></tr></table></figure><p>–initial-cluster 我这一行配置错了</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-05-31 17:37:34.355943 C | etcdmain: member f97020d34db750ca has already been bootstrapped</span><br><span class="line">2020-05-31 17:37:37.422736 I | etcdmain: etcd Version: 3.1.20</span><br><span class="line">2020-05-31 17:37:37.422933 I | etcdmain: Git SHA: 992dbd4d1</span><br><span class="line">2020-05-31 17:37:37.422950 I | etcdmain: Go Version: go1.8.7</span><br><span class="line">2020-05-31 17:37:37.422962 I | etcdmain: Go OS&#x2F;Arch: linux&#x2F;amd64</span><br><span class="line">2020-05-31 17:37:37.422976 I | etcdmain: setting maximum number of CPUs to 4, total number of available CPUs is 4</span><br><span class="line">2020-05-31 17:37:37.423091 N | etcdmain: the server is already initialized as member before, starting as etcd member...</span><br><span class="line">2020-05-31 17:37:37.423171 I | embed: peerTLS: cert &#x3D; .&#x2F;certs&#x2F;etcd-peer.pem, key &#x3D; .&#x2F;certs&#x2F;etcd-peer-key.pem, ca &#x3D; .&#x2F;certs&#x2F;ca.pem, trusted-ca &#x3D; .&#x2F;certs&#x2F;ca.pem, client-cert-auth &#x3D; true</span><br><span class="line">2020-05-31 17:37:37.425752 I | embed: listening for peers on https:&#x2F;&#x2F;192.168.70.22:2380</span><br><span class="line">2020-05-31 17:37:37.425873 W | embed: The scheme of client url http:&#x2F;&#x2F;127.0.0.1:2379 is HTTP while peer key&#x2F;cert files are presented. Ignored key&#x2F;cert files.</span><br><span class="line">2020-05-31 17:37:37.425904 W | embed: The scheme of client url http:&#x2F;&#x2F;127.0.0.1:2379 is HTTP while client cert auth (--client-cert-auth) is enabled. Ignored client cert auth for this url.</span><br><span class="line">2020-05-31 17:37:37.426034 I | embed: listening for client requests on 127.0.0.1:2379</span><br><span class="line">2020-05-31 17:37:37.426143 I | embed: listening for client requests on 192.168.70.22:2379</span><br><span class="line">2020-05-31 17:37:37.433828 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</span><br><span class="line">2020-05-31 17:37:37.466423 C | etcdmain: member f97020d34db750ca has already been bootstrapped</span><br></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfeyubuvokj30ho06ot9a.jpg" alt="image-20200509153629808"></p><p><strong>Traefik-ingress 发布报错</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type     Reason                  Age                    From                       Message</span><br><span class="line"></span><br><span class="line">----     ------                  ----                   ----                       -------</span><br><span class="line"></span><br><span class="line">  Normal   SandboxChanged          10m (x5904 over 3h5m)  kubelet, wang-24.host.com  Pod sandbox changed, it will be killed and re-created.</span><br><span class="line">  Warning  FailedCreatePodSandBox  29s (x6207 over 3h5m)  kubelet, wang-24.host.com  (combined from similar events): Failed create pod sandbox: rpc error: code &#x3D; Unknown desc &#x3D; failed to start sandbox container for pod &quot;traefik</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  -ingress-tnw7n&quot;: Error response from daemon: driver failed programming external connectivity on endpoint k8s_POD_traefik-ingress-tnw7n_kube-system_45d3c9bf-0633-44f0-8048-91061b74a7e2_6215 (b578fba313008f91ed117d5d5112c74ca2d07b5e460c20a862b7ad07207f5f72):  (iptables failed: iptables --wait -t filter -A DOCKER ! -i docker0 -o docker0 -p tcp -d 172.16.24.4 --dport 80 -j ACCEPT: iptables: No chain&#x2F;target&#x2F;match by that name.</span><br><span class="line"> (exit status 1))</span><br></pre></td></tr></table></figure><p>重启问题解决</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一、k8s-实验环境说明</title>
      <link href="/2020/05/28/%E4%B8%80%E3%80%81k8s-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E8%AF%B4%E6%98%8E/"/>
      <url>/2020/05/28/%E4%B8%80%E3%80%81k8s-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E8%AF%B4%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<h2 id="文档说明"><a href="#文档说明" class="headerlink" title="文档说明"></a>文档说明</h2><p>本文档为kubernetes二进制安装方式，以老男孩k8s一期培训课程为基础模版，增加了一个k8s控制节点(机器上也有工作节点)，并有少量改动。</p><p>主要参考文档：</p><ul><li><a href="https://www.jianshu.com/p/ad36d2ad0df0" target="_blank" rel="noopener">OneLpc二进制安装K8S集群</a></li><li><a href="https://www.cnblogs.com/slim-liu/p/11953318.html" target="_blank" rel="noopener">slim_liu的k8s交付实战</a></li><li><a href="https://www.wqblogs.com/2020/01/08/%E9%83%A8%E7%BD%B2kibana/" target="_blank" rel="noopener">虫子k8s生态实战</a></li></ul><h2 id="实验架构图"><a href="#实验架构图" class="headerlink" title="实验架构图"></a>实验架构图</h2><p><img src="http://wang.ikongjian.com/img/kubernetes/install/2020033123005972.png" alt="实验架构图"></p><h2 id="实验主机说明"><a href="#实验主机说明" class="headerlink" title="实验主机说明"></a>实验主机说明</h2><p>操作系统：7.6.1810； 内核：3.10.0</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th><th>硬件配置</th></tr></thead><tbody><tr><td>wang-200.host.com (zzgw7-200)</td><td>192.168.70.200</td><td>运维节点</td><td>4核8G-100G</td></tr><tr><td>wang-11.host.com (zzgw7-11)</td><td>192.168.70.11</td><td>k8s代理节点</td><td>2核4G-100G</td></tr><tr><td>wang-12.host.com (zzgw7-12)</td><td>192.168.70.12</td><td>k8s代理节点</td><td>2核4G-100G</td></tr><tr><td>wang-21.host.com (zzgw7-21)</td><td>192.168.70.21</td><td>k8s控制节点</td><td>2核4G-100G</td></tr><tr><td>wang-22.host.com (zzgw7-22)</td><td>192.168.70.22</td><td>k8s控制节点</td><td>2核4G-100G</td></tr><tr><td>wang-23.host.com (zzgw7-21)</td><td>192.168.70.23</td><td>k8s控制节点, 工作节点</td><td>2核4G-100G</td></tr><tr><td>wang-24.host.com (zzgw7-22)</td><td>192.168.70.24</td><td>k8s工作节点</td><td>4核8G-100G</td></tr></tbody></table><h2 id="通过VMWare创建虚拟主机"><a href="#通过VMWare创建虚拟主机" class="headerlink" title="通过VMWare创建虚拟主机"></a>通过VMWare创建虚拟主机</h2><p>wang-11, wang-12,wang-21, wang-22, wang-23, wang-24</p><h2 id="修改wang-19运维节点系统配置"><a href="#修改wang-19运维节点系统配置" class="headerlink" title="修改wang-19运维节点系统配置"></a>修改wang-19运维节点系统配置</h2><p><strong>修改默认密码</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# echo wang123 | passwd --stdin root</span><br><span class="line">[root@localhost ~]# mkdir &#x2F;data&#x2F;shell</span><br></pre></td></tr></table></figure><p><strong>创建文件，方便以后使用</strong></p><p><code>vim /data/shell/modify_server.sh</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修改主机名</span><br><span class="line">hostip&#x3D;&#96;ifconfig ens160 | grep 192 | awk &#39;&#123;print $2&#125;&#39;| awk -F&#39;.&#39; &#39;&#123;print $4&#125;&#39; &#96;; hostnamectl set-hostname wang-$hostip.host.com</span><br><span class="line"></span><br><span class="line"># 配置阿里yum源</span><br><span class="line">mkdir &#x2F;etc&#x2F;yum.repos.d&#x2F;bak &amp;&amp; mv &#x2F;etc&#x2F;yum.repos.d&#x2F;*.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;bak</span><br><span class="line">curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo</span><br><span class="line">curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;epel-7.repo</span><br><span class="line"></span><br><span class="line"># 关闭SElinux</span><br><span class="line">sed -i &#39;s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config</span><br><span class="line">setenforce 0</span><br><span class="line"></span><br><span class="line"># 关闭firewalld</span><br><span class="line">systemctl disable firewalld.service  </span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"></span><br><span class="line"># 安装必要工具</span><br><span class="line">yum install -y wget net-tools telnet tree nmap sysstat lrzsz dos2unix </span><br><span class="line"></span><br><span class="line"># 创建日志目录</span><br><span class="line">mkdir -p &#x2F;data&#x2F;logs &#x2F;data&#x2F;soft</span><br><span class="line"></span><br><span class="line"># 添加两个变量，方便以后使用</span><br><span class="line">HOSTIP&#x3D;&#96;hostname -i | grep -o &#39;192.168.70.[0-9]\&#123;1,3\&#125;&#39; &#96;</span><br><span class="line">HOSTNUM&#x3D;$&#123;HOSTIP##*.&#125;</span><br><span class="line">echo $HOSTIP $HOSTNUM</span><br><span class="line">echo -e &quot;export HOSTIP&#x3D;$HOSTIP \nexport HOSTNUM&#x3D;$HOSTNUM&quot; &gt;&gt; &#x2F;etc&#x2F;bashrc</span><br></pre></td></tr></table></figure><p>执行配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# chmod +x &#x2F;data&#x2F;shell&#x2F;modify_server.sh</span><br><span class="line">[root@localhost ~]# &#x2F;data&#x2F;shell&#x2F;modify_server.sh</span><br></pre></td></tr></table></figure><h2 id="使用ansible来进行统一管理"><a href="#使用ansible来进行统一管理" class="headerlink" title="使用ansible来进行统一管理"></a>使用ansible来进行统一管理</h2><h3 id="创建一个-SSH-key，用来管理其他服务器"><a href="#创建一个-SSH-key，用来管理其他服务器" class="headerlink" title="创建一个 SSH key，用来管理其他服务器"></a>创建一个 SSH key，用来管理其他服务器</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-19 ~]# ssh-keygen -t rsa -C &quot;wang@qq.com&quot;</span><br></pre></td></tr></table></figure><p>将公钥拷贝到其他管理服务器，比如192.168.70.11</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# ssh-copy-id 192.168.70.11</span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: Source of key(s) to be installed: &quot;&#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub&quot;</span><br><span class="line">The authenticity of host &#39;192.168.70.11 (192.168.70.11)&#39; can&#39;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:uAnxlYCLTfdyOL0yA5xwDgSN1V&#x2F;WmyjwJqvixpsFoJ4.</span><br><span class="line">ECDSA key fingerprint is MD5:47:f9:99:e4:3a:30:2b:05:37:b3:29:07:60:57:ef:4d.</span><br><span class="line">Are you sure you want to continue connecting (yes&#x2F;no)? yes</span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@192.168.70.11&#39;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#39;192.168.70.11&#39;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br></pre></td></tr></table></figure><h3 id="安装ansible"><a href="#安装ansible" class="headerlink" title="安装ansible"></a>安装ansible</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# yum -y install ansible</span><br></pre></td></tr></table></figure><h3 id="修改ansible配置文件"><a href="#修改ansible配置文件" class="headerlink" title="修改ansible配置文件"></a>修改ansible配置文件</h3><p><code>vim /etc/ansible/hosts</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[all:children]</span><br><span class="line">yunwei</span><br><span class="line">k8s</span><br><span class="line">[k8s:children]</span><br><span class="line">nginx</span><br><span class="line">master</span><br><span class="line">worker</span><br><span class="line">[yunwei]</span><br><span class="line">192.168.70.200</span><br><span class="line">[nginx]</span><br><span class="line">192.168.70.11</span><br><span class="line">192.168.70.12</span><br><span class="line">[master]</span><br><span class="line">192.168.70.21</span><br><span class="line">192.168.70.22</span><br><span class="line">192.168.70.23</span><br><span class="line">[worker]</span><br><span class="line">192.168.70.21</span><br><span class="line">192.168.70.22</span><br><span class="line">192.168.70.23</span><br><span class="line">192.168.70.24</span><br></pre></td></tr></table></figure><h2 id="使用anbile修改其他服务器"><a href="#使用anbile修改其他服务器" class="headerlink" title="使用anbile修改其他服务器"></a>使用anbile修改其他服务器</h2><h3 id="修改其他服务器的密码"><a href="#修改其他服务器的密码" class="headerlink" title="修改其他服务器的密码"></a>修改其他服务器的密码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# ansible k8s -m shell -a &quot;echo wang123 | passwd --stdin root&quot;</span><br></pre></td></tr></table></figure><h3 id="调整其他服务器系统配置"><a href="#调整其他服务器系统配置" class="headerlink" title="调整其他服务器系统配置"></a>调整其他服务器系统配置</h3><p>拷贝文件到服务器并运行文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@wang-200 ~]# ansible k8s -m shell -a &quot;mkdir -p &#x2F;data&#x2F;shell&#x2F;&quot;</span><br><span class="line">[root@wang-200 ~]# ansible k8s -m copy -a &quot;src&#x3D;&#x2F;data&#x2F;shell&#x2F;modify_server.sh dest&#x3D;&#x2F;data&#x2F;shell&#x2F;modify_server.sh mode&#x3D;0755 backup&#x3D;true&quot;</span><br><span class="line">[root@wang-200 ~]# ansible k8s -m shell -a &quot;&#x2F;data&#x2F;shell&#x2F;modify_server.sh&quot;</span><br></pre></td></tr></table></figure><h2 id="域名集合"><a href="#域名集合" class="headerlink" title="域名集合"></a>域名集合</h2><p><a href="http://harbor.od.com/" target="_blank" rel="noopener">http://harbor.od.com/</a>    harbor管理仓库</p><p><a href="http://doc.k8s.od.com/" target="_blank" rel="noopener">http://doc.k8s.od.com/</a>     k8s构建文档</p><p><a href="http://traefik.od.com/dashboard/" target="_blank" rel="noopener">http://traefik.od.com/dashboard/</a>   traefik管理界面(Ingress)</p><p><a href="https://dashboard.od.com" target="_blank" rel="noopener">https://dashboard.od.com</a>    k8s管理界面</p><p><a href="http://jenkins.od.com/" target="_blank" rel="noopener">http://jenkins.od.com/</a>  Jenkins构建平台</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 二进制安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 二进制安装 </tag>
            
            <tag> 老男孩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>0、交付-域名集合</title>
      <link href="/2020/05/28/0%E3%80%81%E4%BA%A4%E4%BB%98-%E5%9F%9F%E5%90%8D%E9%9B%86%E5%90%88/"/>
      <url>/2020/05/28/0%E3%80%81%E4%BA%A4%E4%BB%98-%E5%9F%9F%E5%90%8D%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h2 id="域名集合"><a href="#域名集合" class="headerlink" title="域名集合"></a>域名集合</h2><p><a href="http://harbor.od.com/" target="_blank" rel="noopener">http://harbor.od.com/</a>    harbor管理仓库</p><p><a href="http://doc.k8s.od.com/" target="_blank" rel="noopener">http://doc.k8s.od.com/</a>     k8s构建文档</p><p><a href="http://traefik.od.com/dashboard/" target="_blank" rel="noopener">http://traefik.od.com/dashboard/</a>   traefik管理界面(Ingress)</p><p><a href="https://dashboard.od.com" target="_blank" rel="noopener">https://dashboard.od.com</a>    k8s管理界面</p><p><a href="http://jenkins.od.com/" target="_blank" rel="noopener">http://jenkins.od.com/</a>  Jenkins构建平台</p><p><a href="http://dubbo-monitor.od.com/" target="_blank" rel="noopener">http://dubbo-monitor.od.com/</a>  dubbo控制界面</p><p><a href="http://demo.od.com/hello?name=slim" target="_blank" rel="noopener">http://demo.od.com/hello?name=slim</a>   demo测试UI页面</p><p><a href="http://config.od.com/" target="_blank" rel="noopener">http://config.od.com/</a>  apollo客户端</p><p><a href="http://portal.od.com/" target="_blank" rel="noopener">http://portal.od.com/</a>  apollo配置中心</p><p><a href="http://km.od.com/" target="_blank" rel="noopener">http://km.od.com/</a>    kafka管理界面</p><p><a href="http://kibana.od.com/" target="_blank" rel="noopener">http://kibana.od.com/</a>    查看日志</p><p><a href="http://blackbox.od.com/" target="_blank" rel="noopener">http://blackbox.od.com/</a>  服务监控界面</p><p><a href="http://prometheus.od.com/" target="_blank" rel="noopener">http://prometheus.od.com/</a>   prometheus管理界面</p><p><a href="http://grafana.od.com/login" target="_blank" rel="noopener">http://grafana.od.com/login</a>  监控展示界面</p><p><a href="http://alertmanager.od.com" target="_blank" rel="noopener">http://alertmanager.od.com</a>  监控报警页面</p><p>测试域名</p><p><a href="http://config-test.od.com/" target="_blank" rel="noopener">http://config-test.od.com/</a></p><p><a href="http://config-prod.od.com/" target="_blank" rel="noopener">http://config-prod.od.com/</a></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> 老男孩 </category>
          
          <category> 实战交付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> 老男孩 </tag>
            
            <tag> 实战交付 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Test</title>
      <link href="/2020/05/20/test/"/>
      <url>/2020/05/20/test/</url>
      
        <content type="html"><![CDATA[<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><p>哪个英文字母最酷？ <span class="hide-inline"><a class="hide-button button--primary button--animated" style="background-color: #FF7242;color: #fff">查看答案  </a><span class="hide-content">因为西装裤(C装酷)</span></span></p><p>门里站着一个人? <span class="hide-inline"><a class="hide-button button--primary button--animated" style="">Click  </a><span class="hide-content">闪</span></span></p><blockquote><p>wang</p><footer><strong>[author[</strong><cite>source]] [link] [source_link_title]</cite></footer></blockquote><figure class="highlight plain"><figcaption><span>[title] [] [url] [link text] [additional options]</span></figcaption><table><tr><td class="code"><pre><span class="line">code snippet</span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>_.compact</span><a href="http://underscorejs.org/#compact" target="_blank" rel="noopener">Underscore.js</a></figcaption><table><tr><td class="code"><pre><span class="line">_.compact([0, 1, false, 2, &#39;&#39;, 3]);</span><br><span class="line">&#x3D;&gt; [1, 2, 3]</span><br></pre></td></tr></table></figure><div class="hide-block"><a class="hide-button button--primary button--animated" style="">查看答案 小美女    </a><span class="hide-content"><div class="justified-gallery"><p><img src="https://i.loli.net/2019/12/25/Fze9jchtnyJXMHN.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/ryLVePaqkYm4TEK.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/gEy5Zc1Ai6VuO4N.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/d6QHbytlSYO4FBG.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/6nepIJ1xTgufatZ.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/E7Jvr4eIPwUNmzq.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/mh19anwBSWIkGlH.jpg" alt=""><br><img src="https://i.loli.net/2019/12/25/2tu9JC8ewpBFagv.jpg" alt=""></p>          </div></span></div><p>隐藏</p><div class="hide-toggle" style="border: 1px solid bg"><div class="hide-button toggle-title" style="background-color: bg;color: color"><i class="fa fa-caret-right fa-fw"></i><span>display</span></div>    <div class="hide-content"><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">content</span><br><span class="line">[root@ikj-141 hexo]# grep since source&#x2F;_data&#x2F;butterfly.yml </span><br><span class="line">since: 2020</span><br></pre></td></tr></table></figure></div></div><p>mermaid</p><p>使用mermaid标签可以绘制Flowchart（流程图）、Sequence diagram（时序图 ）、Class Diagram（类别图）、State Diagram（状态图）、Gantt（甘特图）和Pie Chart（圆形图</p><div class="mermaid">          内容          </div><div class="mermaid">          pie    title Key elements in Product X    "Calcium" : 42.96    "Potassium" : 50.05    "Magnesium" : 10.01    "Iron" :  5          </div><div class="gallery-group-main">  <figure class="gallery-group">  <img class="gallery-group-img" src='https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png'>  <figcaption>  <div class="gallery-group-name">壁纸</div>  <p>收藏的一些壁纸</p>  <a href='/Gallery/wallpaper'></a>  </figcaption>  </figure>    <figure class="gallery-group">  <img class="gallery-group-img" src='https://i.loli.net/2019/12/25/8t97aVlp4hgyBGu.jpg'>  <figcaption>  <div class="gallery-group-name">漫威</div>  <p>关于漫威的图片</p>  <a href='/Gallery/marvel'></a>  </figcaption>  </figure>    <figure class="gallery-group">  <img class="gallery-group-img" src='https://i.loli.net/2019/12/25/hOqbQ3BIwa6KWpo.jpg'>  <figcaption>  <div class="gallery-group-name">OH MY GIRL</div>  <p>关于OH MY GIRL的图片</p>  <a href='/Gallery/ohmygirl'></a>  </figcaption>  </figure>  </div>]]></content>
      
      
      <categories>
          
          <category> foo </category>
          
          <category> bar </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
            <tag> bar </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/05/01/hello-world/"/>
      <url>/2020/05/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> foo </category>
          
          <category> bar </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
